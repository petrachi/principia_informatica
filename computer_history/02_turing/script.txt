===
Gödel (Livre)
===

- Paradoxe De Burali-Forti (1897):
- Cantor dévelloppe la théorie des ensembles de 1873-1897 pour répondre à des problème d'analyses
- Un des premiers réultat est la distinction entre continu et dénombrable (deux puissances d'infini) -> Tous les infinis ne se valent pas, certains sont plus grand que d'autres.
- l'hypothése du continu de cantor suggére qu'il n'y a pas de puissance intermédiaire entre le dénombrable et le continu
- pour mesurer la puissance de l'infini, Cantor développe les nombres ordinaux (1883 + 1895-97).
- ω est l'ordinal de la suite des nombres entiers
- ω1 est l'ordinal de la suite des ordinaux dénombrables
- l'hypothése de Cantor est que l'infini continu à la même puissance que ω1
- BF cherche à créer l'ordinal de la suite des ordinaux. Une suite devrait générer un ordinal, mais comme un nouvel ordinal serait inclus dans cette suite, ça ne serait pas l'orinal de la suite des oridinaux, donc il ne peux pas y avoir d'ordinal pour cette suite, mais une suite devrait avoir un ordinal.


- Russell, l'ensemble des cuilleres à thé n'est pas une cuieller à thé, il ne s'appartient pas à lui même.
- "être vert" est une propriété (la pomme est verte), qui ne s'applique pas à elle même (le concept "être vert" n'est pas vert lui même). On appelle hétérologie le concept des concepts qui ne s'appliquent pas à eux même. Mais l'héterologie est elle hétérologique ? S'il était hétérologique, il s'appliquerait à lui même, et ne serait pas hétérologique. S'il n'était pas hétérologique, il ne s'appliquerait pas à lui même et serait hétérologique.

- Ponicaré meurt en 1912, sans avoir eu le temps de proposer sa propre solution au pb des fondements

_ Les principia mathematica se basent, pour l'essentiel, sur les théses de Russell (article 1908, "la logique mathématique fondée sur la théorie des types")

- l'infini actuel est utilisé dés l'arithmétique élémentaire, avec le principe du tiers exclu
- principe du tiers exclus : ou bien tous les entiers vérifient P, ou bien il en existe au moins un pour lequel P est faux. Si on est dans le second cas, on affirme l'existence d'un entier qui ne vérifie pas P, avant même de l'avoir calculé
- Le tiers exclu suppose que tous les nombres existent en soi, et ont des propriétés.
- Pointcaré prône le principe de constructivité : un objet mathématique n'existe pas tant que le mathématicien ne l'a pas crée.
- L'intuitionisme admet la même chose, les objets sont engendrés par la consience mathématicienne, qui vit dans le temps. (donc, pour le paradoxe de Richard, le nombre crée à partir de l'ensemble E ne peut pas y appartenir, puisqu'on l'à crée après l'ensemble E)
- H admet pour le programme formaliste le principe de constructivité -> math finitiste, plus strct que l'intuitionnisme

- l'axiomatique, c'est comme la grammaire d'une langue, pas besoin de connaitre le sens des phrases

- le calcul des prédicats représente la structure logique la plus générale des domaines mathématiques.

- Skolem 1923 montre qu'aucun systéme de mathématique classique n'est catégorique. c-a-d: un systéme qui correspondrait point par point à un domaine mathématique, ce qui les rendrait indiscernables.
- systéme = systéme d'axiome
- domaine = théorie mathématique, qui se rapporte à un domaine d'objet (les nombres en arithmétique, les points en géométrie)

- complétude sémantique : un systéme qui peut s'appliquer dans différents domaines, de sorte que ce qui est vrai dans un domaine est également vrai dans un autre
- complétude syntaxique : tout est soit vrai, soit faux
- catégoricité implique complétude syntaxique
- complétude syntaxique implique décidabilité (on ne le savait pas du temps d'H)

- Zermelo axiomatise la théorie des ensembles en 1908, et élimine les paradoxes

- second théoreme d'incomplétude: la consistance d'un systéme ne peut pas être établie au moyen de raisonnements qui se laisseraient formaliser dans le systéme.
- la mathématique finiste est formalisable en arithmétique, on ne peut pas l'utiliser pour prouver la consistance de l'arithmétique.

- 1931 ne clot pas les recherches autour du programme formaliste, il reste la décidabilité : Existe-t-il une procédure uniforme, mécanique, capable de décider ...
- Il faut donner une définition formelle à la notion de "procédure mécanique", qui jusque là ne porte que son sens intuitif.
- entre 1934 et 1937, Gödel, Church et Turing vont donner une définition chacun.

- calcul des prédicats :
- "Si Jean chante, il pleut. Jean chante. Par conséquent, il pleut"
- "Jean aime Marie. Par conséquent, quelqu'un aime Marie"
- 1 = (p -> q   p)/q (qui se lit, p implique q, p alors q)
- 2 = (Rab)/(Ex Rxb) (qui se lit, Relation entre ab et b alors il existe x tel que Relation entre x et b)
- 1 = calcul des propositions
- 2 = calcul des prédicats (fait intervenir la structure interne des proposition, via des quatificateur (ici le 'il existe'))
- à lexception de l'analyse, toutes les théories mathématiques sont formalisées à l'aide du calcul des prédicats.
- la 1° formalisation est due à Frege dans 'idéographie' en 1871. Puis modifiés dans principia mathematica (godel utilise celles la), puis aujourd'hui, on utilise celles de H et Ackermann dans "éléments de la logique théorie (1928)"

- théormes d'incomplétude
- 1° théoréme : été 1930
- il fait la différence entre vérité et démontrabilité, et cherche une formule vraie qui n'est pas démontrable
- il communique son résultat dans une lettre à Carnap le 26 aout 1930, puis le présente dans un colloque à Köningsberg (où sont présents Carnap, Heyting et von Neumann)
- Von Neumann est le seul à réaliser l'importance du théorème, et suggére quelques modification à Gödel.
- Von Neumann écrit quelques mois plus tard à Gödel, en disant qu'il à déduit un second théorème à partir du premier. Gödel est arrivé à la même conclusion et a envoyé quelques jours avant un manuscrit à une revue de Vienne, qui publiera en 1931.
- L'article sera présenté comme thése d'habilitation pour Gödel, et sera accepté à 49 contre 1. Gödel pourra enseigner à Vienne à partir de 1933.

- tout language formel, consistant, et suffisamment riche pour exprimer les nombres entiers et les opérations d'addition et de multiplication, permettent de formuler des propositions indécidables.

- un language incomplet peut être complété (en ajoutant les propositions indécidables comme axiomes), ce faisant on crée un nouveau language, encore une fois incomplet. Mais on peut supposer qu'une suite indéfinie de languages forme un édifice complet.

- 1°théoréme: si l'arithmétique élémantaire est ω-consistante, elle comporte des formules fermées qui ne sont ni démontrables, ni réfutables à partir des axiomes.
- arithmétique élémentaire = système d'axiome, exprimé dans le calcul des prédicats, permettant de définir les entiers avec les opérations d'addition et de multiplication.
- formule fermée = formule sans variables libres ( cad, toutes les variables sont liés à un quatificateur "il existe"/"quel que soit")
- ω-consistant = il est impossible de vérifier une propriété P pour chacun des entiers naturels, et de démontrer la formule "il existe un entier ne vérifiant pas P" (c'est une consistance++, qui inclut le tiers exclu)

- 2° théoréme: si l'arithmétique élémentaire est consistante, sa consistance, qui s'exprime par une formule dans le système, ne peut être provée à partir des axiomes.


- J.Rosser en 1936 montre qu'on peut remplacer pour le 1° théoréme la ω-consistante par la simple consistance

- en plus de l'arithmétique élémentaire, ces deux théorèmes fonctionnement pour des systèmes ajoutant un nombre indéfini d'axiomes. Par cela, on s'attend à ce que pour systéme formel, il existe une procédure uniforme, une liste d'instruction à appliquer de façon mécanique, qui puisse reconnaitre les formules.
- il n'existe pas de définition de "procédure mécanique" en 1931. La portée de ces théorème est suspendue à la définition de "procédure mécanique", cad, de "calculabilité"
- une autre question est de savoir s'il existe des formules indécidables parmis les problémes qu'étudient les mathématiciens (la formule de Gödel est ad hoc, et ne signifie rien pour le mathématicien)
- H croit que tout probléme à une solution. Gödel ne renie par cette pensée, il dit juste que certains problémes n'ont pas de solution dans certains systèmes. (un probléme indécidable en arithmétique pourra avoir une solution en théorie des ensembles)

- Godel, 193? : "la conviction dans la décidabilité de tout problème mathématique n'est pas ébranlée par ce résultat".

- les théorèmes remettent aussi en question les autres axiomatisations que l'arithmétique. Puisqu'il est possible de construire des systèmes consistants, mais dont certains axiomes seraient absurde (cad faux, dans un sens classique du terme, mais vrai mathématiquement puisque ce sont des axiomes). Donc, pour justifier une axiomatique, il ne suffit plus de prouver sa consistance, il faut également redonner leurs sens aux formules. On en revient aux discutions épistémologiques de 1910, sur l'existance "en soi" des objets mathématiques.

- deux autres problèmes :
- définition de la calculabilité (dont dépends la généralisation du théoréme d'incomplétude)
- définition de la vérité (avant, la vérité des axiomes était lié à la consistance du système, si le système est syntaxiquement consistant, les axiomes sont vrais, et les formules démontrables sont vraies aussi). Gödel, sur son travail, à commencé par distinguer démontrabilité et vérité. Tarski en 1935 donnera cette définition (le concept de vérité dans les languages formalisés)

- à partir de 1933, Gödel voyage souvent à princeton (il s'y installera en 1939), où il rencontre Church, S.Kleene, et croise Turing.

- le probléme de la calculabilité ressurgit avec le th d'incomplétude & le pb de décidabilité
- le pb de la décidabilité est lié à la calculabilité : pour définir si une formule est démontrable, on traduit cette formule de son sens métamathématique à l'arithmétique (comme godel pour le th d'incomplétude), puis on voit si la fonction qui résulte de cette traduction est oui ou non calculable
- définir la calculabilité = définir un ensemble de fonctions qui disposent d'un algorithme, d'une suite d'instructions que l'on peut suivre pour parvenir au résultat.

- la méthode de diagonalisation semble empêcher la définition de la calculabilité (si on liste toute les fonctions calculables, infini dénombrable donc, on peut créer une nouvelle fonction calculable qui n'est pas dans la liste, donc la définition est mauvaise)
- Keene 1979 : "Lorsque Church me proposa sa thèse [pour une définition de la calculabilité], je me mis aussitôt à la tâche de la réfuter par une diagonalisation de la classe des fonctions [calculables]. Mais, réalisant vite que la diagonalisation ne pouvait être faite de façon effective, je devins du jour au lendemain partisan de la thèse de Church".

- une T-machine peut être représentée par une code, un entier. Mais tous les entiers ne représentent pas une T-machine
- la solution du "le problème de l'arrêt" dit qu'il n'existe pas de T-machine qui peut dire, lorsqu'on lui soumet un code (un entier), si ce code représente une T-machine ou non.
- on peut arriver à ce résultat par la diagonalisation, si il existe une T-machine capable de dire si un code est une T-machine ou pas, on peut, en testant successivement tous les entiers faire la liste des T-machines. Puis on définit une fonction f(n) = (valeur que donne la n-iéme T-machine à n) + 1. la fonction f serait donc calculable, mais pas par une T-machine (puisque f(n) est forcément différent de la valeur que donne la n-iéme T-machine à n).
- comme la définition de "calculable" est "calculable par une T-machine", notre hypothèse de départ est fausse, et il ne peut pas exister de T-machine qui dit, pour un code donné, si ce code correspond à une T-machine.
- donc il existe des fonctions qui ne sont pas calculables
- et comme on peut traduire en arithmétique la proposition P(n) : n est le code d'une T-machine, il existe des problémes qu'une T-machine ne peut pas résoudre, donc l'arithmétique est indécidable.
- Turing retourne en quelque sorte l'argument de la diagonale (qui au départ semblait poser un obstacle à la définition de calculabilité)
- Lancan, 1973, résume dans une boutade : "j'ai trois frères, Jean, Jacques et moi."

- l'article de Turing en 1937 est l'aboutissement d'une série de travaux sur la calculabilité
- Gödel définit une classe de fonctions calculables en 1931, dite "fonctions récursives primitives"
- Mais on connait depuis 1926 une fonction calculable qui n'est pas récursive primitive (dû à Ackermann, un éléve de Hilbert)
- 1934, Church et Godel publient chacun une définition, elles sont équivalentes. Mais la difficulté est de trouver une justification épistémologique, de reconnaitre un sens intuitif à ces définition (Les machines de turing sont directement intuitives)
- Turing prouvera aussi que sa définition est équivalente avec celles de church & godel.

- Turing compare la machine à l'activité cérébrale humaine. lorsqu'on multiplie par exemple, les écritures qu'on réalise en deux dimensions sur une feuille de papier peuvent être reprotées sur une seule dimension, l'action du calculateur est déteriné par le symbole qui se trouve devant lui, et par l'état mental dans lequel il se trouve. L'homme qui calcule agit comme une machine.
- L'humain ne dispose que d'une quantitée finie d'états mentaux.
- Turing, "on computable numbers" 1937: "si nous admettions une infinité d'états d'esprit, certains d'entre eux seraient arbitrairement proches et se confondraient [dans le calcul]"
- si on peut faire des calculs corrects, c'est qu'on ne confonds pas les états d'esprits, donc qu'ils sont finis, comme dans la machine

- machines sans cercles = code correct, la machine arrive à une approximation de plus en plus précise d'un nombre, ou bien s'arrête.
- machines circulaires = code incorrect
- probléme de l'arret = deviner si une machine est circulaire ou pas.
- décidabilité = probleme de l'arret

- avec sa conclusion négative au pb de décidabilité, turing retrouve les résultats de Godel de 1931.
- On dispose d'une machine qui peut lister une à une toutes les formules démontrables de l'arithmétique. Pour savoir si une formule est démontrable, il suffit de laisser tourner cette machine et d'attendre que la machine écrive soit la formule (démontrable) ou son contraire (réfutable).
- Mais si on pouvait faire ça, on aurait du même coup une procédure de décidabilité.
- donc la complétude sémantique implique la décidabilité.
- la réponse négative au pb de décidabilité donne donc une nouvelle démonstration du th de godel

- la nouvelle définition de Turing n'apporte rien de nouveau aux mathématiques (il y a déjà les définitions de church & godel), mais apportent un sens épistémologique. Les définition de church et godel se basaient sur des systèmes formels, dépourvus de sens. La définition de turing se base sur la définition de machine dans le language naturel.
- le contenu épistémologique de church & godel étaient insuffisant.

- Le probléme du fondement se tourne vers la différence entre l'esprit et la machine. Dans l'article de Turing, l'esprit est considéré comme une machine. Mais pour soutenir la thèse de la résolubilité de tout problème mathématique (comme hilbert, et Godel), il faut réussir à distinguer la différence entre la machine et l'esprit. pour cela, il faut montrer un raisonnement qui fait intervenir le sens des symboles, qu'une machine ne pourrait donc pas suivre (car elle évolue uniquement dans la manipulation des symboles, c'est un système formel)

- dans un article de 1939, Turing ajoute un "oracle" à ses machines, qui permet de résoudre des problèmes arithmétique, et dont on peut seulement dire qu'il n'est pas mécanique
- Turing renoncera à l'oracle, mais participe à la recherche de ce qu'il faut rajouter à une machine de Turing, pour en faire un "esprit". L'oracle permet à la machine de se comprendre elle-même (ce qui était impossible avant, puisqu'une machine ne peut pas prédire une autre machine, ou elle-même, donc, ne peut pas se comprendre elle-même)

- Godel reproche à Turing, dans son analogie esprit-machine, de ne pas prendre en compte l'évolution de l'esprit (1972, conversations avec Wang) : "Ce que Turing à négligé [en identifiant l'esprit à une machine], c'est que l'esprit, en pratique, n'est pas statique mais en développement permanent"

- La thése de Turing repose sur deux choses : Le nombre d'états interne du cerveau est limité (par le nombre de neurones dans le cerveau, et les états seraient représenté par les connections entre les neurones, qui sont soit ouvertes soit fermés (il faut que ça soit une valeur discréte))
- et, les états du cerveaux sont un parralélisme avec les états de l'esprit. à chaque état du cerveau correspond un état d'esprit, et un changement dans l'état du cerveau implique un changement dans l'état d'esprit.
- ces théses impliquent que le cerveau est une machine de Turing, et qu'i existe des problèmes indécidables pour l'esprit humain

- Godel pense que l'esprit humain à la possibilité d'un progrés infini. Godel refuse l'hypothése du parralelisme du cerveau : (dans wang, 1972) "ce parallélisme est un préjugé de notre temps".

- Gödel  quitte l'Allemagne en 1939
- été 1937, Gödel établit la consistance de l'hypothése du continu
- Gödel démontre que l'hypothése du continu ne peut pas être réfutée
- Il conjecture qu'elle est indécidable (donc également non démontrable, ça sera prouvé en 1966 par P.Cohen)
- à noter, elle est indécidable par rapport aux axiomes existant dans la théorie des ensembles, il n'est pas dit qu'elle le reste avec de nouveaux axiomes.
- GÖdel pense que l'hypothése du continu est vraie (et sera démontrés avec de nouveaux axiomes)

- Gôdel croit en l'existance en soi des objets mathématiques (en ooposition à l'intuitionnisme, pour lequel un objet existe quand le mathématicien le crée)
- Gödel 1947 : "[...] les concepts et les théorémes de la théorie des ensembles décrivent une réalité bien déterminée, dans laquelle la conjecture de Cantor est vraie ou fausse. Ainsi son indécidabilité à partir des axiomes acceptés aujourd'hui peut seulement signifier que ces axiomes ne contiennent pas une description complète de cette réalité."
- Gödel 1947 : "les mathématiques décrivent une réalité non sensible, qui existe indépendament des actes et des facultés de l'esprit humain et n'est que perçue, et probablement perçue de façon très incomplète."

- Gödel croit comme Hilbert à la résolubilité de tout problème. De mêm, il croit que les mathématiques existent.
- Pointcarré a le même point de vue "constructionniste" que les intuitionnistes, il croit que les objets mathématiques existent une fois qu'ils ont été construits par le mathématicien. D'où son analyse des paradoxes comprenant un cercle vicieux : Pour le paradoxe de Richard par exemple, on contruit un ensemble E, puis on construit un nombre qui appartient à E, mais pour le construire, on fait référence à E. Donc le nombre fait référence ç lui même dans sa construction (== construction imprédicative). Pointcaré veut interdire ce genre de cercle vicieux et uniquement authoriser les construction prédicatives, celles où un objet est crée à partir d'autres objets, de hiérarchie plus faible dans l'ordre de construction.
- Le constructionnisme de Poincaré ne reconnait pas l'existence des objets mathématiques, et donc, ne reconnait pas l'infini actuel, et donc le tiers exclu, etc.
- Mais l'intuitionnisme, qui est aussi constructionniste, posséde des incohérences, puisqu'il a parfois recours à des raisonnements imprédicatifs.
- principe du cercle vicieux, Russell : "Ce qui présuppose tous les éléments d'une collection ne doit pas être l'un des éléments de la collection; ou, sous la forme converse, si, du fait qu'une collection était totalisable, elle contiendrait des éléments qui ne seraient définissables qu'en termes de cette totalisation, alors la dite collection n'est pas totalisable".

- Pour son retour au programme de fondement, Gödel dit qu'on doit justifier les mathématiques avec une théorie plus étendue que le finitisme de H, et donc, justifier épistémologiquement la notion de l'infini. Pour cela, il veut justifier l'existance en soi de l'infini, et par la même, la capacité de l'esprit humain à raisonner dans l'infini.
- Turing comparait l'esprit à une machine, pour Gödel, comme il n'y a pas de problèmes insolubles, et qu'il en existe pour les machines, il faut différencier l'esprit de la machine.
- Godel 1961 "Dans l'établissement systématique des axiomes mathématiques, de nouveaux axiomes, qui ne découlent pas formellement des précédents, deviennent évidents [...]. C'est ce devenir évident de nouveaux axiomes, sur la base du sens des notions primitives, qu'une machine ne peut pas imiter".

- la diagonalisation nous oblige à admettre l'existance des objets mathématiques en soi, ou bien à refuser la proposition dans laquelle il intervient.
- diagolasition apparait chez Cantor en 1891.


===
Church (web)
===

- In 1936, Church created a method for defining functions called the lambda calculus (λ-calculus). Within λ-calculus, he defined an encoding of the natural numbers called the Church numerals. A function on the natural numbers is called λ-computable if the corresponding function on the Church numerals can be represented by a term of the λ-calculus (which is equivalent to using general recursive functions).
- In computability theory, the Church–Turing thesis is a hypothesis ("thesis") about the nature of computable functions. In simple terms, the Church–Turing thesis states that a function on the natural numbers is computable in an informal sense (i.e., computable by a human being using a pencil-and-paper method, ignoring resource limitations) if and only if it is computable by a Turing machine.
- In 1941 Church wrote the monograph The Calculi of Lambda-conversion, which was later useful to others in the development of semantics for programming languages. Today the λ-calculus is a major research topic in theoretical computer science.
- As one of his colleagues remembered, "Church read everything and forgot nothing". When asked what made Church a world-class scholar, he had a remarkably simple answer: "He was just smarter than anybody else."

- Church fait ses études à l'université de Princeton (new jersey, proche de NY)
- Avec son doctorat il reçoit une bourse de recherche nationale11 qu'il utilise pour voyager. Ainsi, durant l'été 1927 il est instructeur à l'Université de Chicago. Il passe deux ans à l'Université Harvard (1927-1928), puis se rend à l'Université de Göttingen où il rencontre David Hilbert et Paul Bernays puis à l'Université d'Amsterdam où il rencontre Luitzen Egbertus Jan Brouwer (1928-1929)
- Princeton dans les années 1930, est un lieu propice aux échanges en logique car John von Neumann s'y trouve, ainsi que trois étudiants brillants de Church, Stephen Kleene, John Barkley Rosser et Alan Turing. Kurt Gödel, après plusieurs déplacements à l'Institute for Advanced Study entre 1933 et 1935, y donne plusieurs conférences sur son théorème d'incomplétude, et s'y installe définitivement vers 1940.
- Les travaux de son équipe (Church, Kleene et Rosser) précèdent, sur le problème de l'arrêt, le travail d'Alan Turing, qui va d'ailleurs les rejoindre. C'est Church qui, le premier, a l'idée que l'on peut définir le concept de fonction calculable dans un sens très large, cette idée avait déjà été entrevue par Herbrand, mais sa mort prématurée ne lui avait pas permis de la pousser plus loin. Church en a eu l'idée par le lambda-calcul. Church démontre en 1936 l'existence d'un problème insoluble par algorithme, autrement qui ne peut pas être résolu par un calcul mécanisable.

- After graduating from Ridgefield in 1920, Church attended Princeton University where he was an exceptional student, publishing his first paper, on Lorentz transformations, and graduating in 1924 with a degree in mathematics. He stayed at Princeton, earning a Ph.D. in mathematics in three years under Oswald Veblen.
- He taught philosophy and mathematics at Princeton, 1929–1967
- The lambda calculus emerged in his 1936 paper showing the unsolvability of the Entscheidungsproblem. This result preceded Alan Turing's work on the halting problem, which also demonstrated the existence of a problem unsolvable by mechanical means. Church and Turing then showed that the lambda calculus and the Turing machine used in Turing's halting problem were equivalent in capabilities, and subsequently demonstrated a variety of alternative "mechanical processes for computation." This resulted in the Church–Turing thesis.
- The lambda calculus influenced the design of the LISP programming language and functional programming languages in general. The Church encoding is named in his honor.

- L'idée de base du lambda-calcul est que tout est fonction. Une fonction est en particulier exprimée par une expression qui peut contenir des fonctions qui ne sont pas encore définies et qui sont alors remplacées par des variables. Il y a donc, parmi les expressions du lambda-calcul, des expressions qui contiennent des variables. Que peut-on faire avec les fonctions ? On peut les « appliquer » à des valeurs qui sont elles-mêmes des fonctions, puisque tout est fonction. On a donc une opération de base, que l'on appelle « application ». Appliquer l'expression A  (qui décrit une fonction) à l'expression B  (qui décrit une fonction) se note A.B .
- Sur cette base, on peut construire quelques fonctions intéressantes, comme la fonction identité I , qui est la fonction qui à x  fait correspondre x , autrement dit la fonction λx.x . On peut aussi construire les fonctions constantes égales à x , à savoir λy.x . De là on peut construire la fonction qui fabrique les fonctions constantes, pourvu qu'on lui donne la constante comme paramètre, autrement dit la fonction λx.(λy.x)} , c'est-à-dire la fonction qui à x  fait correspondre la fonction constamment égale à x .
- L'idée du lambda-calcul consiste à fournir un langage précis pour décrire les fonctions et les simplifier.
- Le calcul associé à un lambda-terme est la suite de réductions qu'il engendre. Le terme est la description du calcul et la forme normale du terme10 (si elle existe) en est le résultat. Un lambda-terme t est dit en forme normale si aucune bêta-contraction ne peut lui être appliquée, c'est-à-dire si t ne contient aucun rédex, ou encore s'il n'existe aucun lambda-terme u tel que t → u.

- Lambda calculus (also written as λ-calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution. It was first introduced by mathematician Alonzo Church in the 1930s as part of an investigation into the foundations of mathematics.
The lambda calculus was introduced by mathematician Alonzo Church in the 1930s as part of an investigation into the foundations of mathematics.[7][8] The original system was shown to be logically inconsistent in 1935 when Stephen Kleene and J. B. Rosser developed the Kleene–Rosser paradox. Subsequently, in 1936 Church isolated and published just the portion relevant to computation, what is now called the untyped lambda calculus.[9] In 1940, he also introduced a computationally weaker, but logically consistent system, known as the simply typed lambda calculus.[10]
- Computable functions are a fundamental concept within computer science and mathematics. The λ-calculus provides a simple semantics for computation, enabling properties of computation to be studied formally. The λ-calculus incorporates two simplifications that make this semantics simple. The first simplification is that the λ-calculus treats functions "anonymously", without giving them explicit names. The second simplification is that the λ-calculus only uses functions of a single input (currying).
- exemple : square_sum(x, y) => x*x + y*x
- becomes : (x, y) => x*x + y*y
- and then : x => (y => x*x + y*y)
- à l'appel : ((x => (y => x*x + y*y))(5))(2) - (y => 2*2 + y*y)(5) - 29

- A function F: N → N of natural numbers is a computable function if and only if there exists a lambda expression f such that for every pair of x, y in N, F(x)=y if and only if f x =β y,  where x and y are the Church numerals corresponding to x and y, respectively and =β meaning equivalence with beta reduction. This is one of the many ways to define computability
- There is no algorithm that takes as input two lambda expressions and outputs TRUE or FALSE depending on whether or not the two expressions are equivalent. This was historically the first problem for which undecidability could be proven. As is common for a proof of undecidability, the proof shows that no computable function can decide the equivalence. Church's thesis is then invoked to show that no algorithm can do so.
- Church's proof first reduces the problem to determining whether a given lambda expression has a normal form. A normal form is an equivalent expression that cannot be reduced any further under the rules imposed by the form. Then he assumes that this predicate is computable, and can hence be expressed in lambda calculus. Building on earlier work by Kleene and constructing a Gödel numbering for lambda expressions, he constructs a lambda expression e that closely follows the proof of Gödel's first incompleteness theorem. If e is applied to its own Gödel number, a contradiction results.

- Bien que Church soit sans nul doute le premier, au début des années 1930, à avoir pensé pouvoir définir formellement la calculabilité intuitive (par la λ-définissabilité)3, c'est cependant l'article d'Alan Turing de 1936 et son modèle mécanique de calculabilité, qui ont définitivement emporté l'adhésion, selon Gödel, Kleene et Church lui-même.

- La thèse de Church-Turing dit juste que ces définitions de calculabilités sont des bonnes définitions. C'est plus une hypothése qu'une thése (elle n'a pas été démontrée). Tout ce qui peut être calculé par une "procédure effective" peut être calculé par un lambda calcul, une machine de Turing, ...

- In 1933, Austrian-American mathematician Kurt Gödel, with Jacques Herbrand, created a formal definition of a class called general recursive functions. The class of general recursive functions is the smallest class of functions (possibly with more than one argument) which includes all constant functions, projections, the successor function, and which is closed under function composition and recursion.
- In 1936, Alonzo Church created a method for defining functions called the λ-calculus. Within λ-calculus, he defined an encoding of the natural numbers called the Church numerals. A function on the natural numbers is called λ-computable if the corresponding function on the Church numerals can be represented by a term of the λ-calculus.
- Also in 1936, before learning of Church's work, Alan Turing created a theoretical model for machines, now called Turing machines, that could carry out calculations from inputs by manipulating symbols on a tape. Given a suitable encoding of the natural numbers as sequences of symbols, a function on the natural numbers is called Turing computable if some Turing machine computes the corresponding function on encoded natural numbers.
- Church[2] and Turing[3] proved that these three formally defined classes of computable functions coincide: a function is λ-computable if and only if it is Turing computable if and only if it is general recursive. This has led mathematicians and computer scientists to believe that the concept of computability is accurately characterized by these three equivalent processes.

- Turing, 1939, Systems of Logic Based on Ordinals, " We shall use the expression 'computable function' to mean a function calculable by a machine, and let 'effectively calculable' refer to the intuitive idea without particular identification with any one of these definitions."
- Same "It was stated ... that 'a function is effectively calculable if its values can be found by some purely mechanical process.' We may take this literally, understanding that by a purely mechanical process one which could be carried out by a machine. The development ... leads to ... an identification of computability† with effective calculability."

- The debate began when Church proposed to Gödel that one should define the "effectively computable" functions as the λ-definable functions. Gödel, however, was not convinced and called the proposal "thoroughly unsatisfactory".[12] Rather, in correspondence with Church (ca 1934–5), Gödel proposed axiomatizing the notion of "effective calculability"; indeed, in a 1935 letter to Kleene, Church reported that: "His [Gödel's] only idea at the time was that it might be possible, in terms of effective calculability as an undefined notion, to state a set of axioms which would embody the generally accepted properties of this notion, and to do something on that basis"
- Gödel said that "he was, at the time of these [1934] lectures, not at all convinced that his concept of recursion comprised all possible recursions".[16] By 1963–4 Gödel would disavow Herbrand–Gödel recursion and the λ-calculus in favor of the Turing machine as the definition of "algorithm" or "mechanical procedure" or "formal system"
- Church was quick to recognise how compelling Turing's analysis was. In his review of Turing's paper[24] he made clear that Turing's notion made "the identification with effectiveness in the ordinary (not explicitly defined) sense evident immediately".
