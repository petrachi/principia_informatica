Alors aujourd'hui, on va parler de l’histoire de l’informatique, des années pionnières de l’informatique, et donc on va parler de tous ces personnages, de tous ces inventeurs qui ont participé à l’élaboration des premières machines. On parlera bien entendu d’Alan Turing, de John Von Neumann, de Mauchly, Eckert, Williams, Kilburn, il y aura Max Newman, et quelques autres encore que je n’ai pas le temps de citer ici. 

Mais juste avant de commencer, en guise d’introduction, j'aimerais vous répéter ce que m'a dit Jean Lassègue, qui a publié un livre sur Alan Turing aux éditions Les belles lettres, et qui me disait : l'histoire de l'ordinateur peut-être soit vue d'un point de vue théorique. C’est à dire que les premiers ordinateurs seraient le fruit d'une réflexion très théorique menée principalement par Turing et Von Neumann. Soit, l'autre version de la même histoire, c'est de considérer qu'il s'agit essentiellement d'une affaire d'ingénierie, c’est à dire la mise ou point et la perfection de machines calculantes.

Alors vous avez bien compris, on a d’un côté on a la théorie, et de l’autre la pratique. Alors on va explorer ces deux points de vue, et pour commencer, je vous propose de remonter dans les années 1880 pour se placer d’abord du point de vue théorique de cette histoire, que nous allons voir à travers le travail de David Hilbert et de sa participation à ce que j’appellerais la grande quête scientifique du début du 20ème siècle, c’est la quête du fondement mathématique.

Donc David Hilbert, on l’a bien compris, c’est un mathématicien, mais c’est un mathématicien allemand, il a fait ses études à l’université de Köningsberg, qui est l’une des universités les plus réputés du pays, et il a fait là bas deux rencontres qui vont être importantes pour sa carrière de mathématicien, puisque c’est en discutant avec Adolf Hurwitz, qui est un de ses professeurs à l’université, et avec Hermann Minkowski, un autre étudiant, que la carrière de Hilbert va prendre la direction que l’on connaît aujourd’hui, et que je m’apprête à vous raconter.

Alors, on a un témoignage direct de Hilbert qui nous raconte cette époque à Köningsberg : "Ainsi, alors que j'étais encore étudiant, j'ai été poussé par Hurwitz au coeur des débats scientifiques et j'ai eu la chance, en étant avec lui, d'apprendre à connaître, d'une façon plaisante, les deux écoles opposées mais parfaitement complémentaires, l'école géométrique de Klein et l'école algébrique-analytique de Berlin. Lorsqu'il revenait dans sa famille à Köningsberg, le génial Minkowski, avec qui je m'étais déjà lié, se joignait à nous. Au cours de ces innombrables promenades, jour après jour, pendant huit années, nous avons fouillé tous les coins du savoir mathématique."

Il passe donc huit ans à Köningsberg, d’abord, quatre ans d’études, il est diplômé en 1885, et puis, sous l’impulsion d’Hurwitz, il va voyager afin de rencontrer certains grands mathématiciens de son époque, il ira voir Felix Klein, Henri Poincaré à Paris, Kronecker à Berlin. Après un an de voyages, il retourne à l’université de Köningsberg afin d’obtenir son habilitation d’enseignant, il devient donc « Privatdozen », ce qui en français peut se traduire par « Assistant », et qui est un poste de préambule à celui de professeur.

Le « Privatdozen » peut enseigner mais ne touche pas de rémunération fixe, à la place il est directement payé par les élèves qui choisissent d'assister à ses cours, puisque, il faut le rappeler, il ‘y a pas à l’université de classes imposés. Les étudiants sont laissés totalement libres de faire ce qu’ils veulent, d’assister aux classes qu’ils choisissent pendant les quatre ans de cursus, jusqu’au seul et unique l’examen final.

Alors ce statut de « Privatdozen », qui n’est pas très confortable d’un point de vue financier, laisse cependant suffisamment de temps libre, assez en tout cas pour permettre à Hilbert de démarrer un travail de recherche, et en particulier, il va s’intéresser à la théorie des invariants qui depuis vingt ans est au point mort.

Le problème principal de la théorie des invariants, c'est d’identifier certaines propriétés, qui sont invariantes, pour des formes qui évoluent dans des espaces à plusieurs dimensions. 

Alors, bien entendu, quand on parle de théorie des invariants, on ne peux pas ne pas citer Gordan, puisque c’est Gordan, surnommé le « roi de la théorie des invariants », qui en 1869 à démontré que l'anneau des invariants des polynômes homogènes à deux variables de degré fixé est de type fini.

En clair, il à résolu le problème des invariants pour un espace en deux dimensions. Mais ce résultat de Gordan est aussi le principal obstacle de la théorie des invariants, puisque la méthode de Gordan nécessite des calculs qui sont d’une grande complexité, et qui est impossible à étendre à un nombre plus important de variables. Comprenez, pour les espaces à trois dimensions, quatre dimensions et plus, la méthode de Gordan est inutilisable.

Alors Hilbert, qui s'attaque à ce problème, va modifier son point de vue et va appliquer ce qu’on appelle en mathématique la méthode abstraite. Plutôt que de calculer, Hilbert va étudier les relations entre les différents objets mathématiques, et il va démontrer, à partir de cette étude, qu’il existe une famille génératrice de forme.

Le problème des invariants est donc presque résolu puisque les propriétés invariantes sont les propriétés de la famille génératrice dont Hilbert vient de montrer l’existence, et donc, si on peut calculer la famille génératrice, on aura du même coup les propriétés invariantes. Hélas, Hilbert ne sait pas encore comment calculer cette famille génératrice de formes.

Alors il va tout de même publier ses premiers résultats dans un article intitulé "De la théorie des formes algébriques", on est là en 1890, et Gordan, qui est sans doute un peu perplexe devant cette absence totale de calcul commentera : "Ce n'est pas des mathématiques, c'est de la théologie". 

Pourtant, Hilbert, qui ne va pas s’arrêter là, continue à travailler sur ce problème et trois ans plus tard, il publie à nouveau, et cette fois, il fournit une méthode pour calculer cette fameuse famille génératrice de forme. Gordan sera alors abrogé d’admettre : "La théologie à parfois ses mérites".

De son côté, Hilbert écrit à Minkowski, il lui dit : "Je quitte maintenant le domaine des invariants définitivement et je ne m'occuperais plus que de théorie des nombres". C'est aussi parce que l'association des mathématiciens Allemands vient de lui demander un rapport sur la théorie des nombres algébriques, puisque Kummer et Kronecker, qui sont les deux grandes figures du domaine, n’ont que peu publiés leurs travaux. 

L’ouvrage sera finalement édité en 1897, et, pour la petite histoire, deviendra plus tard l’ouvrage de référence dans les années 1920 pour les travaux d'Emmy Noether, la première femme à enseigner dans une université allemande.

Mais un autre événement à la même époque, bien plus important dans la carrière de Hilbert, c’est sa nomination en 1895 au poste prestigieux de professeur ordinaire à l’université de Göttingen, sur la recommandation de Felix Klein. C’est un grand honneur pour Hilbert, et un tournant majeur dans la vie mathématique de l’époque puisque, forte de l’influence de Klein, de Hilbert, et un peu plus tard de Minkowski, qui arrivera à Göttingen en 1902, à la recommandation de Hilbert, que l’université va se transformer pour devenir un centre incontournable, on dit c’était comme si la ville toute entière s’était dédié au savoir mathématique, au point d’en devenir la capitale mondiale.

Alors on se doute bien qu’une université qui jouit d’une telle réputation attire de nombreux étudiants; parmi eux, Hermann Weyl, qui va écrire en 1944 : "J'entends toujours la flûte douce de Hilbert nous séduisant pour nous conduire dans la rivière profonde des mathématiques [...] Les portes d'un monde nouveau s'ouvraient devant moi et je n'étais pas là depuis longtemps que déjà la résolution s'était formé dans mon jeune coeur de lire tout ce que cet homme avait écrit."

À Göttingen, Hilbert va préparer un cours de géométrie, ou plutôt, un cours sur sa nouvelle axiomatisation de la géométrie, puisque c’est, après les nombres algébriques, son nouveau domaine de recherche, peut-être d’ailleurs inspiré par l’influence de Klein. Je dis peut-être parce que je n’ai n’ai aucun document pour le prouver mais on sait très bien que Klein était très attaché à la géométrie.

Alors un mot peut-être sur l’axiomatique d’abord. Il faut remonter dans l’antiquité, en 300 avant notre ère, à l’époque d’Euclide qui, dans un livre intitulé « Les Éléments », va établir un ensemble de règles pour décrire ce qu’il est juste de faire et ce qui est interdit quand on fait de la géométrie. Ces règles, c’est ce qu’on appelle les « axiomes », et l’ensemble de ces règles, c’est « l’axiomatique ».

Depuis Euclide, l’axiomatique s’est étendue à touts les domaines des mathématiques, chaque branche possède sa propre axiomatique, qui définit les différentes notions mathématiques, et comment nous pouvons les utiliser.

Il faut préciser que les axiomes, les règles de base, sont les propositions mathématiques les plus importantes, puisque les axiomes représentent tout ce qui est « vrai », et il n’y a que la vérité inscrite dans les axiomes qu’il nous est possible d’utiliser au cours d’une démonstration ou d’un raisonnement mathématique. Tous les théorèmes reposent sur les axiomes et uniquement sur les axiomes. 

Alors il faut faire extrêmement attention, pour celui qui propose une axiomatique, de choisir des axiomes qui soient suffisamment évident, et qu’ils ne soient pas contradictoires, puisqu’il faudra ensuite pouvoir convaincre le reste de la communauté des mathématiciens.

Et justement, l’axiomatisation de la géométrie d’Euclide ne convainc plus, on lui reproche un manque d’axiomes. On se retrouve parfois dans un cas où il manque des axiomes pour compléter la démonstration.

Je vous propose un exemple pour mieux comprendre le problème : Imaginez d’abord une maison, pas très grande, et à côté de la maison, une tour de plusieurs étages. Il est évident à l’observateur que la tour est plus grande que la maison. Pour le démontrer mathématiquement, il faudrait mesurer la taille des deux bâtiments. La maison fait 18m, la tour en fait 150, il suffit ensuite de comparer ces deux nombres pour se rendre compte que 150 est plus grand que 18. On a la preuve mathématique que la tour est plus grande que la maison.

Mais comprenez bien que pour comparer 150 et 18, nous avons utilisé l’algèbre, et il y a une axiomatique à l’algèbre, et dans cette axiomatique, il y a un axiome en particulier qui nous permet de comparer deux nombres entre eux. Si cet axiome n’existait pas, la preuve mathématique que nous venons de faire aurait été impossible, même s’il serait toujours aussi évident que l’un des deux bâtiments est plus grand que l’autre.

Et c’est bien ça qu’on reproche à l’axiomatisation d’Euclide, il n’y a pas suffisamment d’axiomes pour prouver mathématiquement tout ce qu’on voudrait pouvoir prouver, et c’est ce problème que Hilbert va chercher à résoudre, en proposant une nouvelle axiomatisation de la géométrie, avec l’aide de la méthode abstraite, comme il avait fait pour la problème des invariants.

L’idée de la méthode abstraite, c’est de distancer les notions mathématiques par rapport au sens usuel, au sens courant. Si je sais par exemple que « Socrates est un homme » et que « Tous les hommes sont mortels », je peux en tirer la conclusion logique que « Socrates est mortel ». Mais le nom « Socrates », qui est utilisé dans les deux propositions de départ, qui font figures d’axiomes, ce nom fait aussi référence à un personnage historique. Alors je pourrais dire que, puisque Socrates est un homme, alors Socrates est un philosophe grec, mais cette conclusion n’est plus le fruit d’une déduction logique tiré uniquement des axiomes, mais plutôt de mon expérience des livres d’histoires. 

La méthode abstraite permet d’éviter ce genre de dérives dangereuses dans le raisonnement mathématique, en ne donnant aucun sens aux notions mathématiques. Plutôt que « Socrates est un homme » et « Tous les hommes sont mortels », on aurait : « X est un A », « Tous les A sont des P », desquels on pourrait déduire que « X est un P ».

Et c’est cette démarche que Hilbert va appliquer à la géométrie, et qui est d’ailleurs est particulièrement bien illustrée par cette petite anecdote. On a Hilbert qui est assis à la terrasse d'un café avec ses étudiants, et qui il leur dit : "L'on devrait pouvoir parler en géométrie de tables, de chaises et de chopes de bière, au lieu de points, de droites et de plan".

Alors vous voyez que, dans l’esprit d’Hilbert, les notions classiques de droites, de points et de plans sont assez superflues.

Le cours de géométrie qu'il donne d'ailleurs ne les mentionne que dans son introduction : "Nous pensons trois systèmes différents de choses. Nous nommons les choses du premier système des points [...]. Nous nommons droites les choses du deuxièmes système [...]. Nous appelons plans les choses du troisième système. [...]. Entre les points, les droites et les plans, nous imaginons certaines relations que nous exprimons par des expressions telles que "être sur", "entre", "congruent". La description exacte et appropriée au but des mathématiques de ces relations est donnée par les axiomes de la géométrie".

Après l’axiomatisation de la géométrie, Hilbert s’attaque de 1901 jusqu’en 1908 à l’axiomatisation de l’analyse, et c’est au cours de ces travaux qu’il va développer ce que lui appelle la "théorie spectrale", mais qui est aujourd’hui connue plus simplement comme la "théorie des espace de Hilbert".

Ces travaux, qui offrent de nouvelle méthodes pour résoudre des équations intégrales, vont êtres au centre des travaux de physiciens dont les noms vous serons peut-être connus, Schrödinger, Bohr, Heisenberg; Heisenberg d’ailleurs qui dira : "Indirectement, Hilbert exerça la plus grande influence sur le développement de la physique [...] Les méthodes mathématiques de la mécanique quantique sont une application directe de la théorie hilbertienne des équations intégrales".

——

Je vous avait dit la dernière fois que lorsqu’on travaille à une axiomatisation, le plus difficile finalement c’est de convaincre. Et la méthode la plus efficace pour convaincre, c’est de fournir une preuve de consistance des axiomes, c’est à dire la preuve formelle que les axiomes ne sont pas contradictoires. 

Ce qu’on fait en général, et ça sera le cas pour l’axiomatique de la géométrie, et celle de l’analyse de Hilbert, c’est qu’on construit cette preuve par analogie. Il faut réussir à exprimer les axiomes dans une forme algébrique.

L’idée est que la théorie des nombres algébriques est le domaine le plus fiable des mathématiques. Alors si les axiomes de la géométrie de Hilbert par exemple, étaient contradictoires, une fois exprimés sous forme algébrique, cette contradiction s’étendrait à l’algèbre. Mais l’algèbre est sûre et peu contestable, alors cela suffit à convaincre le reste de la communauté mathématique.

Mais des paradoxes qui vont émerger en théorie des ensembles vont remettre en cause cette méthode. La théorie des ensembles est une théorie assez récente pour l’époque dont je vous parle puisque elle à été développé à partir de 1873 et jusqu’en 1897 par Georg Cantor, qui va d’ailleurs parvenir, à l’aide des ensembles, à des conclusions qui sont très surprenantes, même si le raisonnement de Cantor reste parfaitement logique. Par exemple il va montrer qu’il existe des infinis plus grands que d’autres.

Alors afin de comparer la « taille » de différents ensembles, on dispose de la notion de « cardinalité », un ensemble de trois pommes par exemple aura une cardinalité de 3. Et un ensemble de trois ballons aura également une cardinalité de 3. 

Alors on peut associer la pomme verte au ballon de foot, la pomme rouge au ballon de basket et la pomme jaune au ballon de rugby. Ainsi, chaque élément des deux ensembles est associé à un et un seul élément de l’autre ensemble, c’est ce qu’on appelle en mathématique une correspondance bi-univoque, et on peut en conclure que les deux ensembles possèdent la même cardinalité, donc, qu’ils sont de même taille.

Et c’est en comparant différents ensembles, mais des ensembles infinis cette fois, que Cantor s’est aperçu qu’il y en avait certains qui étaient plus grands que d’autres. Alors attention, tout cela peut paraître assez évident, après tout, si on prends un exemple simple, n’y a t’il pas plus des nombres entiers que de nombres entiers pairs ? D’instinct, on pourrait penser qu’il y a environ deux fois plus de nombre entiers qu’il n’y en as de nombres pairs, mais ce serait une erreur puisqu’on ne peux pas réfléchir avec l’infini comme on réfléchit avec des un ensemble fini.

D’ailleurs, je vous propose une petite expérience pour essayer de vous convaincre. Vous me donnez un nombre entiers, et je vous donne un nombre pairs. Si vous me donnez « 1 », je vous donne « 2 », si vous donnez « 2 » je donne « 4 », vous donnez « 3 » je donne « 6 », « 4 » je donne « 8 », « 5 » je donne « 10 », « 6 » je donne « 12 ». Et on pourrait continuer comme ça à l’infini. Vous ne serez jamais à court de nombres entiers, mais, de la même façon je ne serais jamais à court non plus de nombres pairs.

Ce qu’on vient de faire, en réalité, c’est une correspondance bi-univoque entre l’ensemble des nombres entiers et celui des nombres pairs, puisqu’on peut associer à chaque nombre entier « x », le nombre pair « x*2 ». Ces deux ensembles ont donc la même cardinalité, puisqu’on peut faire une correspondance bi-univoque, et on peux dire, la même taille. Il y a autant de nombres entiers que de nombres pairs, une infinité.

Par contre, Cantor va montrer que tous les ensembles infinis ne se valent pas, en particulier il va montrer qu’il y a plus de nombres réels, c’est à dire les nombres à virgules, que de nombres entiers. Et il va le montrer à l’aide d’une méthode qui sera réutilisée ensuite par de nombreux mathématiciens, c’est la méthode de « diagonalisation ». 

Pour commencer, Cantor imagine que les deux ensembles sont de même taille, donc on peut faire une association un à un de tous leurs éléments. Le nombre « 1 » peut être par exemple associé à « 0,0145078304… », en dessous de lui, le nombre « 2 » serait associé à « 0,8350927655… », le « 3 » à « 0,0000345081… », et ainsi de suite pour tous les nombres entiers et réels.

Mais Cantor va montrer que dans cette liste, qui devrait logiquement contenir tous les nombres entiers et tous les nombres réels, il manque au moins un nombre réel. Si on prends le chiffre à la première position du premier nombre réel, puis celui à la seconde position du second nombre réel, celui à la troisième position du troisième réel, et ainsi de suite pour tous les nombres réels de la liste, et qu’on modifie chacun de ces nombres en suivant une règle simple : « si c’est un 0, il devient un 1, et si ça n’est pas un 0, il devient un 0 », alors on obtient un nouveau nombre réel qui n’était pas déjà inclus dans la liste, c’est la diagonalisation.

Pourquoi je vous dis qu’il n’était pas déjà inclus dans la liste ? Tout simplement parce que ça ne peut pas être le premier nombre, puisque le chiffre à la première position est différent. Ça n’est pas non plus le second nombre puisque le chiffre à la seconde position est différent, c’’est pas le troisième, ni le quatrième, ni le cinquième, ni le sixième, ni, finalement, aucun des nombres de la liste.

Mais si il existe, puisqu’on vient de le trouver, un nombre réel qui n’était pas déjà dans la liste, ça veut donc dire, d’abord que les deux ensembles n’ont pas la même cardinalité, mais aussi qu’il y a plus de nombres réels que de nombres entiers.

L’infini des nombres réels est donc « plus grand », puisqu’il possède plus d’éléments que l’infini des nombres entiers. Et ça, je vous avoue que c’est une idée que je ne sais pas vraiment comment qualifier. L’infini, c’est déjà une notion assez particulière à s’imaginer, puisque finalement, autour de nous, dans notre vécu, dans notre expérience, rien n’est infini. Mais alors, dire qu’il existe un infini plus grand que l’infini … 

Alors c’est justement pour étudier plus encore les différentes « tailles » d’infinis que Cantor va ajouter à la théorie des ensembles ce qu’il appelle les nombres ordinaux, qui servent à décrire à la fois la taille d’une ensemble, mais aussi l'ordre de ses éléments. Ainsi, à chaque ensemble ordonné, à chaque suite d’éléments, corresponds un nombre ordinal.  Et c’est à ce moment là qu’un mathématicien italien, Cesare Burali-Forti, va déceler un problème en 1897, avec les nombres ordinaux. 

Burali-Forti cherche à calculer le nombre ordinal associé à la suite de tous les nombres ordinaux. Problème, dés qu’il calcule ce nombre ordinal, la suite de tous les nombres ordinaux, qui sert de base au calcul, n’est plus la suite de tous les nombres ordinaux, puisqu’il en manque un, celui qu’on vient de calculer. Donc le nouveau nombre ordinal ne représente finalement pas tous les nombres ordinaux mais seulement tous ceux qui le précédent.

Et c’est là le paradoxe : N’importe quelle suite d’éléments devrait être associé à un nombre ordinal, et pourtant, il y ne peut pas exister de nombre ordinal pour la suite des nombres ordinaux. Alors c’est un premier problème.

Ensuite, en 1902, quelques années plus tard donc, c’est Bertrand Russell qui va mettre à jour un second paradoxe, il va dire : l'ensemble des cuillères à thé n'est pas lui-même une cuillère à thé, il ne s'appartient donc pas à lui-même, il ne correspond pas à sa propre définition. Par contre, on peut réfléchir à l'ensemble de tous les ensembles qui ne s'appartiennent pas à eux-mêmes. Est-ce que cet exemple là s’appartient à lui-même ou pas ?

Au fond, il n’y a que deux possibilités, soit, il s'appartient à lui-même, dans ce cas il devrait correspondrait à sa propre définition, c’est à dire qu’il ne s’appartient pas à lui-même. Donc s’il s’appartient à lui-même, il ne s’appartient pas à lui-même, mais c’est impossible, donc il doit probablement ne pas s’appartenir à lui-même. Mais s'il ne s'appartient pas à lui-même, alors il mérite de faire partie de l’ensemble des ensembles qui ne s'appartiennent pas à eux-mêmes, et alors, il s'appartiendrait à lui-même.

Dans son élan, Russell va appliquer la même logique à l'ordre des concepts. "Être vert" est un concept, on peut dire qu'une pomme "est verte", mais "être vert" n'est pas vert lui-même, il ne s'applique donc pas à lui-même. C’est ce qu’on appelle un concept hétérologique.

Mais l’hétérologie est-elle elle-même hétérologique ? Si oui, alors le concept s’appliquerait à lui-même et ne serait donc pas hétérologique, mais s’il n’est pas hétérologique, alors, comme il ne s’applique pas à lui-même, il est hétérologique. C’est le serpent qui se mords la queue.

Hilbert de son côté n'est pas surpris par les réflexions de Russell. Dans une lettre à Frege, il raconte qu’un autre mathématicien est lui aussi est arrivé à la même conclusion que Russell, et que le paradoxe est déjà connu à Göttingen depuis au moins trois ou quatre ans.

C’est finalement Antoine Richard en 1905 qui va mettre à jour le dernier paradoxe de la série. Il commence par faire la liste de tous les nombres définis en moins de mille mots, puis, en empruntant la méthode de diagonalisation de Cantor, il trouve un nombre qui n’est pas déjà inclus dans la liste. Mais c’est un problème puisque la méthode de diagonalisation s’explique en moins de mille mots, donc le nombre révélé est définissable en moins de milles mots et devrait déjà être dans la liste.

Alors, on pourrait penser que le problème, finalement, c’est la théorie des ensembles, qui n’est pas très correcte, mais souvenez vous que la consistance de la théorie des ensembles repose, comme le reste des branches des mathématiques sur la consistance présumée de l’arithmétique. Alors les paradoxes trouvés en théorie des ensemble se répercutent donc sur l’arithmétique, et finalement sur l’ensemble de toutes les mathématiques.

Alors c’est un gros problème auquel vont devoir faire face maintenant les mathématiciens, puisqu’il va falloir fixer l’arithmétique et l’algèbre, refaire une nouvelle axiomatique afin de faire disparaitre les paradoxes déjà connus, et de donner une preuve de consistance de ces axiomes, afin de se prévenir contre l’apparition de nouveaux problèmes. Seulement, avant, les preuves de consistances étaient produite par analogie avec l’arithmétique et l’algèbre, et c’est une méthode qu’on ne pourra pas utiliser pour l’arithmétique elle-même. Et personne à ce moment là n’a la moindre idée de comment faire une preuve de consistance qui ne reposerait pas sur l’arithmétique et l’algèbre, alors ça sera le début de ce qu’on a appelé la quête du fondement.

——

Je vous ai dit le dernière fois que le problème maintenant, c’était de trouver un fondement solide aux mathématiques, et ce fondement repose sur une preuve de consistance des axiomes de l’arithmétique. D’ailleurs, Hilbert s'était déjà exprimé sur la nécessité de cette preuve de consistance, c’était en 1900 au congrès international des mathématiciens à Paris.

Hilbert devait y donner une conférence, un exposé général sur les mathématiques, mais c'est Minkowski, son ami de Köningsberg qui va lui donner une autre idée. Il écrit à Hilbert le 5 janvier 1900 : "Il serait intéressant de regarder dans le futur et de faire une liste des problèmes sur lesquels les mathématiciens travaillerons dans le siècle qui vient. Avec un tel sujet, on parlera encore de ton exposé dans plusieurs décennies".

L’histoire, bien entendu, lui donnera raison, et Hilbert présentera finalement une liste de 23 problèmes qui vont occuper la quasi-totalité de la recherche mathématique pendant la première moitié du 20ème siècle, et d’ailleurs, il reste encore aujourd'hui, quelques problèmes de cette liste qui ne sont toujours pas résolus.

Mais en particulier, j’aimerais vous lire le second problème de la liste, qui fait figure de précurseur à la quête du fondement, le problème est le suivant : "Peut-on prouver la cohérence de l'arithmétique ? En d'autres termes, peut-on démontrer que les axiomes de l'arithmétique ne sont pas contradictoires ?".

Hilbert va s’intéresser personnellement à ce problème et en 1904, il tente, dans le cadre d'une conférence intitulée "Sur les fondements de la logique et de l'arithmétique", une preuve de consistance, non pas pour l’arithmétique mais pour un système minimaliste d'axiomes qui ne représente que les nombres entiers, et la notion d'égalité. Cette démonstration va être critiquée par Henri Poincaré, mais il faut dire que les deux hommes ne partagent pas les même convictions par rapport aux mathématiques.

De son côté, Hilbert estime que les objets mathématiques, les nombres par exemple, existent, qu’ils sont réels. Un nombre, n’importe lequel, existe, même si personne ne l’a jamais écrit, même si personne ne l’a jamais calculé, ce nombre, et tous les autres nombres, les fonctions, les droites, les vecteurs, tout cela existe indépendamment des mathématiciens. Pour Poincaré par contre, c’est l’inverse, pour lui les nombres sont construits par les mathématiciens, un nombre n’existe qu’une fois que le mathématicien l’a calculé, ou définit.

Mais ce qu’il faut bien comprendre c’est que ces deux points de vue ont une grande influence sur la façon de faire des mathématiques. Pour Poincaré par exemple, on ne peux pas parler d'infini. Comme les nombres n'existent pas, il est impossible d’imaginer l’ensemble de tous les nombres, ou même, l’ensemble de tous les ensemble, comme dans le paradoxe de Russell.

Pour répondre au problèmes que posent les paradoxes, Poincaré prône le constructivisme. Pour le paradoxe de Richard par exemple, le dernier des trois, le paradoxes existe simplement parce que Richard fait une mauvaise utilisation des mathématiques. Pourquoi est-ce que Richard pense que le nombre obtenu par diagonalisation aurait dû être dans la liste ? Certes il est définissable en moins de milles mots, mais au moment de construire la liste, ce nombre n’existait pas encore, il ne pouvait donc pas y figurer.

C’est ce que Poincaré appelle le principe du cercle vicieux : un objet ne devrait pas s’auto-référencer dans sa propre définition, il ne devrait pas avoir besoin de déjà exister pour pouvoir être définit. C’est le cas dans le paradoxe de Richard, et c’est le cas dans la démonstration de consistance de Hilbert, qui utilise des nombres pour définir les nombres.

Depuis les critiques de Poincaré et la mise en évidence du principe du cercle vicieux, il est maintenant clair que pour donner une preuve de consistance de l’arithmétique, il faudra différencier deux choses : d’un côté, les notions que l’on veut prouver, et de l’autre, celles qui serviront à construire cette preuve.

Alors Hilbert, qui a appris de ces critiques, va choisir de diviser l'arithmétique en deux domaines. D'un côté, la mathématique formelle. C’est une mathématique totalement abstraite, donc détachée du sens usuel, et qui décrit l'ensemble complet des mathématiques contemporaines. Et d'un autre côté, Hilbert construit la mathématique finitiste, qui se limite à utiliser les notions qui sont immédiatement évidentes et acceptées de tous : les nombres entiers, les opérations arithmétiques de bases, etc; et qui laisse de côté tout le reste, toutes les notions sur lesquelles les mathématiciens ne s’entendent pas, comme la notion de l’infini.

L’objectif d’Hilbert, avec ces deux mathématiques, est de réussir à donner une preuve de consistance pour la mathématique formelle à l’aide de la mathématique finitiste que personne ne conteste. Comme il le dit, , il s'agit de "s'assurer par le fini le droit d'opérer sur l'infini". Mais Hilbert n’est pas le seul à chercher une solution au problème du fondement.

Il y a par exemple en Angleterre Bertrand Russell et Alfred Whitehead qui vont tenter une axiomatisation de l’ensemble des mathématiques, inspirés d’un précédent article de Russell : « La logique mathématique fondée sur la théorie des types ».

Cette théorie des types cherche à hiérarchiser les différentes notions des mathématiques. Ainsi, les notions de rang 1 s’appliquent uniquement aux notions de rang 2, les notions de rang 2 s’appliquent aux notions de rang 3, etc. Et cette hiérarchie permet d'éviter qu'une notion ne s'applique à elle-même, et donc d’éviter le cercle vicieux de Poincaré.

Russell et Whitehead vont donc publier leur axiomatique globale des mathématiques en trois volumes, intitulés « Principia Mathematica ». Le travail est véritablement colossal, il leur faudra plus de dix ans pour compléter leur oeuvre, et on trouve par exemple, pour vous donner juste une idée, plus de quatre cents cinquante pages afin de prouver que 1 + 1 = 2. 

Pourtant, il va manquer aux « principas » un élément essentiel, une preuve de consistance des axiomes. Pour Russell, qui est celui qui s’occupe des questions d’ordre épistémologiques, philosophiques on pourrait dire, les axiomes présentés sont des notions intuitives, évidentes, et nécessairement vraies. Une preuve de consistance ne serait, pour lui, qu’une simple validation de l’évidence, de la vérité, des axiomes, et n’est finalement pas très importante.

Hilbert commentera à propos des « principias » quelques années plus tard : "La théorie des fondements de Russell et Whitehead [...] fait reposer les mathématiques sur l'axiome de l'infini et sur un axiome dit de réductibilité. Or ces deux axiomes sont d'authentiques hypothèses qui ne peuvent s'appuyer [...] sur une preuve de consistance [... et] dont la validité universelle reste même ouverte au doute". Alors il est clair que l’évidence des axiomes ne fait pas l’unanimité.

Un peu plus loin, aux Pays-Bas, on trouve Brouwer, qui lui, place l’évidence immédiate et l’intuition au coeur des mathématiques. Pour Brouwer et le reste de ce qu’on appelle les « intuitionnistes », il faut bannir des mathématiques tout ce qui n’est pas immédiatement évident.

Les paradoxes étaient un avertissement : un usage abusif des règles de la logique, qui font abstraction du sens des notions, crée des énoncés vides de sens, et finalement, des paradoxes.

Brouwer en vérité est assez proche des positions de Poincaré. Comme lui il a une vision constructiviste des mathématiques, il veut supprimer la notion d’infini, et même si, pour cela il doit renoncer à certains outils très pratiques en mathématiques, comme le principe du « tiers exclu ».

Ce principe, qui repose sur les notions d'infini, et donc d'existence en soi des objets mathématiques, permet de dire que soit une propriété mathématique est vraie, soit son opposée est vraie, il n’y a pas de troisième possibilité. Avec le tiers exclu, un problème mathématique est donc soit vrai, soit faux, et c'est ce qui fera dire à Brouwer que : "La question de la validité du tiers exclu équivaut à celle de la possibilité de problèmes mathématiques non résolubles".

Alors il faut se souvenir que Hilbert avait défendu sa conviction dans la résolubilité de tout problème mathématique. Il avait dit au congrès international de 1900 : « Jamais le mathématicien ne sera réduit à dire Ignorabimus ! ». Ignorabimus, la citation latine qui signifie « on ne sait pas, et on ne saura pas ». Donc jamais le mathématicien ne sera réduit à dire « on ne sait pas et on ne saura pas », autrement dit, il n’y a pas de problème mathématique impossible à résoudre.

Cependant, l’intuitionnisme va gagner en influence, au point même de convaincre Herman Weyl, l’ancien étudiant d’Hilbert qui s'oppose maintenant à son professeur, je le cite : "Si les mathématiques doivent rester une préoccupation culturelle sérieuse, alors un certain sens doit être attaché au jeu de formules de Hilbert, et je ne vois qu'une seule possibilité de lui attribuer un sens intellectuel indépendant. En physique théorique, nous avons devant nous le grand exemple d'une connaissance d'un caractère tout à fait différent de la connaissance commune qui exprime purement ce qui est donné dans l'intuition".

Il faut comprendre qu’en physique, l’intuition, c’est à dire l’expérience, prends le pas sur les formules de calculs. Pourtant les mathématiques, qui représentent la pensée logique, fonctionnent sur le modèle inverse.

Alors Hilbert répondra aussi aux intuitionnistes, et leur dira : "Oter le [tiers exclu] au mathématicien serait comme si on voulait enlever à l'astronome son télescope, au boxeur le droit de se servir de son poing. [... C'est] quasiment à renoncer à la science mathématique. Car que sont les misérables restes, qu'est-ce que la poignée de résultats incomplets et disparates que les intuitionnistes ont pu élaborer [...] à l'égard de l'étendue formidable de la mathématique contemporaine ?".

Alors on trouve une certaine force dans cette déclaration d’Hilbert, mais encore faudrait-il qu’il puisse proposer sa propre solution au problème du fondement, puisqu’il n’a encore aucun résultats de ce côté là pour l’instant, et c’est pour ça qu’il va fonder à partir de 1922, et ça continuera jusqu’en 1930, ce qu’on à appelé le programme de Hilbert.

——

L'objectif affiché du programme formaliste de Hilbert est d'établir la mathématique formelle, une mathématique abstraite dont on pourrait dire qu’elle est pure de forme mais vide de sens, à l’aide de la mathématique finitiste, qui n’utilise que des notions clairement établies, et acceptées par toute la communauté mathématique.

C’est ce qui fait la force du programme formaliste, d’ailleurs, pour Hilbert, formaliser "c'est dépeindre l'activité de notre intelligence", c'est "dresser un inventaire des règles d'après lesquelles fonctionne réellement notre pensée". Il se permettra même quelques commentaires à l’égard des arguments des autres mathématiciens qui se sont essayés au problème du fondement, en disant qu’il n’a "besoin ni du Bon Dieu, comme Kronecker, ni de l'hypothèse d'une faculté de conscience accordée au principe d'induction complète, comme Pointcarré, ni de l'intuition originelle de Brouwer, ni non plus des axiomes de l'infini [comme Russell et Whitehead]".

Pourtant, et malgré la force supérieure des arguments philosophiques du programme formaliste, les mathématiciens  qui sont engagés dans le programme, il y a Hilbert bien entendu, mais il y a aussi Bernays, Von Neumann, Ackermann; ces mathématiciens n’ont toujours pas obtenus de résultats satisfaisants et toutes les différentes tentatives d’axiomatisation ou de preuve de consistance ont échouées.

Alors en 1928, Hilbert va prendre la parole au congrès international de Bologne, et il va exposer devant ses pairs trois problèmes que cherche à résoudre le programme formaliste : L'axiomatique formelle est-elle complète ? consistante ? et décidable ?

Il faut expliquer ce que cela veut dire. D’abord, l’axiomatique formelle est-elle complète ? C'est à dire qu’il faut pouvoir prouver que n'importe quelle formule crée à partir des axiomes est nécessairement soit démontrable, soit réfutable. Il faut y voir la volonté d’une validation du principe du tiers exclu, et de la conviction dans la résolubilité de tout problème mathématique. On se souvient de la citation de 1900, « Jamais le mathématicien ne sera réduit à dire Ignorabimus ».

Ensuite, l’axiomatique formelle est-elle consistante ? C’est le coeur du programme formaliste et de la quête du fondement, il s’agit toujours de prouver que les axiomes ne sont pas contradictoires.

Et enfin, l’axiomatique formelle est-elle décidable ? C’est à dire, est-ce qu'il existe une méthode effective, qui permette de décider si une formule donnée est démontrable ou réfutable ? Hilbert cherche en fait une formule mathématique qui permettrait de démontrer quasi automatiquement tous les théorèmes qui existent.

Alors il est bien entendu que Hilbert espère apporter une réponse positive à ces trois questions. Et c'est même à cette condition seulement que pourrait se concrétiser le programme formaliste. D’ailleurs, en 1928, on peut-être assez optimiste. Au cours de la conférence, Hilbert à annoncé qu'Ackermann et Von Neumann sont parvenus à prouver la consistance de l'axiomatique formelle, et aussi qu’Ackermann et lui-même seront bientôt en mesure d’apporter la preuve de la complétude des « prédicats du premier ordre », et même si le prédicats ne représentent qu’une partie de l’axiomatique formelle, c’est une partie très importante puisque les prédicats du premier ordre décrivent l’ensemble des règles de logiques applicables dans une démonstration mathématique.

Alors ils sont nombreux ceux qui écoutent la conférence de Hilbert, mais en particulier il faut noter la présence à Bologne d’un jeune mathématicien Autrichien qui va prêter beaucoup d’attention à l’exposé d’Hilbert, ce mathématicien, c’est Kurt Gödel.

Alors j’ai dit qu’il était Autrichien mais on peut ouvrir là une petite parenthèse sur la nationalité de Kurt Gödel. Il est né Austro-Hongrois, puis sera naturalisé Tchécoslovaque à la fin de la première guerre mondiale, au moment de la dissolution de l'Autriche-Hongrie. Toujours attaché à ses racines, il va prendre la nationalité Autrichienne en 1929, puis devra devenir Allemand en 1938, à cause de l’annexion de L’Autriche par L’Allemagne. Quelques années plus tard, de peur d’être enrôlé dans l’armée Allemande à cause de sa santé fragile, il part aux États-Unis. Pour obtenir sa nouvelle nationalité, il doit passer devant un juge, qui n’acceptera la candidature de Gödel que grâce à la réputation d’Albert Einstein, avec qui Gödel est très ami, puisque Gödel, qui avait étudié avec attention la constitution en vue de l’entretient était en train de démontrer au juge qu’un régime dictatorial pouvait émerger aux États-Unis en toute légalité.

Alors pour revenir à notre histoire, Je vous avais dit que Hilbert et Ackerman pensaient pouvoir démontrer la complétude des prédicats du premier ordre, mais c’est en fait Gödel qui apportera cette preuve, on est en 1929. Et puis, un an plus tard, en août 1930, se tient une conférence à Köningsberg. Plusieurs points de vue sur le problème du fondement sont exposés, Heyting parle de l'intuitionnisme, Von Neumann défends le formalisme, et Hilbert annonce sa retraite avec un discours qui se termine par : « Nous devons savoir. Nous le saurons! ». Des mots qui s’opposent bien entendu à l’Ignorabimus qu’il avait déjà attaqué en 1900.

Alors, si je vous parle de cette conférence, c’est parce que sur les côtés de la conférence, à la faveur d’une discussion informelle, Gödel va présenter un théorème, qu’il a trouvé quelques jours plus tôt on imagine, et qu’il n’a pas encore publié à quelques-uns de ses collègues, parmi lesquels figure John Von Neumann. Il dit : « Si l'arithmétique élémentaire est ω-consistante, elle comporte des formules fermées qui ne sont ni démontrables, ni réfutables à partir des axiomes ». Et Von Neumann, qui, on le rappelle, est au centre du programme formaliste, aura ce mot : « Tout est fini » !

C’est d’ailleurs le seul, à ce moment là, à réaliser les conséquences du théorème de Gödel, qui, exposé simplement, dit que n’importe quelle axiomatique est nécessairement soit incomplète, soit inconsistante. Alors pour le programme formaliste qui voulait prouver à la fois la complétude et la consistance de l’axiomatique formelle, cet objectif est en fait irréalisable.

Et pourtant, l’idée est simple, Gödel considéré même qu’il s’agit d’une "conséquence presque triviale" des travaux de Skolem. En fait, Gödel montre qu’il est possible dans n’importe quelle axiomatique, à la condition que cette axiomatique soit suffisamment expressive pour représenter les nombres entiers et les opérations d’addition et de multiplication, c’est à dire l’arithmétique élémentaire, il est possible de créer une proposition qui dise : « Je ne suis pas démontrable ».

À partir de là il n’y a plus que deux possibilités, soit la formule est démontrable, mais alors, nous avons un système d’axiome qui démontre des choses qui sont fausses. Et c’est la catastrophe puisque dans ce cas là le système n’est pas consistant, et donc inutilisable. 

L’autre solution, c’est que la formule ne soit pas démontrable, mais alors, elle est vraie. Donc on se retrouve avec une formule qui est vraie mais qui n’est pas démontrable, le système est incomplet.

Deux mois plus tard, le 20 Novembre, Von Neumann écrit à Gödel, il lui dit qu'il à trouvé un second théorème à partir du premier : "la consistance d'un système ne peut pas être établie au moyen de raisonnements qui se laisseraient formaliser dans le système".

C’est une nouvelle catastrophe pour le programme formaliste, puisque l’idée de Hilbert était d’apporter la preuve de consistance de l’axiomatique formelle à l’aide de la mathématique finitiste. Mais comme la mathématique finitiste, qui ne représente qu’une partie de l’arithmétique, est formalisable dans l’axiomatique formelle, qui elle représente toute l’arithmétique, alors il est impossible d’utiliser la mathématique finitiste pour apporter la preuve de consistance de l’axiomatique formelle.

En fait Gödel était déjà arrivé à la même conclusion quelques jours plus tôt, et il avait déjà envoyé un article avec les deux théorèmes à une revue mathématique Viennoise, qui le publiera finalement en Janvier 1931.

Si on en croit Bernays, Hilbert entra dans une colère noire à l’instant où il découvre les deux théorèmes. Peut-être parce qu’il n'avait lui-même découvert ces deux théorèmes. Ou peut-être parce que ces deux théorèmes marquent l’échec de son programme.

Et pourtant, Gödel n’est pas du même avis, il dit : "il reste un espoir pour que dans le futur on puisse trouver des méthodes satisfaisantes [...] dépassant les limites du système [finitiste de Hilbert] et permettant de fonder l'arithmétique classique et l'analyse. Cette question ouvre un champ de recherches fécond". Et il ajoute : "la conviction dans la décidabilité de tout problème mathématique n'est pas ébranlée par ce résultat". 

Par ailleurs, Gödel n’est pas le seul à considérer que les théorèmes d’incomplétude ne marquent pas un point final au programme formaliste, John Von Neumann par exemple va dire: "Ce résultat imposant de l'analyse de Gödel ne doit pas être mal compris: il n'exclut pas une preuve méta-mathématique de la consistance de l'arithmétique. [...] Gödel a montré qu'aucune preuve n'est possible qui peut être représentée au sein de l'arithmétique. Son argument ne supprime pas la possibilité de preuves strictement finitiste qui ne sont pas représentés au sein de l'arithmétique. Mais personne aujourd'hui ne semble avoir une idée claire de ce qu'une preuve finitiste serait qui ne serait pas formulable dans l'arithmétique".

De toute façon, avant de clore définitivement le programme formaliste, il reste encore à résoudre la question de la décidabilité. Et cette question va prendre d’autant plus d’importance depuis les théorème de Gödel, puisqu’il y est question de trouver une « procédure effective » qui puisse décider de la démontrabilité de n’importe quelle formule. Et ce terme de « procédure effective », qui est au centre de la question de la décidabilité, est également au centre de la généralisation des théorèmes d’incomplétude de Gödel, mais il n’y a pas de définition mathématique précise pour cette idée de « procédure effective », qui en fait renvoie à l’idée de « calculabilité ». Alors il va s’agir maintenant de trouver une définition appropriée à la « calculabilité », de sorte d’identifier tout ce qui est calculable, et de laisser de côté tout ce qui ne l’est pas.

——

C’est au cours du 18ème siècle que l’idée de « calculabilité » est associée avec l’idée de « fonction » mathématique. Mais les fonctions vont évoluer pendant le 19ème siècle afin de décrire seulement la transition entre un point de départ et un point d'arrivée, sans qu’il ne soit nécéssaire pour définir la fonction de décrire la procédure de calcul, cette fameuse « procédure effective » qu’utilise Hilbert dans la question de la décidabilité. On peut alors différentier deux types de fonctions, celles pour lesquelles on a la procédure de calcul, et qui sont dites « calculables », et les autres. Alors l’enjeu derrière la définition formelle de la calculabilité, c’est de tracer une ligné précise entre les fonctions calculables et les fonctions non-calculables.

Le premier à trouver une définition satisfaisante à la calculabilité, c’est l’américain Alonzo Church. Professeur à l’université de Princeton, il va publier en 1936 un article titré « Un problème insoluble de la théorie des nombres élémentaires », qui propose une définition de la calculabilité, basé sur le le λ-calcul, un système de calcul que Church à développé années précédentes, et il propose aussi une solution au problème de la décision. 

Pour Church, le λ-calcul représente tout ce qui est calculable. L’idée de base du λ-calcul est de n’utiliser que des fonctions. Une fonction y est décrite par une expression mathématique, mais peut aussi contenir d’autres fonctions. On peut également « appliquer » deux fonctions entre-elles, c’est à dire qu’on va utiliser le résultat d’une première fonction pour le calcul d’une seconde fonction. C’est à partir de ces quelques opérations basiques que Church peut construire des fonctions de plus en plus compliquées, et, possiblement, tout ce qui est calculable.

Mais certains, comme Stephen Kleene, ne sont pas immédiatement convaincus. Kleene pense pour sa part qu’une définition de la calculabilité est impossible. Il pense que si on avait une définition valable, on pourrait ensuite faire la liste de toutes les fonctions calculables, puis par diagonalisation, créer une nouvelle fonction qui soit calculable mais qui ne soit pas déjà dans la liste, donc qui n’était pas inclus dans la définition de la calculabilité, ce qui rends la définition caduque. Ce raisonnement empêche toute définition de la calculabilité, et pourtant, Kleene va changer d’avis, il dit : "Lorsque Church me proposa sa thèse [pour une définition de la calculabilité], je me mis aussitôt à la tâche de la réfuter par une diagonalisation de la classe des fonctions [calculables]. Mais, réalisant vite que la diagonalisation ne pouvait être faite de façon effective, je devins du jour au lendemain partisan de la thèse de Church".

Deux mois seulement après la publication de Church, une autre définition de la calculabilité apparaît, et cette fois-ci, c’est un Anglais qui nous la donner, un jeune diplômé du King’s College de Cambridge : Alan Turing. Turing avait suivi l’année précédentes le cours de « fondement des mathématiques » de Max Newman. Newman enseigne le programme formaliste de Hilbert, les théorèmes d’incomplétude de Gödel, et commente sur le problème de la décision : « Supposons, par exemple, que nous puissions trouver un système fini de règles qui nous permettrait de dire si une formule quelconque est ou non démontrable. Ce système contiendrait un théorème de métamathématique. Évidemment, ce théorème n'existe pas et c'est heureux, parce que s'il existait, nous aurions un ensemble mécanique de règles nous permettant de trouver la solution de tous les problèmes mathématiques et notre activité en tant que mathématiciens cesserait d'exister ».

Newman utilise l’expression d’un « ensemble mécanique de règles » plutôt que de « procédure effective ». L’expression vient en fait de Von Newmann qui disait, en parlant du problème de la décision : « il y aurait une instruction absolument mécanique à l'aide de laquelle quiconque pourrait décider, à partir de n'importe quelle formule donnée, si elle est ou non démontrable ». Cette vision mécanique du calcul va définitivement inspirer Turing, son professeur raconte : « et cela bien sûr conduit [Turing] au prochain défi, quel type de machine ? Et cela l'a inspiré pour essayer de définir ce que l'on voudrait dire par une machine à calculer parfaitement générale ».

Alors c’est à la fin de l’été 1936 que Turing termine la rédaction de « On Computable Numbers / Sur les nombres calculables », et il faut noter qu’il n’a à cette époque, aucune idée des travaux de Church, et il est d’ailleurs assez évident de voir que Turing ne s’est absolument pas inspiré de Church, tellement les deux méthodes sont différentes. Alors on va trouver des références au λ-calcul de Church dans l’article de Turing, puisque l’article, terminé en 1936, ne sera publié qu’en 1937, et entre temps, Turing ira s’installer à Princeton pour travailler sous la direction de Church.

C’est Max Newman qui a arrangé la venue de Turing à Princeton, il écrit dans une lettre à Church : « Je dois mentionner que le travail de Turing est entièrement indépendant: il a travaillé sans supervision ou critique de quiconque. Cela rend d'autant plus important qu'il devrait entrer en contact le plus tôt possible avec les principaux travailleurs de ce domaine, de sorte qu'il ne devrait pas se transformer en un solitaire confirmé ».

Il n’est donc pas très étonnant de trouver dans la version finale des références aux travaux de Church, dans l’introduction par exemple : « Dans un article récent Alonzo Church a introduit l'idée de "calculabilité effective", ce qui équivaut à ma "calculabilité", mais est définie de manière très différente. Church atteint également des conclusions similaires au sujet du problème de la décision. La preuve de l'équivalence entre "calculabilité" et "calculabilité effective" est décrite dans une annexe au présent document ».

Alors c’est quoi la « calculabilité » de Turing ? Toujours dans l’introduction on peut lire : « Selon ma définition, un nombre est calculable si [il] peut être écrit par une machine. […] ». Par une machine, mais quelle machine ? Justement, il y a la définition complète dans le premier chapitre de l’article : « On peut comparer un homme en train de calculer un nombre à une machine qui est seulement capable d'un nombre fini de conditions, qui seront appelés "m-configurations". La machine est livrée avec une "bande" (l'analogue du papier) qui la traverse, et est divisée en sections (appelé "carrés") capables chacun de porter un "symbole". A tout moment, il y a juste un carré [...] qui est "dans la machine". Nous pouvons appeler cette place le "carré lu". Le symbole sur le carré lu peut être appelé le "symbole lu". Le "symbole lu" est le seul dont la machine est, pour ainsi dire, "directement au courant". Cependant, en modifiant sa m-configuration la machine peut se rappeler efficacement certains des symboles qu'elle a "vu" précédemment. À tout moment, le comportement de la machine est déterminé par la m-configuration [...] et [...] le symbole lu. Cette paire [...] sera appelé "configuration" : ainsi la configuration détermine le comportement de la machine. Dans certaines configurations dans lesquelles le carré lu est vierge (i.e. il ne porte pas de symbole), la machine écrit un nouveau symbole sur le carré lu: dans d'autres configurations, il efface le symbole lu. La machine peut également changer le carré en cours de lecture, mais seulement en le déplaçant d'une case à droite ou à gauche. En plus de l'une de ces opérations, la m-configuration peut être modifiée. Certains des symboles écrits formeront la séquence de chiffres [...] du nombre [...] qui est calculé. Les autres ne sont que des brouillons pour "aider la mémoire". [...] Je soutiens que ces opérations comprennent toutes celles qui sont utilisés dans le calcul d'un nombre. »

Turing propose ensuite quelques exemples afin de mieux comprendre le fonctionnement de ses machines, il dit : « Une machine peut être construite pour calculer la séquence 01010101 ... [...] La machine possède quatre m-configurations "b", "c", "f", "e" et est capable d'écrire "0" et "1". Le comportement de la machine est décrite dans le tableau suivant dans lequel "R" signifie "la machine se déplace de sorte à lire le carré immédiatement à la droite de celui qui était auparavant lu". De même, pour "L". "E" signifie "le symbole lu est effacé" et "P" signifie "écrire". La machine démarre dans la m-configuration "b" et avec une bande vide. [b None P0, R c; c None R e; e None P1, R f; f None R b] »

Donc, la machine démarre avec la m-configuration « b », avec une bande vide, donc le premier symbole lu est vide, c’est donc la première ligne du tableau qui s’applique : La machine imprime le symbole « 0 », se décale vers la droite et passe dans la m-configuration « c ». Et on recommence, la machine est en m-configuration « c », le symbole lu est vide, c’est donc la seconde ligne du tableau qui s’applique, la machine se décale vers la droite et passe en configuration « e ».

C’est ensuite la troisième ligne du tableau qui va s’appliquer, puisqu’on a un symbole vide et la m-configuration « e », on écrit un « 1 », on se décale à droite et on passe en m-configuration « f ». Finalement, cette configuration correspond à la dernière ligne du tableau, la machine se décale à droite et passe en m-configuration « b », et la boucle va recommencer.

Turing donne ensuite un second exemple dans son article, une machine qui calcule la séquence 01011011101111… Cette machine repose sur les mêmes principes que la précédente, ce qui change, c’est la table d’instruction, qui représente en fait les engrenages, les rouages de la machine. Alors comme chaque calcul peut-être représenté par une machine de Turing, et que chaque machine de Turing possède une table d’instruction unique, Turing à l’idée d’utiliser un code, qui permet de représenter sous forme numérique la table d’instruction d’une machine spécifique, et donc, d’un calcul. En faisant la liste de tous les nombres entiers, et en disposant d’une méthode qui permettrait de vérifier si un nombre correspond au code d’une machine de Turing, on pourrait alors lister la totalité des calculs qui existent.

Turing nous explique donc comment obtenir, à partir de la table d’instruction d’une machine, le « nombre de définition » de cette machine. On commence par lister les m-configurations de la machine, de sorte à pouvoir les identifier comme la "première" m-configuration, ou la "cinquième" m-configuration. On peut alors coder une m-configuration spécifique en utilisant la lettre « D », suivie autant de fois que nécessaire par la lettre « A », afin de décrire sa position dans la liste. Par exemple, la première m-configuration sera codée par « DA », la seconde sera "DAA", etc. La même opération est faite pour les symboles, en utilisant cette fois la lettre « C » plutôt que la lettre « A », le troisième symbole sera donc codé "DCCC". Ensuite, les lettres « L », « R », et « N » sont associées aux opérations de déplacement de la machine, et le symbole « ; » est utilisé pour séparer les différentes lignes. Finalement, on remplace chaque lettre par un chiffre, le "A" est remplacé par un "1", le "C" par  un « 2 », "D" par "3", "L" par "4", "R" par "5", "N" par "6" et finalement, le « ; » est remplacé par un "7".

En appliquant cette procédure à la table d’instruction de la machine qui nous as servi d’exemple tout à l’heure, on obtiens le nombre suivant : 31332531173113353111731113322531111731111335317.

L’objectif de Turing maintenant est d’arriver à savoir si il existe une méthode qui lui permettrait de deviner à partir d’un nombre si ce nombre représente une machine de Turing, et plus précisément, une machine de Turing non circulaire. Une machine de Turing non-circulaire est une machine qui calcule et aboutit à un résultat, autrement dit, après un certains temps de calcul, elle s’arrête. À l’inverse, les machines dites « circulaires » ne s’arrêtent jamais, et ne progressent jamais vers aucun résultat. On peut imaginer par exemple une machine qui écrirait le caractère « a » sur la bande, puis l’effacerait et le remplacerait par un « b », puis l’effacerait et le remplacerait par un « a », puis l’effacerait et ainsi de suite. C’est une machine circulaire, qu’il ne faut pas confondre avec une machine au temps de calcul infini, comme la machine qui calcule petit à petit toutes les décimales de π, ou notre machine d’exemple de tout à l’heure.

Alors si Turing s’intéresse au problème de l’arrêt, de cherche à savoir à l’avance si une machine va s’arrêter ou non, si elle est circulaire ou non, c’est parce que ce problème est en réalité très proche du problème de la décision, et s’il trouve la solution du problème de l’arrêt, Turing aura quasiment du même coup la solution au problème de la décision.

Il commence par imaginer qu’il existe une machine, qu’il appelle la machine D, qui soit capable de décider si une machine M, celle que l’on veut tester, est circulaire ou non. Sur le ruban de la machine D, on inscrit le nombre de la machine M, puis la machine D inscrira sur le ruban soit le symbole « u », soit le symbole « s ». Le symbole « u » signifie que la machine M est circulaire, « s » qu’elle est sans cercle. 

Ensuite, Turing va construire une autre machine. Cette machine va lire le symbole inscrit sur le ruban, si elle lit un "u", la machine se stoppe, mais si elle lit un "s", elle entre dans une configuration circulaire, et ne s’arrêtera pas.

En associant ces deux machines, on peut créer la machine H. Donc, on inscrit d'abord le nombre de définition d'une machine M, H va commencer par calculer un premier résultat intermédiaire, et va inscrire sur le ruban soit le symbole « u », soit le symbole « s », en fonction de la « circularité » de la machine M. Ensuite, en fonction du symbole écrit sur la bande, la machine H va soit s’arrêter, soit entrer dans une configuration circulaire.

Et c’est à ce moment que Turing nous pose une question : que se passe-t-il si on donne à la machine H son propre nombre de définition ?

Il y a deux scénarios possibles, soit le résultat intermédiaire prédit que la machine H est circulaire, donc la machine écrit le symbole « u » sur la bande, puis s’arrête. Elle n’est donc pas circulaire, la prédiction était fausse. Ou bien, le résultat intermédiaire prédit que la machine H est sans cercle, et qu’elle s’arrêtera. Dans ce cas, c’est le symbole « s » qui est écrit sur la bande, et alors, la machine H va entrer dans une configuration où elle est en fait circulaire.

Dans les deux cas, les prédictions du résultat intermédiaire sont fausses. Turing en conclut alors que la machine D, qui jouait ce rôle, ne peut donc tout simplement pas exister. Il est  impossible de décider à l’avance si une machine de Turing sera circulaire ou pas. Avec un raisonnement quasi-identique, Turing va également démontrer qu’il est impossible de décider si une machine de Turing va inscrire le caractère « 0 » au cours de son calcul ou pas.

À partir de ces deux conclusions, Turing peux dire qu’il n’y a pas de solution au problème de la décision de Hilbert, puisqu’il montre que si il existait une procédure effective, c’est à dire une machine de Turing, qui soit capable de décider si une formule mathématique est démontrable ou non, alors il existerait aussi une procédure effective pour décider si une machine de Turing inscrit le caractère « 0 » au cours de son calcul, mais Turing vient de démontrer qu’une telle machine n’existe pas. La réponse à la dernière question du programme formaliste de Hilbert est donc, elle aussi, négative.

Mais l’article de Turing ne s’arrête pas à la solution du problème de la décision, il continue et va faire maintenant ce qui manquait au λ-calcul de Church, il va justifier la machine de Turing en tant que définition de la calculabilité, d’un point de vue philosophique. Il compare ses machines aux cahiers quadrillés de mathématiques qu’utilisent les écolier. Et il écrira même que le fonctionnement de ses machine est une bonne description du fonctionnement de la pensée humaine.

Et c’est d’ailleurs cette justification philosophique qui fera la force de l’article, puisque la majorité de ses contemporains reconnaissent la supériorité de la définition de Turing, surtout comparée au λ-calcul, du fait de sa simplicité. Church par exemple va dire : « l'identification avec l'effectivité dans l'ordinaire [...] semble immédiatement évident ». Gode aussi, qui ajoute en note aux théorèmes d’incomplétude : « Grâce à certains travaux qui ont suivi cet article, en particulier ceux de A. M. Turing, nous disposons désormais d'une définition sûre, précise et adéquate du concept de système formel [...] dont la propriété est qu'en son sein, et en principe, le raisonnement peut être entièrement remplacé par des règles mécaniques ».

Alors si l’article est largement reconnu en mathématiques, il sera aussi considéré ensuite comme un article fondateur de la science informatique, puisqu’il il y a  dans un chapitre dont je n’ai pas encore parlé la description par Turing de ce qu’il appelle la « machine universelle ». Il dit : « Il est possible d'inventer une machine unique qui peut être utilisée pour calculer toute séquence calculable. [...] Si cette machine U est fournie avec une bande sur laquelle est écrite la définition standard d'une machine M, U calculera la même séquence que M ».

Cette seule phrase est véritablement extraordinaire, puisque dans ces quelques mots, on lit véritablement les deux grandes idées, les deux piliers de la science informatique : d’abord, le principe d’une machine unique qui peut réaliser n’importe quel calcul, à une époque où les machines à calculer son encore mécaniques, et où ces machines sont spécialisées, chaque machine correspond à un seul type de calcul, Turing vient de prouver qu’il est possible de construire une seule machine pour faire le travail de n’importe quelle autre.

Ensuite, il y a l’idée de programme. Un programme qui est accessible sur la bande de la machine, c’est à dire qu’il est traité comme n’importe quelle autre information que la machine reçoit, le programme n’est pas différent des nombres sur lesquels la machine doit effectuer son calcul. Et il est même possible à la machine de modifier les instructions de son propre programme. Alors même si il existe déjà en 1936 des machines programmables, l’idée d’un programme qui soit manipulable par la machine est tout à fait originale, et ouvre la voie sur des nouvelles possibilités.

On pourrait presque dire qu’à ce moment là, Turing à inventé l’ordinateur, c’est d’ailleurs quelque chose que j’entends régulièrement, pourtant il y a une différence importante entre la machine de Turing universelle et un ordinateur : la machine universelle n’est que théorique. Turing d’ailleurs était directement intéressé en 1936, après avoir écrit son article, par la construction d’une véritable machine qui soit l’incarnation de la machine universelle. Il ne construira aucune machine en 1936, puisque, selon lui, il n’existe pas encore de technologie suffisante pour réaliser un tel projet. Il va falloir attendre la seconde guerre mondiale avant que Turing, et d’autres, ne puissent maîtriser la technologie suffisante qui leur permettra ensuite de construire les premiers ordinateurs.
