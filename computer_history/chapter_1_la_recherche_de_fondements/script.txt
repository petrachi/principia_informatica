Bonjour. Aujourd'hui on va se lancer dans une longue histoire, un exposé de la naissance des premiers ordinateurs. Mais avant de commencer, j'aimerais vous répéter ce que m'a dit Jean Lassègue dans un entretient pendant que j'effectuais mes recherches. Il me disait que l'histoire de l'ordinateur peut-être soit vue d'un point de vue théorique. Les premiers ordinateurs seraient le fruit d'une réfléxion très théorique menée principalement par Turing et Von Neumann. Soit, l'autre version de la même histoire, c'est de considérer qu'il s'agit essentiellement d'une affaire d'ingénierie, et de la mise ou point, ou de la perfection, de machines calculantes.

Alors, on va essayer ensemble d'explorer les deux versans de cette histoire. Et pour commencer, on va remonter un peu avant le début du 20ème siècle, et suivre à travers le travail de David Hilbert ce que l'on appelle la quête du fondement mathématique, et qui va mener aux première théories de la science informatique.

Donc, David Hilbert, c'est un Allemand, et il va démarrer ses études en mathémtiques, contre l'avis de son père, à l'université de Köningsberg, qui, il faut le dire, est une des universités les plus réputés d'Allemagne.

C'est à Köningsberg qu'Hilbert va faire deux grandes rencontres. D'abord, il croise le chemin d'Adolf Huritz, qui est l'un de ses professeurs à l'unversité, mais surtout, Hilbert va se lier d'une trés grande amitié avec une autre étudiant, c'est Hermann Minkowsky.

Alors on a un témoignage direct de Hilbert de cette époque : "Ainsi, alors que j'étais encore étudiant, j'ai été poussé par Hurwitz au coeur des débats scientifiques et j'ai eu la chance, en étant avec lui, d'apprendre à connaître, d'une façon plaisante, les deux écoles opposées mais parfaitement complémentaires, l'école géométrique de Klein et l'école algébrique-analytique de Berlin. Lorsqu'il revenait dans sa famille à Köningsberg, le génial Minkowski, avec qui je m'étais déjà lié, se joignait à nous. Au cours de ces innombrables promenades, jour après jour, pendant huit années, nous avons fouillé tous les coins du savoir mathématique."

Après ses études, et après avoir pris le temps de voyager et de rencontrer certaines grands mathématiciens de son époque, Klein, Kronecker, Pointcaré; Hilbert va devenir "Privatdozent", que l'on peut traduire par "assistant".

C'est classique dans le système éducatif de l'époque, le "Privatdozent" peut enseigner mais ne touche pas de rémunération fixe, il est directement payé par les élèves qui choississent d'assister à ses cours, puisqu'il n'y a pas dans les universités de classes imposés. Les étudiants sont totalement libres, pendant quatres ans, jusqu'à l'examen final.

Mais ce statut lui offre également le temps, la flexibilité nécéssaire pour commencer un travail de recherche, et en particulier, Hilbert va s'intèresser à la théorie des invariants qui, depuis 20 ans maintenant, attends des réponses.

Le problème que l'on cherche à résoudre en théorie des invariants, c'est d'identifier certaines propriètés invariantes, qui ne changent pas, pour des formes représentées dans des espaces à plusieurs dimensions.

C'est grâce aux travaux de Gordan que l'on sait identifier les propriétés invariantes pour des formes dans des espaces à deux dimensions. Mais Gordant à dû réaliser une quantité déjà monumentale de calculs, et pour un nombre de dimensions supérieur on fait face à un problème de taille, la quantité de calculs nécéssaires rends la tâche tout simplement irréalisable.

Alors Hilbert, qui s'attaque à ce problème, décide de tenter une autre voie. Il démontre qu'il existe une famille génératrice de formes, qui existe pour n'importe quel nombre de dimensions, et tout ça sans aucun calcul !

Le problème des invariants est donc résolu puisque les propriétés invariantes sont les propriétés de la famille génératrice, si on a la famille génératrice, on a les propriétés invariantes. Mais c'est bien là qu'est le problème, Hilbert ne sait pas comment calculer cette fameuse famille génératrice de formes.

Il n'a, rapellons-le, utilisé aucun calcul pour parvenir à ce résultat. À la place, il a étudié, grâce à cet outil mathématique qu'es la méthode abstraite, il a étudié les relations des différents objets, des différentes formes entre-elles.

Et il va publier ses résultats en 1890 dans un article intitulé "De la théorie des formes algébriques", auquel Gordant répondra : "Ce n'est pas des mathématiques, c'est de la théologie".

Trois ans plus tard, Hilbert publie à nouveau, et cette fois, il fournit une méthode afin de calculer la famille génératrice de forme. Et Gordant sera obligé d'admettre : "La théologie à parfois ses mérites".

De son côté, Hilbert écrit à Minkowski, il dit : "Je quitte maintenant le domaine des invariants définitivement et je ne m'occuperais plus que de théorie des nombres". C'est aussi parceque l'association des mathématiciens Allemands vient de lui demander un rapport sur la théorie des nombres algébriques, puisque Kummer et Kronecker, qui sont les deux grandes figures du domaine, ont peu publiés. Le rapport, qui sera publié en 1897 deviendra plus tard un véritable ouvrage de référence, nottament pour les travaux d'Emmy Noether dans les années vingt.

C'est aussi à cette époque que Hilbert arrive à Göttingen. À l'invitation de Klein, il est nommé professeur ordinaire à l'université en 1895, puis à son tour, il fera nommer Minkowski en 1902. L'influence de Klein, de Hilbert et de Minkowski va faire de Göttingen un centre incontournable des mathématiques, on pourrait presque dire la capitale des mathématiques.

Ainsi, l'université attire de nombreux étudiants, l'un d'entre eux, Hermann Weyl, écrira en 1944 : "J'entends toujours la flûte douce de Hilbert nous séduisant pour nous conduire dans la rivière profonde des mathématiques [...] Les portes d'un monde nouveau s'ouvraient devant moi et je n'étais pas là depuis longtemps que déjà la résolution s'était formé dans mon jeune coeur de lire tout ce que cet homme avait écrit."

Alors il aura des choses à lire ce jeune homme, puisqu'aprés avoir publié son rapport sur la théorie des nombres, il change une fois encore de domaine et s'intéresse cette fois à la géométrie.

Je vous avais dit quand il s'occupait de théorie des invariants qu'il avait résolu le problème en appliquant une nouvelle méthode au problème, la méthode abstraite. Et c'est exactement ce qu'il va faire pour la géométrie, en allant encore un peu loin que la méthode abstraite, jusqu'à l'axiomatique.

C'est Euclide, qui à vécu en 300 avant notre ère, qui a, le premier, établi un ensemble de régles pour décrire ce qu'on peut faire en géométrie, et ce que nous ne pouvons pas faire. C'est la première axiomatisation.

C'est à dire : définir un ensemble de régles, qu'on appelle les axiomes, qui vont former la base de l'édifice mathématique. Toutes les propositions, tous les théorèmes seront déduis des axiomes.

Les axiomes sont donc les seules propositions mathématiques qu'il n'est pas nécéssaire de prouver. Mais cela rends la tâche d'autant plus complexe, puisqu'il faut alors réussir à trouver des axiomes qui soient suffisament simples et évident pourqu'il n'y ait pas besoin de prouver leur vérité.

Depuis Euclide, la méthode axiomatique s'est étendue à tous les domaines mathématiques, chaque branche des mathématiques poséde sa propre axiomatique, les régles qui définissent pour chaque domaine comment manipuler les différentes notions.

Mais l'axiomatisation de la géométrie, donc celle d'Euclide est critiquée, depuis longtemps d'ailleurs, puisque déjà à son époque, Archiméde avait ajouté un axiome qui lui semblait manquer.

Le défaut de l'axiomatisation d'Euclide, c'est qu'il n'y a pas suffisament d'axiomes pour répondre à certains problèmes de façon purement logique, et il est parfois nécéssaire de recourir au sens évident d'une chose au cours d'une démonstration afin de pallier au manque d'axiomes.

Il faut que je vous donne un exemple pour que vous compreniez bien, on peux commencer par déclarer un axiome dans une nouvelle branche des mathématiques :  "Socrates est un homme", c'est notre premier axiome. Et dans un article, dans une publication mathématique, on pourrait trés bien affirmer que, puisque socrates est un homme, alors Socrates est mortel.

Ça paraît évident, puisque tous les hommes sont mortels, c'est une vérité que l'on connait tous et qui est tiré de notre expérience vécue, mais c'est aussi une preuve mathématique très faible.

Les mathématiques sont un language formel, c'est à dire que tout doit y être définit sans ambiguité. Dans ce contexte, rien ne nous permet d'affirmer que tous les hommes sont mortels, sauf si cette proposition était un axiome.

La validité de la conclusion, que Socrates est mortel, dépends de l'existence en tant qu'axiome de la proposition "Tous les hommes sont mortels".

Dans notre exemple, je ne crois pas que la publication finale aurait fait débat, du fait  de l'évidence immédiate de notre axiome manquant, que tous les hommes soient mortels.

Mais on trouve en mathématiques des notions beaucoup plus floues et qui ne sont pas nécéssairement érigées en tant qu'axiomes, comme par exemple la notion de l'infini, qui fera, comme on le vera, l'objet de profonds désacords dans la communautée.

C'est ce problème, le manques d'axiomes en géométrie, que Hilbert veut résoudre en proposant une toute nouvelle axiomatisation. Et cette fois encore, il va différentier son point de vue par rapport au reste de ses pairs.

D'ordinaire, les axiomes servent à décrire directement les objets mathématiques. En géométrie on parle de points, de droites et de plans. Hilbert, lui, va se servir des axiomes pour décrire plutôt les interactions, les relations des différents objets entre eux, sans jamais les définirs directement.

La démarche est particulièrement bien illustrée par cette petite anecdote. Hilbert est à la terrasse d'un café avec ses étudiants et leur dit : "L'on devrait pouvoir parler en géométrie de tables, de chaises et de chopes de bière, au lieu de points, de droites et de plan".

Le cours de géométrie qu'il donne d'ailleurs ne mentionne que dans son introduction les notions de points, de  droites et de plans : "Nous pensons trois systèmes différents de choses. Nous nommons les choses du premier système des points [...]. Nous nommons droites les choses du deuxièmes système [...]. Nous appelons plans les choses du troisième système. [...]. Entre les points, les droites et les plans, nous imaginons certaines relations que nous exprimons par des expressions telles que "être sur", "entre", "congruent". La description exacte et appropriée au but des mathématiques de ces relations est donnée par les axiomes de la géométrie".

Alors pourquoi une telle démarche ? L'intérêt, dans l'idée de Hilbert, est de retirer totalement le sens usuel, les définitions courantes et le sens intuitif que l'on peut accorder à certains mots, certaines notions qui sont utilisées en mathématiques, et en géométrie plus particuliérement.

Pour reprendre notre exemple de tout à l'heure, au lieu de "Socrates est un homme" et "Tous les hommes sont mortels", on aurait "X est un A", "Tous les A sont des P", desquels on pourrait conclure que "X est un P".

Aprés avoir terminé son axiomatisation de la géométrie, Hilbert va s'attaquer entre 1901 et 1908 à l'axiomatisation de l'analyse, la branche des mathématiques qui sert à étudier la notion de "limite".

C'est à ce moment qu'il va développer ce qu'il appelle la "théorie spectrale", connue aujourd'hui comme la "théorie des espace de Hilbert".

Ces travaux, qui offrent de nouvelle méthodes pour résoudre des équations intégrales, vont vont êtres au centre des travaux de Weyl, Von Neumann, Schrödinger, de Bohr et d'Heisenberg. 

Heisenberg va dire : "Indirectement, Hibert exerça la plus grande influence sur le développement de la physique [...] Les méthodes mathématiques de la mécanique quantique sont une application directe de la théorie hilbertienne des équations intégrales".

Alors le travail d’axiomatisation, qui est finalement la constante dans le parcours mathématique d’Hilbert, n’est pas simplement d’établir une liste d’axiomes. Il faut également pouvoir montrer que ces axiomes sont cohérents, et qu’on ne peut pas construire à partir des axiomes de propositions contradictoires.

Pour cela, Hilbert, comme le reste des mathématiciens, procède par analogie. Si il peut exprimer les axiomes de la géométrie, ou de l’analyse, sous forme algébriques, alors ces axiomes sont considérés comme valides, ou consistants comme on le dit en mathématiques.

L’idée est que, la théorie des nombres algébriques est le domaine mathématique le plus sûr et le plus fiable que nous possédons. Si les axiomes de la géométrie par exemple étaient contradictoires, alors, cette contradiction s’étendrait à l’algèbre, une fois les axiomes « traduits ».

Puisque l’algèbre est sûre et peu contestable, une traduction des axiomes vers l’algèbre constitue un preuve de consistance suffisante pour la communauté mathématique.

Pourtant, la méthode commence à poser problème. Entre 1897 et 1905, trois paradoxes vont être révélés en théorie des ensembles, et ces paradoxes, qui révèlent des contradictions dans la théorie des ensembles, s’étendent alors à l’algèbre.

La théorie des nombres algébrique ne serait pas aussi sûre que ça. Il faudrait donc pouvoir prouver la consistance de l’algèbre elle-même, mais personne n’a de méthode pour ça. On ne peux pas comparer l’algèbre avec elle-même comme on le faisait pour les autres théories.

Alors c’est le début de la quête du fondement, la quête d’une preuve de consistance des axiomes de l’arithmétique. Mais avant de vraiment continuer, il faut que je vous explique quels sont les trois paradoxes qui ont provoqués ce véritable tremblement de terre en mathématiques. 

La théorie des ensembles, dans laquelle se passent les paradoxes, à été développée entre 1873 et 1897 par Georg Cantor, qui va , à l’aide de cette théorie, parvenir à des conclusions contres-intuitives, qu’on pourrait même qualifier d’étranges.

Alors cette théorie, du fait de ces résultats inattendus, provoquera un certain scepticisme chez des mathématiciens comme Kronecker et Pointcaré. Hilbert d’un autre côté sera lui, un vif supporter de la théorie.

La théorie des ensembles qui permet d'étudier des collections d'objets, qui sont définis par une propriété commune. Par exemple on peut considérer l’ensemble de tous les nombres pairs, ou l'ensemble des nombres inférieurs à trois. 

Pour compter, pour définir la « taille » d’un ensemble, Cantor propose la notion de « cardinalité ». Deux ensembles qui contiennent le même nombre d’éléments possèdent la même cardinalité, et c’est bien pratique lorsqu’on cherche à comparer des ensembles très grands, voir infinis.

Comment comparer, si ce n’est grâce à la cardinalité, l’ensemble des nombres pairs, qui est infini, et l’ensemble des nombres entiers, qui est également infini ?

Alors on peut tenter d’associer chaque élément d’un ensemble, à un seul et unique élément d’un autre ensemble, c’est ce qui s’appelle en mathématique faire une correspondance bi-univoque.

On peut associer le nombre « 1 » de l’ensemble des nombres entiers, au nombre « 2 » de l’ensemble des entiers pairs. Et on peut continuer e associant le « 2 » des nombres entiers au « 4 » des nombres pairs, puis le « 3 » au « 6 ».

Et il apparait une sorte de règle générale, puisqu’on peut associer les éléments des deux ensembles en suivant une règle de calcul très simple : le nombre « x » des entiers est associé au nombre « x*2 » des entiers pairs.

Ainsi, chaque éléments du premier ensemble est associé à un et un seul élément du deuxième ensemble, et réciproquement. 

On peut donc affirmer que ces deux ensembles possédent la même "cardinalité", c'est à dire, la même taille. Et c’est déjà un premier résultat étrange, puisqu’on vient de montrer que l’infini de tous les nombres entiers fait exactement la même taille que l’infini des nombres pairs, alors qu’on aurait pu croire qu’il existe plus de nombres entiers que de nombres entiers pairs.

Alors on pourrait penser maintenant que tous les infinis se valent, qu’il sont tous de la même « taille ». Mais c’est justement ce que Cantor va contredire, en cherchant un ensemble infini pour lequel on ne pourrait pas faire de correspandece bi-univoque avec l’ensemble des nombres entiers.

Et il va le trouver, cet ensemble, c’est l’ensemble des nombres réels, ce sont les nombres à virgules, qui forment une ligne continue si on les représentait graphiquement, à l’inverse d la nature « discrète » des nombres entiers, qui laissent des espaces vides entre les valeurs.

Alors la peule de Cantor est très intéressante, c’est ce qu’on appelle la méthode de « diagonalisation ». 

Cantor commence par imaginer que l’enseble des nombres entiers et l’ensembles des nombres réels possèdent la même cardinalité, donc on peut faire une association un à un de tous les éléments que ces deux ensembles contiennent.

Et Cantor présente cette association sous forme de liste, le nombre « 1 » est associé à un nombre réel choisi aléatoirement, en dessous de lui, le nombre « 2 » est associé à un autre réel, puis le « 3 », le « 4 », et ainsi de suite jusqu’à l’infini.

À partir de cette liste, Cantor nous propose de sélectionner des chiffres spécifiques choisis, c’est la diagonalisation. On prends le chiffre à la première position du premier nombre réel, celui à la seconde position du second nombre réel, à la troisième position du troisième réel, etc.

Puis, nous allons modifier chacun de ces chiffres ainsi récupérés, en suivant une règle simple : Si le chiffre est un 0, on le remplacera par un 1, si c’est autre chose qu’un 0, on le remplacera par un 0.

En positionnant tous ces chiffres les uns à la suite des autres, nous avons crée un nouveau nombre réel, mais qui a une particularité essentielle, il est différent de tous les nombres de la liste.

Il est différent du premier nombre puisque le chiffre à la première position est différent, il est différent du second nombre puisque le chiffre à la seconde position est différent, et de même pour tous les nombres de la liste.

Mais si on peut créer un nombre, qui est un nombre réel, et qui n’est pas déjà dans la liste, ça veut dire qu’on ne peut pas, c’est impossible, faire de correspondance bi-univoque entre l’ensemble des réels et l’ensemble des entiers.

L’infini des nombres réels est donc « plus grand » que l’infini des nombres entiers. C’est une idée que je ne sais pas vraiment comment qualifier, peut-être terrifiante. il est déjà difficile de s’imaginer l’infini, mais comment est-ce que l’on peut se représenter quelque chose qui est plus grand que l’infini, c’est terrible.

Et c’est justement pour étudier encore les différentes « tailles » d’infinis que Cantor va ajouter à la théorie des ensembles ce qu’il appelle les nombres ordinaux.

Les nombres ordinaux servent à décrire à la fois la quantité, mais aussi l'ordre des éléments d'un ensemble. Alors à chaque ensemble, ordonné, corresponds un nombre ordinal. 

Et c’est là que le mathématicien italien, Cesare Burali-Forti, va trouver un problème de taille en 1897, avec les nombres ordinaux.

Burali-Forti cherche à calculer le nombre ordinal associé à l’ensemble de tous les nombres ordinaux. Problème, dés qu’il calcule le nombre ordinal, l’ensemble de tous les ordinaux, qui sert de base au calcul, est modifié, donc le nouveau nombre ordinal ne représente pas tous les nombres ordinaux, seulement tous ceux qui le précédent.

Et c’est là le paradoxe : Tous les ensembles ordonnés devraient être associé à un nombre ordinal, et pourtant, il y ne peut pas exister de nombre ordinal pour l’ensemble des nombres ordinaux. Alors c’est un problème.

Ensuite, c’est Bertrand Russell qui, en 1902, va mettre à jour un second paradoxe, il va dire : l'ensemble des cuillères à thé n'est pas lui-même une cuillère à thé, il ne s'appartient pas à lui-même. Qu’en est-il pour l'ensemble de tous les ensembles qui ne s'appartiennent pas à eux-mêmes ?

Si cet ensemble s'appartenait à lui-même, il correspondrait à sa propre définition,  c’est à dire un ensemble qui ne s'appartient pas à lui-même, donc s'il s'appartient à lui-même, il ne s'appartient pas à lui-même. Mais s'il ne s'appartient pas à lui-même, alors il mérite de faire partie de l’ensemble des ensembles qui ne s'appartiennent pas à eux-mêmes, donc, il s'appartient à lui-même.

Pris dans son élan, Russell va appliquer la même logique à l'ordre des concepts. "Être vert" est un concept, on peut dire qu'une pomme "est verte", mais "être vert" n'est pas vert lui-même, il ne s'applique donc pas à lui-même. C’est ce qu’on appelle un concept hétérologique.

Mais l’hétérologie elle-même est-elle hétérologique ? Si oui, alors le concept s’appliquerait à lui-même et ne serait donc pas hétérologique, mais s’il ne l’est pas, alors, comme il ne s’applique pas à lui-même, il devient hétérologique.

David Hilbert n'est pas surpris par les réflexions de Russuel, dans une lettre à Frege, il raconte qu’un autre mathématicien est lui aussi est arrivé à la même conclusion que Russell, et que le paradoxe est  déjà connu à Göttingen depuis trois ou quatre ans.

Le dernier paradoxe de la série sera attribué à Antoine Richard, en 1905, qui va emprunter la méthode de diagonalisation de Cantor.

Richard commence par faire la liste de tous les nombres définis en moins de mille mots, puis, par diagonalisation, crée une nouveau nombre qui n’est pas déjà dans la liste. Problème, la méthode de diagonalisation s’explique en moins de mille mots, donc le nouveau nombre devrait être déjà dans la liste, ce que la diagonalisation empêche.

Alors, on pourrait penser que le problème, finalement, c’est la théorie des ensembles, qui n’est pas correcte, mais souvenez vous que la validité de la théorie des ensembles repose sur la validité de l’arithmétique. Les paradoxes trouvés en théorie des ensemble se répercutent donc sur l’arithmétique, et finalement sur l’ensemble de toutes les différentes branches mathématiques dont l’arithmétique est le support.

Il s'agit maintenant pour les mathématiciens de refaire l'arithmétique, de repenser ses axiomes, afin de supprimer les paradoxes déjà connus, et de se prévenir contre des paradoxes futurs. Il faudra fournir aux nouveaux axiomes de l’arithmétique une preuve de consistance, seulement, personne n’a la moindre idée de comment faire.

Hilbert en 1900 s'était déjà exprimé sur la nécessité d'une preuve de consistance pour l'arithmétique. C’était au congrès international des mathématiciens à Paris.

Hilbert devait y donner une conférence, un exposé général sur les mathématiques, mais c'est Minkowski, son ami de Köningsberg qui va lui donner une autre idée. Il écrit à Hilbert le 5 janvier : "Il serait intéressant de regarder dans le futur et de faire une liste des problèmes sur lesquels les mathématiciens travaillerons dans le siècle qui vient. Avec un tel sujet, on parlera encore de ton exposé dans plusieurs décennies".

Il n’avait pas tort Minkowski, et Hilbert va présenter une liste de 23 problèmes qui vont occuper la quasi-totalité de la recherche mathématique sur la première moitié du 20ème siècle, et encore aujourd'hui, certains problèmes ne sont toujours pas résolus.

Alors, dans cette liste, j’aimerais vous lire le second problème, qui trouve au coeur de la recherche des fondements une résonance particulière : "Peut-on prouver la cohérence de l'arithmétique ? En d'autres termes, peut-on démontrer que les axiomes de l'arithmétique ne sont pas contradictoires ?".

En 1904 ensuite, Hilbert va tenter dans le cadre d'une conférence intitulée "Sur les fondements de la logique et de l'arithmétique", une démonstrations de consistance pour un système minimaliste d'axiomes qui ne représentent que les nombres entiers, et la notion d'égalité entre ces nombres.

La démonstration sera vivement critiqué par Pointacré, mathématicien influent, qui ne partage pas certaines idées d'Hilbert.

Hilbert estime que les objets mathématiques, les nombres par exemple, existent, qu’ils sont réels. Un nombre, n’importe lequel, existe, même si personne ne l’a jamais écrit, même si personne ne l’a jamais calculé, ce nombre, et tous les autres nombres, fonctions, droites, vecteurs, existent. 

C’est une conviction que Pointcaré ne partage pas, tout au contraire, pour lui, les nombres sont construit par les mathématiciens, un nombre n’existe qu’une fois que le mathématicien l’a calculé, ou définit.

Et ces différents points de vue sur les mathématiques changent la façon de faire des mathématiques.

Pour Pointacré par exemple, on ne peux pas parler d'infini, puisque les nombres n'existent pas, on ne saurait avoir une collection qui regroupe tous les nombres, ou avoir l’ensemble de tous les ensemble, comme dans la paradoxe de Russell.

Pointcaré va expliquer les paradoxes du point de vue du constructivisme. Pour le paradoxe de Richard, le dernier que je vous ai raconté, il n’y a pas de paradoxe, simplement une mauvaise utilisation des mathématiques.

Pourquoi le nombre crée à partir de la diagonalisation aurait dû être dans la liste des nombres définit en moins de milles mots. On ne pouvais pas l’inclure dans cette liste puisqu’au moment de créer la liste, le nombre en question n’existait tout simplement pas.

Chez Pointacré, les paradoxes s’expliquent par le principe du cercle vicieux : ce sont tous des objets qui font référence à eux-mêmes dans leur propre définitions, ils ont besoin de déjà exister pour exister. 

Et c’est le même reproche que Pointcaré fait à la démonstration de Hilbert de 1904. Hilbert utilise les nombres pour définir les nombres, c’est le cercle vicieux qu’il faudrait interdire des mathématiques.

Tout le monde, bien entendu, ne partage pas le sentiment de Pointcaré sur les mathématiques, à commencer par Hilbert. Mais il est apparu, depuis la mise en évidence du cercle vicieux, que pour donner une preuve de consistance de l’arithmétique, il fallait différencier deux choses : d’un côté, les notions que l’on veut prouver, et de l’autre, celles qui serviront à la preuve.

Principalement, c’est la notion de l'infini qui pose problème, puisque l’infini présuppose l'existence en soi des objets mathématiques. 

Alors Hilbert va choisir de diviser l'arithmétique en deux domaines. D'un côté, la mathématique formelle, qui décrit l'ensembles des mathématiques, l’infini y compris. Et d'un autre côté, ce qu’on va appeler la mathématique contentuelle, puisqu’elle conserve le sens usuel, le contenu des notions mathématiques, et qui se limite à ce qui est immédiatement évident : les nombres entiers, les opérations basiques, etc.

L’idée d’Hilbert est simple, réussir à prouver l’ensemble de l’édifice mathématique grâce à des notions que personne ne conteste. Puisqu’en dehors du formalisme d’Hilbert, il existe d’autres courants et d’autres mathématiciens qui se sont penchés sur la question du fondement.

Parlons d'abord de Bertrand Russell, et de son ami, Alfred North Whitehead. Ils vont tenter une axiomatisation de l’ensemble des mathématiques, inspirés par un précédent article de Russell : « La logique mathématique fondée sur la théorie des types ».

La théorie des types cherche à hiérarchiser les différentes notions des mathématiques. Ainsi, le notions de rang 1 s’appliquent à celles de rang 2, qui s’appliquent aux notions de rang 3, etc.

Cette hiérarchie permet d'éviter qu'une notion ne s'applique à elle-même, et donc d’éviter le cercle vicieux décrit par Pointcaré.

Russell et Whitehead vont publier leur axiomatique globale en plusieurs énormes volumes, intitulés « Principia Mathematica ». Mais il y manque la preuve de consistance.

Russell, qui s’occupe principalement des questions philosophiques liées à l’ouvrage, estime que les axiomes sont des notions intuitives, évidentes, et nécessairement vraies. Une preuve de consistance ne serait qu’une simple validation de l’évidence des axiomes, et elle n’est finalement pas très importante.

Mais Hilbert commentera, quelques années plus tard : "La théorie des fondements de Russell et Whitehead [...] fait reposer les mathématiques sur l'axiome de l'infini et sur un axiome dit de réductibilité. Or ces deux axiomes sont d'authentiques hypothèses qui ne peuvent s'appuyer [...] sur une preuve de consistance [... et] dont la validité universelle reste même ouverte au doute".

L’évidence des axiomes de Russell et Whitehead n’est donc pas si évidente que ça.

Ailleurs, aux Pays-Bas, on trouve Brouwer, qui place l’évidence immédiate et l’intuition au coeur des mathématiques. Pour lui et le reste des « intuitionnistes », il faut bannir des mathématiques tout ce qui n’est pas immédiatement évident.

Les paradoxes étaient un avertissement : un usage abusif des règles de la logique, qui font abstraction, comme on l’a vu, du sens des notions, crée finalement des énoncés vides, et des paradoxes.

Brouwer est finalement assez proche des positions de Pointcaré, il prône une vision constructiviste des mathématiques, et bannit l’infini, même si pour ça, il doit renoncer à certains outils les plus pratiques des mathématiques, et en particulier, le principe du « tiers exclu »..

Le principe du tiers exclu, qui repose sur les notions d'infini et d'existence en soi des objets mathématiques, permet de dire que soit une propriété est vraie, soit son opposé est vrai, il n’y a pas de troisième option.

Avec le tiers exclu, un problème mathématique est soit vrai, soit faux, c'est ce qui fera dire à Brouwer que : "La question de la validité du tiers exclu équivaut à celle de la possibilité de problèmes mathématiques non résolubles".

On se rappelle, Hilbert avait défendu la résolubilité de tout problème mathématique. Il avait dit au congrès international en 1900 : « Jamais le mathématicien ne sera réduit à dire Ignorabimus ! ».

Ignorabimus, la citation latine qui signifie « on ne sait pas, et on ne saura pas ».

Mais l’intuitionnisme va gagner en influence, au point même de convaincre Herman Weyl, un ancien étudiant de Hilbert qui s'oppose maintenant à son professeur : "Si les mathématiques doivent rester une préoccupation culturelle sérieuse, alors un certain sens doit être attaché au jeu de formules de Hilbert, et je ne vois qu'une seule possibilité de lui attribuer un sens intellectuel indépendant. En physique théorique, nous avons devant nous le grand exemple d'une connaissance d'un caractère tout à fait différent de la connaissance commune qui exprime purement ce qui est donné dans l'intuition".

Comprenons, en physique, l’intuition, c’est à dire l’expérience, prends le pas sur les formules de calculs. Mais les mathématiques, qui représente la pensée logique, et la physique, qui décrit les phénomènes réels, ne sont pas tout à fait les même sciences.

Alors Hilbert répondra également aux intuitionnistes, et va leur dire : "Oter le [tiers exclu] au mathématicien serait comme si on voulait enlever à l'astronome son télescope, au boxeur le droit de se servir de son poing. [... C'est] quasiment à renoncer à la science mathématique. Car que sont les misérables restes, qu'est-ce que la poignée de résultats incomplets et disparates que les intuitionnistes ont pu élaborer [...] à l'égard de l'étendue formidable de la mathématique contemporaine ?".

C’est vrai qu’il y a un certain panache dans cette déclaration, mais encore faut-il qu’Hilbert élabore sa propre réponse au problème du fondement. Et les choses vont se préciser à partir de 1922 et jusqu’en 1930, avec une série d’article dans lesquels Hilbert dessine petit à petit son programme formaliste.

L'objectif du programme est d'établir une mathématique formelle, pure de forme et vide de sens. C'est la méthode axiomatique poussée à son maximum. Une mathématique d'axiomes et de logique, où l'intuition et l'évidence immédiate n'ont pas leur place.

Et pour valider, pour justifier cette mathématique formelle, Hilbert définit la mathématique contentuelle, on parlera aussi de mathématique finitiste, qui n’utilise que les notions clairement établies, et acceptées par la communautés mathématique dans son ensemble le plus large.

Comme le dit Hilbert, il s'agit de "s'assurer par le fini le droit d'opérer sur l'infini".

C’est la force du programme formaliste, on utilise les mathématiques pour justifier les mathématiques, et c’est ce qui permettra à Hilbert un petit commentaire, disant qu’il n’a "besoin ni du Bon Dieu, comme Kronecker, ni de l'hypothèse d'une faculté de conscience accordée au principe d'induction complète, comme Pointcarré, ni de l'intuition originelle de Brouwer, ni non plus des axiomes de l'infini [comme Russell et Whitehead]". 

D’ailleurs, et ce sont les paroles de Hilbert encore, formaliser "c'est dépeindre l'activité de notre intelligence", c'est "dresser un inventaire des règles d'après lesquelles fonctionne réellement notre pensée".


——


Mais malgrès la force de leurs arguments épistémologique, les mathématiciens engagés dans le programme, Hilbert, Bernays, Von Neumann ou Ackermann, pour n'en citer que quelques-uns, n'ont toujours pas de résultats. Toutes les différentes tentatives d'axiomatisation et de preuve de consistence ont échoués.

C'est alors que Hilbert prendra la parole, au congrès internationnal de Bologne, en 1928. Là, il lance à ses pairs trois problèmes ouverts : L'axiomatique formelle est-elle compléte ? consistante ? et décidable ?

L'axiomatique formelle est-elle complète ? C'est à dire que n'importe quelle proposition ou formule crée à partir des axiomes est nécéssairement soit démontrable, soit réfutable. Ça serait la validation du principe du tiers exclu et de l'idée de la résolubilité de tout problème mathématique. "Jamais le mathématicien ne sera réduit à dire Ignorabimus" !

L'axiomatique formelle est-elle consistante ? C'est la preuve de non-contradiction que cherchent les mathématiciens depuis l'apparition des paradoxes en théorie des ensembles. Qui permettrait de justifier la totalité de l'édifice mathématique et de donner à la science des fondations solides, irréfutables.

L'axiomatique formelle est-elle décidable ? Est-ce qu'il existe une méthode effective, qui permette de décider si une formule donnée est démontrable ou réfutable ? Si elle est vraie ou fausse ?

Bien entendu, Hilbert espére que les trois réponses à ces trois problèmes seront positives. C'est même à cette condition seulement que pourrait se poursuivre le programme formaliste. D'ailleurs, tout semble bien parti, toujours au cours de la conférence, Hilbert annonce qu'Ackermann et Von Neumann sont parvenus à prouver la consistance de l'axiomatique formelle.

Il annonce aussi que lui-même et Ackermann pensent pouvoir bientôt amener la preuve de la complétude des "prédicats du premier ordre". Certes, le calcul des prédicats ne représentent pas toute l'arithmétique, mais c'est la partie la plus importante : ils décrivent les règles de la logique. Sans calcul des prédicats, impossible de construire une démonstration ou un théorème en mathématique.

Mais si tout s'annonce bien, c'était sans compter sur la présence au congrés de Bologne d'un mathématicien d'origine Autrichienne : Kurt Gödel.

La nationalité de Gödel fait débat : il est né à Brno, en Autriche-Hongrie, mais sera naturalisé Tchécoslovaque en 1918, à la dissolution de l'Autriche-Hongrie. Attaché à ses racines, il retrouvera la nationnalité Autrichienne en 1929, seulement pour devenir Allemand aprés l'annexion de son pays en 1938. Il finirat par s'exiler aux États-Unis, où il n'obtient la nationnalité que grâce au support de son ami, Albert Einstein.

Mais laiisons là cette histoire et retournons aux fondements. Je vous avais dit qu'en 1928 congrés de Bologne, Hilbert avait annoncé pouvoir apporter la preuve de la complétude des prédicats du premier ordre avec Ackermann. C'est en fait Gödel qui arrivera le premier à démontrer la complétude de cette partie de l'arithmétique, en 1929.

Mais c'est ensuite, en 1931, que Gödel va marquer l'histoire de la recherche des fondements en mathématiques. Le 26 Août 1930, Gödel assiste à une conférence à Köningsberg, Heyting y parle de l'intuitionnisme, Von Neumann parle du formalisme, et Hilbert annonce sa retraite dans un discourt : "Contrairement à l'Ignorabimus stupide, notre credo est: Nous devons savoir. Nous le saurons!", "Wir müssen wissen. Wir werden wissen!", des mots qui seront inscrits sur son épitaphe.

Au cours d'une discussion fortuite, Gödel va présenter à quelques-une de ses pairs le premier théorème d'incomplétude : "Si l'arithmétique élémantaire est ω-consistante, elle comporte des formules fermées qui ne sont ni démontrables, ni réfutables à partir des axiomes". Von Neumann commentera instantanément : "Tout est fini" !

Et il a raison, puisque le théoréme d'incomplétude signe la fin du programme formaliste dans sa forme actuelle. En clair, le théorème dit que n'importe quelle axiomatique, à partir du moment où elle suffisament expressive pour représenter les nombres entiers et les opérations d'addition et de multiplication, est nécéssairement soit inconsistante, soit incompléte. Pour Hilbert qui voulait contruire une axiomatique, qui soit à la fois consistante, compléte et décidable, c'est la catastrophe.

Gödel parvient à ce résultat en montrant que pour n'importe quelle axiomatique, dans laquelle on puisse représenter l'arithématique élémentaire, il peut construire une proposition qui dit "Je ne suis pas démontrable".

De là, deux possibilités, soit la formuler est démontrable, et c'est terrible puisqu'on vient de démontrer quelquechose d'évidement faux, donc le système est inconsistant. Soit, la formule n'est pas démontrable, auquel cas, elle dit vrai. On se retrouve alors avec une formule vraie, mais qui n'est pas démontrable, donc le système est incomplet (dans un système complet, toute les formules vraies sont démontrables).

Von Neumann écrira à Gödel le 20 Novembre 1930 pour lui dire qu'il à trouvé un second théorème à partir du premier : "la consistance d'un systéme ne peut pas être établie au moyen de raisonnements qui se laisseraient formaliser dans le systéme".

Gödel est en fait déjà arrivé à la même conclusion quelques jours plus tôt. Pour le programme formaliste, c'est un nouveau coup dur, Hilbert voulait démontrer l'axiomatique formelle à l'aide de la mathématique finitiste, ce que le second théorème d'incomplétude interdit.

Les deux thèorèmes seront publiés en Janvier 1931 dans une revue mathématique Viennoise. En apprenant les théorèmes de Gödel, Hilbert rentra dans une colère noire. Peut-être parcequ'il n'a pas trouvé lui même ce que Gödel considére comme une "conséquence presque triviale" des travaux de Skolem, mais qu'il n'avait pas remarqué de faute de n'avoir pas quité un point de vue strictement finitiste. Ou alors, plus simplement, parceque ces deux théorèmes d'incomplétude semblent signer la fin du programme formaliste et de la recherche du fondement.

Ce n'est pourtant pas le cas, Gödel commentera d'ailleurs : "il reste un espoir pour que dans le futur on puisse trouver des méthodes satisfaisantes [...] dépassant les limites du système [finitiste de Hilbert] et permettant de fonder l'arithmétique classique et l'analyse. Cette question ouvre un champ de recherches fécond". Et ajoute dans un second commentaire : "la conviction dans la décidabilité de tout problème mathématique n'est pas ébranlée par ce résultat".

Je crois que Gödel est au moins aussi triste que Hilbert d'avoir trouvé les théorèmes d'incomplétudes. Il partage plusieurs croyances sur le monde mathématique avec Hilbert, il dit : "les mathématiques décrivent une réalité non sensible, qui existe indépendament des actes et des facultés de l'esprit humain et n'est que perçue, et probablement perçue de façon très incomplète". C'est l'expression de l'existance en soi des objets mathématiques.

Gôdel reviendra d'ailleurs sur la quête des fondements en 1947, et il explique maintenant l'indécidabilité de certains problèmes, cette indécidabilité qu'il a mise à jour, par le manque d'axiomes, ou l'imprécision de ceux-ci : "les concepts et les théorémes de la théorie des ensembles décrivent une réalité bien déterminée, dans laquelle la conjecture de Cantor est vraie ou fausse. Ainsi son indécidabilité à partir des axiomes acceptés aujourd'hui peut seulement signifier que ces axiomes ne contiennent pas une description complète de cette réalité".

Mais Gôdel ne sera pas le seul à commenter sur ses théorèmes, c'est Von Neumann cette fois qu'on écoute : "Ce résultat imposant de l'analyse de Gödel ne doit pas être mal compris: il n'exclut pas une preuve  méta-mathématique de la consistance de l'arithmétique. [...] Gödel a montré qu'aucune preuve n'est possible qui peut être représentée au sein de l'arithmétique. Son argument ne supprime pas la possibilité de preuves strictement finitiste qui ne sont pas représentés au sein de l'arithmétique. Mais personne aujourd'hui ne semble avoir une idée claire de ce qu'une preuve finitiste serait qui ne serait pas formulable dans l'arithmétique".

Mais de toute les manières, même si on voulait abandonner le programme formaliste, il reste une question à résoudre, la décidabilité. L'axiomatique formelle est-elle décidable ? Bon, depuis les résultats de Gödel, on se doute que la réponse sera négative : il n'existe pas de procédure effective qui puisse décider si une formule donnée est démontrable ou non. Encore faudra t-il le prouver.

Et ça va devenir d'autant plus important qu'au sein de la question de la décidabilité se trouve la notion de procédure effective, mais, le terme qu'utilise Hilbert de "procédure effective" ne dispose pas de définition formelle. En fait, la notion de "procédure effective" renvoie à la notion de "calculabilité".

Depuis le 18éme siècle, les mathématiciens ont associé l'idée de calcul avec l'idée de fonction. Mais les fonctions évoluent au 19ème siécle pour ne plus décrire qu'une correspondance entre un point de départ et un point d'arrivé, sans qu'un calcul effectif n'ait besoin d'être réalisée. On commence alors à dissocier les fonctions en deux groupes, celles qui possédent une procédure de calcul effective, les fonction calculables, et les autres, les non-calculables.

Il s'agit alors de trouver une définition au terme de "procédure effective", de "calculabilité", qui engloble toute les fonctions calculables, et mette les autres de côté.

Si je vous ai dit que la question de la décidabilité était devenue d'autant plus importante après les théorèmes d'incomplétude de Gödel, c'est que les théorèmes sont généralisables, mais cette généralisation ne peut se faire qu'une fois qu'on aura une définition satisfaisante de la calculabilité.

Alors ce sont trois mathématiciens qui vont tenter de résoudre ce problème. Gödel d'abord, mais on ne parlera pas de ses recherches, elles sont compliquées et n'aboutissent pas. En revanche, on va parler un peu des travaux d'Alonzo Chruch, et surtout, on verra en détail l'article fondateur d'un jeune mathématicien anglais : Alan Turing.

Church d'abord, établit à Princeton aux États-Unis, il publie en 1936 une preuve de l'indécidabilité de l'arithématique, à l'aide d'un système de calcul qu'il développe en 1932 et 1933, le λ-calcul.

Le λ-calcul est un système formel qui permet de décrire l'ensemble des fonctions calculables. Une fonction est décrire par une expression, qui peut elle-même contenir d'autres fonctions. Afin de créer des fonctions de plus en plus complexes, on peut "appliquer" une fonction à une autre, en clair, on doit d'abord calculer le résultat d'une première fonction, pour ensuite réutiliser ce résultat lors du calcul de la second fonction.

C'est à partir de cette base seulement que l'on peut construire n'importe quelle fonction calculable. Pour vous donner quelques exemples simples, on peut construire la fonction d'identité, qui ne modifie pas la valeur qu'on lui donne : λx.x. On peut aussi construire une fonction constante qui à n'importe quelle valeur fait correspondre la valeur 2 : λx.2.

À partir de ces deux fonctions, on peut les assembler pour créer une fonction qui fabrique des fonctions constantes : λx(λy.x). SI j'envoie la valeur 2, je récupére la fonction constante à 2 : λy.2.

Le λ-calcul permet à Church d'identifier la limite des fonctions calculables, et va lui servir de base pour fournir la démonstration que l'arithmétique n'est pas décidable. Mais si le principe est simple, le λ-calcul est difficile à lire et à relire, et la vérification des résultats de Church est un vrai casse-tête pour le reste des mathématiciens. Tous ne sont pas convaincu.

Stephen Kleene par exemple, un étudiant d'Hilbert qui se souvient de la méthode de diagonalisation de Cantor. Kleene pense que la diagonalisation empêche toute définition formelle de la calculabilité. L'idée est simple : si on a une définition, on peut alors faire une liste de toutes les fonctions calculables, puis, par diagonalisation, on va créer une nouvelle fonction calculable qui n'était pas dans la liste, donc qui n'était pas incluse par la définition de calculabilité, donc la définition est mauvaise.

C'est ce qu'il va immédiatement tenter de faire : "Lorsque Church me proposa sa thèse [pour une définition de la calculabilité], je me mis aussitôt à la tâche de la réfuter par une diagonalisation de la classe des fonctions [calculables]. Mais, réalisant vite que la diagonalisation ne pouvait être faite de façon effective, je devins du jour au lendemain partisan de la thèse de Church".

La définition de Church, de la calculabilité, est bonne, mais quelques mois plus tard, et sans connaitre les travaux de Church, Alan Turing propose une autre définition, identique du point de vue mathématique, mais bien plus simple à comprendre et à réaliser, c'est cette définition qui restera dans l'histoire, c'est la machine de Turing.

En 1935, Turing, qui est encore étudiant au King's College à Cambridge, en Angleterre, assiste au cours de son professeur Max Newman : "Fondement des mathématiques". Newman enseigne les théories de Hilbert, les théorèmes d'incomplétudes de Gödel et commente sur le problème de la décision : "Supposons, par exemple, que nous puission trouver un système fini de règles qui nous permettrait de dire si une formule quelconque est ou non démontrable. Ce système contiendrait un théorème de métamathématique. Évidemment, ce théorème n'existe pas et c'est heureux, parceque s'il existait, nous aurions un ensemble mécanique de règles nous permettant de trouver la solution de tous les problèmes mathématiques et notre activité en tant que mathématiciens cesserait d'exister".

C'est cette vision mécaniste du calcul, qui vient d'abord de Von Neumann, "il y aurait une instruction absolument mécanique à l'aide de laquelle quiconque pourrait décider, à partir de n'importe quelle formule donnée, si elle est ou non démontrable", qui va pousser Turing à essayer de trouver une machine pour définir la calculabilité.

Alors j'ai deux citations là dessus, une de Max Newman : "et cela bien sûr conduit [Turing] au prochain défi, quel type de machine ? Et cela l'a inspiré pour essayer de définir ce que l'on voudrait dire par une machine à calculer parfaitement générale".

L'autre citation vient de William Newman, qui est le fils de Max Newman, et qui à connu Alan Turing : "À un moment, il a posé sa classe une question: la prouvabilité des énoncés mathématiques pourrait-elle être découvert par un procédé mécanique ? Cette question est restée dans l'esprit d'Alan, et peu à peu, il a développé le papier qui allait faire sa réputation dans le monde mathématique"

Turing termine à la fin de l'été 1936, deux mois seulement après la publication de Church, un article "On Computable Numbers, with an Application to the Entscheidungsproblem", "Sur les nombres calculables, avec une application au problème de la décision".

Alors, rappelons-le c'est important, Turing, quand il termine son article et qu'il le montre en première lecture à Newman, son professeur, il ne connait pas encore les travaux de Church. Par contre, il les connait en janvier 1937, date où l'article de Turing est publié pour la première fois.

On le sait pour deux raisons, d'abord, parceque Turing mentionne les travaux de Church en introduction de l'article : "Selon ma définition, un nombre est calculable si [il] peut être écrit par une machine. [...] Dans un article récent Alonzo Church a introduit l'idée de "calculabilité effective", ce qui équivaut à ma "calculabilité", mais est définie de manière très différente. Church atteint également des conclusions similaires au sujet du problème de la décision. La preuve de l'équivalence entre "calculabilité" et "calculabilité effective" est décrite dans une annexe au présent document".

Et aussi, parceque Turing va s'installer pendant deux ans à l'université de Princeton, travailler sur des problèmes de logiques sous la direction de Church. C'est son professeur de Cambridge, Max Newman, qui à arrangé cette collaboration, il écrit dans une lettre à Church : "Je dois mentionner que le travail de Turing est entièrement indépendant: il a travaillé sans supervision ou critique de quiconque. Cela rend d'autant plus important qu'il devrait entrer en contact le plus tôt possible avec les principaux travailleurs de ce domaine, de sorte qu'il ne devrait pas se transformer en un solitaire confirmé."

Alors maintenant que nous avons décrit le contexte d'écriture de cet article fondateur de Turing, fondateur à plusieurs niveau on en parlera ensuite, on peut regarder et lire la définition dans le premier chapitre de l'article de cette fameuse machine de Turing.

"On peut comparer un homme en train de calculer un nombre à une machine qui est seulement capable d'un nombre fini de conditions, qui seront appelés "m-configurations". La machine est livrée avec une "bande" (l'analogue du papier) qui la traverse, et est divisée en sections (appelé "carrés") capables chacun de porter un "symbole". A tout moment, il y a juste un carré [...] qui est "dans la machine". Nous pouvons appeler cette place le "carré lu". Le symbole sur la carré lu peut être appelé le "symbole lu". Le "symbole lu" est le seul dont la machine est, pour ainsi dire, "directement au courant". Cependant, en modifiant sa m-configuration la machine peut se rappeler efficacement certains des symboles qu'elle a "vu" précédemment. Le comportement de la machine possible à tout moment est déterminé par la m-configuration [...] et [...] le symbole lu. Cette paire [...] sera appelé "configuration" : ainsi la configuration détermine le comportement possible de la machine. Dans certaines configurations dans lesquelles le carré lu est vierge (i.e. il ne porte pas de symbole), la machine écrit un nouveau symbole sur la place balayée: dans d'autres configurations, il efface le symbole lu. La machine peut également changer le carré en cours de lecture, mais seulement en le déplaçant d'une case à droite ou à gauche. En plus de l'une de ces opérations, la m-configuration peut être modifiée. Certains des symboles écrits formeront la séquence de chiffres [...] du nombre [...] qui est calculé. Les autres ne sont que des brouillons pour "aider la mémoire". [...] Je soutiens que ces opérations comprennent toutes celles qui sont utilisés dans le calcul d'un nombre."

Alors on a une description qui est très courte, et minimaliste, mais c'est tout à fait vonlontaire de la part de Turing puisqu'il veut forcer le lecteur qui veut comprendre à s'identifier à la manichine en train de réaliser un calcul. Et cette identification va renforcer les arguments épistémologiques, philosophiques de Turing par rapport à la justesse de sa machine.

On va passer sur quelques exemples donc, et on va d'ailleurs réutiliser les mêmes exemples que Alan Turing donne dans son article : "Une machine peut être construite pour calculer la séquence 0101001 ... [...] La machine posséde quatre m-configurations "b", "c", "f", "e" et est capable d'écrire "0" et "1". Le comportement de la machine est décrite dans le tableau suivant dans lequel "R" [ndl: Right en anglais, Droite] signifie "la machine se déplace de sorte à lire le carré immédiatement à la droite de celui qui était auparavant lu". De même, pour "L" [ndl: Left, Gauche]. "E" [ndl: Erase] signifie "le symbole lu est effacé" et "P" [ndl: Print] signifie "écrire". La machine démarre dans la m-configuration "b" et une bande vide. [b None P0, R c; c None R e; e None P1, R f; f None R b]"

Il faut que j'insiste sur un point avant de continuer. La table d'instruction qui décrit le comportement de la machine est unique pour chaque machine. La machine que nous venons de décrire n'est capable que de produire la suite 010101 ... De la même manière, il existe une machine capable de faire une soustraction, une pour la multiplication et une autre qui calcule π. Pour chaque calcul, chaque séquence calculable, il existe une machine de Turing.

On peut du coup considérer qu'un calcul en particulier est définissable par rapport à la machine de Turing qui effectue ce calcul. La séquence 010101 ... peut donc être définie par rapport à la machine qu'on a utilisé tout à l'heure. Et cette machine est caractérisé par rapport à sa table d'instruction.

Et si on code chaque ligne de la table d'instruction, on peut obtenir un nombre, que Turing apelle le "nombre standard", qui nous permet de représenter une machine de Turing, et donc, un calcul, sous forme numérique.

Pour faire ça, Turing propose une méthode : On commence la lister les m-configurations de la machines, de façon à pouvoir les identifier comme la "première" m-configuration, ou la "cinquième" m-configuration. On peut alors coder une m-configuration spécifique en utilisant la lettre "D", suivie par la lettre "A" autant de fois que nécéssaire pour décrire sa position dans la liste. Ainsi, la première m-configuration sera codée par "DA", la seconde par "DAA", la cinquième par "DAAAAA".

Et on peut procéder de la même manière pour les symboles qu'écrit la machine. On fait une liste de tout les symboles et on les code avec la lettre "D" suivi de la lettre "C". Le premier symbole sera "DC" et le troisième sera "DCCC".

En plus des m-configurations et des symboles, on va associer une lettre spécifique pour chaque opération de la machine, ainsi, on peut représenter la table d'instriction d'une machine par un code uniquement composé des caractères "A", "C", "D", "L", "R", "N" et ";". Le ";" est utilisé comme séparateur, pour différentier une ligne de l'autre.

La dernière étape est d'associer à chaque caractère un chiffre. Le "A" est remplacé par un "1", le "C" par "2", "D" par "3", "L" par "4", "R" par "5", "N" par "6" et finalement, ";" par "7".

Si je reprends la table d'instruction de notre machine d'exemple, on commence par renommer les m-configurations et les symboles : [table, q est m-configuration, S est symbole] [q1 S0 PS1,R q2; q2 S0 PS0,R q3; q3 S0 PS2,R q4; q4 S0 PS0,R q1]

Puis, on code chaque ligne de la table pour déterminier la "définition standard" : "DADDCRDAA;DAADDRDAAA;DAAADDCCRDAAAA;DAAAADDRDA". Et à partir de là, le nombre de la définition : 31332531173113353111731113322531111731111335317.

L'interêt de cette notation de Turing, c'est qu'on dispose maintenant d'un nombre qui décrit une machine de Turing. Et qu'on va pouvoir se servir de ce nombre pour étudier les propriètés de la machine qu'il décrit. Et en particulier, Turing cherche à savoir si il est possible de prédire, à partir du nombre standard d'une machine de Turing prise au hasard, si cette machine va aboutir à un résultat ou non.

On l'a déjà dit, Turing utilise ses machines pour définir la calculabilité, donc l'ensemble des machines de Turing représentent l'ensemble de tout ce qui est calculable. Mais il faut bien remarquer que les calculs n'aboutissent pas tous à un résultat. On peut très bien imaginer une machine de Turing qui inscrirait successivement, sur le même carrée de la bande, le symbole "0", puis "1", puis "2", puis "0", puis "1", puis "2", puis "0", et ainsi de suite, pour toujours. C'est ce que Turing appelle les machines "circulaires", elles tournent en boucle et n'arrivent jamais nulle part.

Alors c'est ça que Turing veut parvenir à deviner, décider à l'avance si une machine s'arrêtera ou non. C'est le problème de l'arrêt, et l'interêt de ce problème, c'est qu'il est presque identique au problème de la décision. Si on résouds le problème de l'arrêt, on aura également résolu le problème de la décision d'Hilbert.

Alors comme pour le problème de la décision, on peut supposer que c'est impossible de décider à l'avance si une machine de Turing que l'on choisit aléatoirement, appelons-la la machine M, si cette machine M est circulaire, donc qu'elle ne s'arrête jamais, ou bien si elle est sans cercle, c'est à dire qu'elle s'arrête.

Mais imaginons pour une seconde qu'il existe une procédure effective, donc une machine de Turing qui puisse décider à l'avance si la machine M est circulaire ou non. On appelera cette machine la machine D.

Comment fonctionne cette machine D ? On commence par lui donner, sur le ruban, le nombre de la description standard de la machine M, si la machine M s'arrête, la machine D va inscrire sur le ruban le symbole "s". En revanche, si la machine M est circulaire, si elle ne s'arrête jamais, la machine D va inscrire sur son ruban le symbole "u".

Maintenant, Turing nous propose de construire une autre machine, la machine U. Son fonctionnement est simple, si elle lit sur le ruban le symbole "u", la machine s'arrête immédiatement. Par contre, si elle lit le symbole "s", la machine U rentre dans une configuration où elle ne s'arrêtera pas.

On sait que cette machine U existe puisqu'il est finalement assez simple de trouver sa table d'instruction.

À partir des machines D et U, en les associants, on va créer la machine H. Donc la machine H, on lui fournit d'abord la description standard d'une machine de Turing, n'importe laquelle, la machine M.

La machine H calcule d'abord un résultat intermédiaire, soit le symbole "u", soit le symbole "s", en fonction si la machine M est circulaire ou non. Et puis, la machine H va soit s'arrêter immédiatement, soit ne jamais s'arrêter, en fonction de ce résultat intermédiaire.

Alors, que se passe t'il si on donne à la machine H sa propre définition stadard ? D'abord, elle doit calculer le résultat intermédiaire, deux solutions, soit la machine D prédit que la machine H s'arrête, soit que la machine H ne s'arrête pas, qu'elle est circulaire.

Si la machine H s'arrete, alors elle inscrit le symbole "s" sur la bande, et rentre dans une configuration où elle ne s'arrête pas. En court, si elle s'arrête, elle ne s'arrête pas. Et si elle ne s'arrête pas ? Dans ce cas, le résultat intermédiaire est un "u", donc la machine H s'arrête.

On a là une double contradiction, une situation impossible, ce qui signifie que les suppositions que l'on avait faites au départ, nos hypothéses, sont fausses. Et la seule hypothése que l'on avait faite, c'était qu'il existe une machine D qui puisse prédire si une autre machine de Turing est circulaire ou non. Cette machine D ne peut donc pas exister. On ne peux pas prédire à l'avance si une machine de Turing s'arrêtera.

Et exactement avec la même démonstration, on peut prouver qu'il n'existe pas de machine de Turing, de procédure effective, qui puisse déterminer si une autre machine inscrira le symbole "0" à un moment donnée dans son exécution.

C'est important pour le problème de la décision, puisque Turing va prouver, dans un language mathématique avancé que je ne développerais pas ici, que si il existe une méthode générale capable de décider si une formule est prouvable, alors, il existe une méthode générale pour déterminer si la machine de Turing correspondante à cette formule écrit "0".

Et comme on a déjà montré qu'une telle machine ne peux pas exister, alors, il n'y a également pas de processus pour déterminer si une formule est prouvable. D'où le problème de la décision ne peut pas être résolu.

Dans la suite de l'article, Turing va exposer plusieurs argument épistémologiques, philosophiques afin de justifier la validité de sa définition, des machines de Turing. Il va les comparer au cahier d'algébre, quadrillé, qu'utilisent les écoliers lorsqu'ils apprenant à calculer. Pour lui, le fonctionnement de ses machines est une bonne description de la façon que nous avons nous, humains, de penser.

C'est d'ailleurs cette validation philosophique qui fera la force de la définition de Turing, du modéle des machines de Turing pour décrire la calculabilité. C'est ce qui manquait au λ-calcul de Church.

Mais je vous avait dit que l'article de Turing était fondateur, alors il n'est pas fondateur pour les mathématiques. Il n'y a finalement aucun résultat nouveau dans ce que présente Turing.

Il propose une définition correcte de la calculabilité, mais on en avait déjà une avec celle de Church. Et d'ailleurs, au moment où l'article est publié, en janvier 1937, Turing à rajouté un appendice dans lequel il prouve que tout ce qu'on peut faire avec les machines de Turing, on peut le faire avec le λ-calcul. Et tout ce qu'on peut faire avec le λcalcul, on peut le faire avec les machines de Turing.

Alors les deux définitions sont bien équivalentes. Même si celle de Turing, qui est largement plus simple, fera l'objet d'une plus largeme approbation, et de l'avis de Church en premier lieu : l'identification avec l'effectivité dans l'ordinaire [...] semble immédiatement évident", ce sont le mots de Church.

On a aussi Gödel qui ajoutera en note à ses théorèmes d'incomplétudes : Grâce à certains travaux qui ont suivi cet article, en particulier ceux de A. M. Turing, nous disposons désormais d'une définition sûre, précise et adéquate du concept de système formel [...] dont la proprièté est qu'en son sein, et en principe, le raisonnement peut être entièrement remplacé par des règles mécaniques".

On a aussi dans l'article la solution, négative, au problème de la décision d'Hilbert. Mais là aussi, Church avait devancé Turing.

Alors si cet article est devenu tellement important par la suite, c'est à cause d'un chapitre dont je ne vous ai pas encore parlé, et qui décrit ce que Turing apelle la machine universelle.

C'est donc la première phrase du sixième chapitre de l'article, intitulé "La machine à calculer universelle" que je vous lis : "Il est possible d'inventer une machine unique qui peut être utilisée pour calculer toute séquence calculable. [...] Si cette machine U est fournie avec une bande sur laquelle est écrite la définition standard d'une machine M, U calculera la même séquence que M".

Il faut comprendre que c'est absolument extraordinaire ce que nous raconte Turing à ce moment là. Remettons-nous dans le contexte, en 1936, au moment où Turing rédige son article, on construit déjà, et depuis un certain temps maintenant, des machines. Mais chacune de ces machines est construite pour réaliser une tâche spécifique.

Et c'est bien la même chose pour les machines à calculer de l'époque. Des machines mécaniques qui vont nous sembler assez rudimentaires puisqu'elle ne permettent que de manipuler les quatres opérations de bases, l'addition, la soustraction, la multiplication et la division.

Mais il faut voir que chacune de ces opérations est réalisée grâce à un assemblage de roues, d'engrenages etc. Alors si on voulait ajouter une opération supplémentaire, il faudrait déssiner, ajouter un assemblage supplémentaire.

Et c'est en ça que la machine universelle de Turing est révolutionaire, c'est que Turing montre qu'on peut construire une machine unique, un assemblage unique, qui permettra de réaliser n'importe quel calcul, de calculer tout ce qui est calculable, à condition de lui fournir la description de ce calcul.

Et c'est là la seconde grande idée, le concept de programme. Alors il existe aussi des machines programmables, à commencer par le métier à tissier Jacquard, qui date de 1801. Mais le programme est toujours considéré comme une entité extérieure, immuable face à la machine.

Alors que dans la machine universelle, le programme est à l'intérieur de la machine, il est inscrit sur le ruban, ce qu'on peut considérer comme la "mémoire" de la machine. Et c'est aussi un endroit que la machine de Turing peut modifier, elle pourrait, pourquoi pas, se reprogrammer elle-même. Et c'est bien la première fois en 1936 qu'on peut envisager une telle posibilité.

Et c'est en ça que l'article de 1936 est fondateur, c'est parcequ'il pose les deux piliers théoriques, une machine unique capable de calculer tout ce qui est calculable, et le programme stocké en mémoire, qui seront fondamataux pour la science informatique à venir.
