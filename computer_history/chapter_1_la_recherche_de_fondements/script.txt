Bonjour. Aujourd'hui on va se lancer dans une longue histoire, un exposé de la naissance des premiers ordinateurs. Mais avant de commencer, j'aimerais vous répéter ce que m'a dit Jean Lassègue dans un entretient pendant que j'effectuais mes recherches. Il me disait que l'histoire de l'ordinateur peut-être soit vue d'un point de vue théorique. Les premiers ordinateurs seraient le fruit d'une réfléxion très théorique menée principalement par Turing et Von Neumann. Soit, l'autre version de la même histoire, c'est de considérer qu'il s'agit essentiellement d'une affaire d'ingénierie, et de la mise ou point, ou de la perfection, de machines calculantes.

Alors, on va essayer ensemble d'explorer les deux versans de cette histoire. Et pour commencer, on va remonter un peu avant le début du 20ème siècle, et suivre à travers le travail de David Hilbert ce que l'on appelle la quête du fondement mathématique, et qui va mener aux première théories de la science informatique.

Donc, David Hilbert, c'est un Allemand, et il va démarrer ses études en mathémtiques, contre l'avis de son père, à l'université de Köningsberg, qui, il faut le dire, est une des universités les plus réputés d'Allemagne.

C'est à Köningsberg qu'Hilbert va faire deux grandes rencontres. D'abord, il croise le chemin d'Adolf Huritz, qui est l'un de ses professeurs à l'unversité, mais surtout, Hilbert va se lier d'une trés grande amitié avec une autre étudiant, c'est Hermann Minkowsky.

Alors on a un témoignage direct de Hilbert de cette époque : "Ainsi, alors que j'étais encore étudiant, j'ai été poussé par Hurwitz au coeur des débats scientifiques et j'ai eu la chance, en étant avec lui, d'apprendre à connaître, d'une façon plaisante, les deux écoles opposées mais parfaitement complémentaires, l'école géométrique de Klein et l'école algébrique-analytique de Berlin. Lorsqu'il revenait dans sa famille à Köningsberg, le génial Minkowski, avec qui je m'étais déjà lié, se joignait à nous. Au cours de ces innombrables promenades, jour après jour, pendant huit années, nous avons fouillé tous les coins du savoir mathématique."

Après ses études, et après avoir pris le temps de voyager et de rencontrer certaines grands mathématiciens de son époque, Klein, Kronecker, Pointcaré; Hilbert va devenir "Privatdozent", que l'on peut traduire par "assistant".

C'est classique dans le système éducatif de l'époque, le "Privatdozent" peut enseigner mais ne touche pas de rémunération fixe, il est directement payé par les élèves qui choississent d'assister à ses cours, puisqu'il n'y a pas dans les universités de classes imposés. Les étudiants sont totalement libres, pendant quatres ans, jusqu'à l'examen final.

Mais ce statut lui offre également le temps, la flexibilité nécéssaire pour commencer un travail de recherche, et en particulier, Hilbert va s'intèresser à la théorie des invariants qui, depuis 20 ans maintenant, attends des réponses.

Le problème que l'on cherche à résoudre en théorie des invariants, c'est d'identifier certaines propriètés invariantes, qui ne changent pas, pour des formes représentées dans des espaces à plusieurs dimensions.

C'est grâce aux travaux de Gordan que l'on sait identifier les propriétés invariantes pour des formes dans des espaces à deux dimensions. Mais Gordant à dû réaliser une quantité déjà monumentale de calculs, et pour un nombre de dimensions supérieur on fait face à un problème de taille, la quantité de calculs nécéssaires rends la tâche tout simplement irréalisable.

Alors Hilbert, qui s'attaque à ce problème, décide de tenter une autre voie. Il démontre qu'il existe une famille génératrice de formes, qui existe pour n'importe quel nombre de dimensions, et tout ça sans aucun calcul !

Le problème des invariants est donc résolu puisque les propriétés invariantes sont les propriétés de la famille génératrice, si on a la famille génératrice, on a les propriétés invariantes. Mais c'est bien là qu'est le problème, Hilbert ne sait pas comment calculer cette fameuse famille génératrice de formes.

Il n'a, rapellons-le, utilisé aucun calcul pour parvenir à ce résultat. À la place, il a étudié, grâce à cet outil mathématique qu'es la méthode abstraite, il a étudié les relations des différents objets, des différentes formes entre-elles.

Et il va publier ses résultats en 1890 dans un article intitulé "De la théorie des formes algébriques", auquel Gordant répondra : "Ce n'est pas des mathématiques, c'est de la théologie".

Trois ans plus tard, Hilbert publie à nouveau, et cette fois, il fournit une méthode afin de calculer la famille génératrice de forme. Et Gordant sera obligé d'admettre : "La théologie à parfois ses mérites".

De son côté, Hilbert écrit à Minkowski, il dit : "Je quitte maintenant le domaine des invariants définitivement et je ne m'occuperais plus que de théorie des nombres". C'est aussi parceque l'association des mathématiciens Allemands vient de lui demander un rapport sur la théorie des nombres algébriques, puisque Kummer et Kronecker, qui sont les deux grandes figures du domaine, ont peu publiés. Le rapport, qui sera publié en 1897 deviendra plus tard un véritable ouvrage de référence, nottament pour les travaux d'Emmy Noether dans les années vingt.

C'est aussi à cette époque que Hilbert arrive à Göttingen. À l'invitation de Klein, il est nommé professeur ordinaire à l'université en 1895, puis à son tour, il fera nommer Minkowski en 1902. L'influence de Klein, de Hilbert et de Minkowski va faire de Göttingen un centre incontournable des mathématiques, on pourrait presque dire la capitale des mathématiques.

Ainsi, l'université attire de nombreux étudiants, l'un d'entre eux, Hermann Weyl, écrira en 1944 : "J'entends toujours la flûte douce de Hilbert nous séduisant pour nous conduire dans la rivière profonde des mathématiques [...] Les portes d'un monde nouveau s'ouvraient devant moi et je n'étais pas là depuis longtemps que déjà la résolution s'était formé dans mon jeune coeur de lire tout ce que cet homme avait écrit."

Alors il aura des choses à lire ce jeune homme, puisqu'aprés avoir publié son rapport sur la théorie des nombres, il change une fois encore de domaine et s'intéresse cette fois à la géométrie.

Je vous avais dit quand il s'occupait de théorie des invariants qu'il avait résolu le problème en appliquant une nouvelle méthode au problème, la méthode abstraite. Et c'est exactement ce qu'il va faire pour la géométrie, en allant encore un peu loin que la méthode abstraite, jusqu'à l'axiomatique.

C'est Euclide, qui à vécu en 300 avant notre ère, qui a, le premier, établi un ensemble de régles pour décrire ce qu'on peut faire en géométrie, et ce que nous ne pouvons pas faire. C'est la première axiomatisation.

C'est à dire : définir un ensemble de régles, qu'on appelle les axiomes, qui vont former la base de l'édifice mathématique. Toutes les propositions, tous les théorèmes seront déduis des axiomes.

Les axiomes sont donc les seules propositions mathématiques qu'il n'est pas nécéssaire de prouver. Mais cela rends la tâche d'autant plus complexe, puisqu'il faut alors réussir à trouver des axiomes qui soient suffisament simples et évident pourqu'il n'y ait pas besoin de prouver leur vérité.

Depuis Euclide, la méthode axiomatique s'est étendue à tous les domaines mathématiques, chaque branche des mathématiques poséde sa propre axiomatique, les régles qui définissent pour chaque domaine comment manipuler les différentes notions.

Mais l'axiomatisation de la géométrie, donc celle d'Euclide est critiquée, depuis longtemps d'ailleurs, puisque déjà à son époque, Archiméde avait ajouté un axiome qui lui semblait manquer.

Le défaut de l'axiomatisation d'Euclide, c'est qu'il n'y a pas suffisament d'axiomes pour répondre à certains problèmes de façon purement logique, et il est parfois nécéssaire de recourir au sens évident d'une chose au cours d'une démonstration afin de pallier au manque d'axiomes.

Il faut que je vous donne un exemple pour que vous compreniez bien, on peux commencer par déclarer un axiome dans une nouvelle branche des mathématiques :  "Socrates est un homme", c'est notre premier axiome. Et dans un article, dans une publication mathématique, on pourrait trés bien affirmer que, puisque socrates est un homme, alors Socrates est mortel.

Ça paraît évident, puisque tous les hommes sont mortels, c'est une vérité que l'on connait tous et qui est tiré de notre expérience vécue, mais c'est aussi une preuve mathématique très faible.

Les mathématiques sont un language formel, c'est à dire que tout doit y être définit sans ambiguité. Dans ce contexte, rien ne nous permet d'affirmer que tous les hommes sont mortels, sauf si cette proposition était un axiome.

La validité de la conclusion, que Socrates est mortel, dépends de l'existence en tant qu'axiome de la proposition "Tous les hommes sont mortels".

Dans notre exemple, je ne crois pas que la publication finale aurait fait débat, du fait  de l'évidence immédiate de notre axiome manquant, que tous les hommes soient mortels.

Mais on trouve en mathématiques des notions beaucoup plus floues et qui ne sont pas nécéssairement érigées en tant qu'axiomes, comme par exemple la notion de l'infini, qui fera, comme on le vera, l'objet de profonds désacords dans la communautée.

C'est ce problème, le manques d'axiomes en géométrie, que Hilbert veut résoudre en proposant une toute nouvelle axiomatisation. Et cette fois encore, il va différentier son point de vue par rapport au reste de ses pairs.

D'ordinaire, les axiomes servent à décrire directement les objets mathématiques. En géométrie on parle de points, de droites et de plans. Hilbert, lui, va se servir des axiomes pour décrire plutôt les interactions, les relations des différents objets entre eux, sans jamais les définirs directement.

La démarche est particulièrement bien illustrée par cette petite anecdote. Hilbert est à la terrasse d'un café avec ses étudiants et leur dit : "L'on devrait pouvoir parler en géométrie de tables, de chaises et de chopes de bière, au lieu de points, de droites et de plan".

Le cours de géométrie qu'il donne d'ailleurs ne mentionne que dans son introduction les notions de points, de  droites et de plans : "Nous pensons trois systèmes différents de choses. Nous nommons les choses du premier système des points [...]. Nous nommons droites les choses du deuxièmes système [...]. Nous appelons plans les choses du troisième système. [...]. Entre les points, les droites et les plans, nous imaginons certaines relations que nous exprimons par des expressions telles que "être sur", "entre", "congruent". La description exacte et appropriée au but des mathématiques de ces relations est donnée par les axiomes de la géométrie".

Alors pourquoi une telle démarche ? L'intérêt, dans l'idée de Hilbert, est de retirer totalement le sens usuel, les définitions courantes et le sens intuitif que l'on peut accorder à certains mots, certaines notions qui sont utilisées en mathématiques, et en géométrie plus particuliérement.

Pour reprendre notre exemple de tout à l'heure, au lieu de "Socrates est un homme" et "Tous les hommes sont mortels", on aurait "X est un A", "Tous les A sont des P", desquels on pourrait conclure que "X est un P".

Aprés avoir terminé son axiomatisation de la géométrie, Hilbert va s'attaquer entre 1901 et 1908 à l'axiomatisation de l'analyse, la branche des mathématiques qui sert à étudier la notion de "limite".

C'est à ce moment qu'il va développer ce qu'il appelle la "théorie spectrale", connue aujourd'hui comme la "théorie des espace de Hilbert".

Ces travaux, qui offrent de nouvelle méthodes pour résoudre des équations intégrales, vont vont êtres au centre des travaux de Weyl, Von Neumann, Schrödinger, de Bohr et d'Heisenberg. 

Heisenberg va dire : "Indirectement, Hibert exerça la plus grande influence sur le développement de la physique [...] Les méthodes mathématiques de la mécanique quantique sont une application directe de la théorie hilbertienne des équations intégrales".

Alors le travail d’axiomatisation, qui est finalement la constante dans le parcours mathématique d’Hilbert, n’est pas simplement d’établir une liste d’axiomes. Il faut également pouvoir montrer que ces axiomes sont cohérents, et qu’on ne peut pas construire à partir des axiomes de propositions contradictoires.

Pour cela, Hilbert, comme le reste des mathématiciens, procède par analogie. Si il peut exprimer les axiomes de la géométrie, ou de l’analyse, sous forme algébriques, alors ces axiomes sont considérés comme valides, ou consistants comme on le dit en mathématiques.

L’idée est que, la théorie des nombres algébriques est le domaine mathématique le plus sûr et le plus fiable que nous possédons. Si les axiomes de la géométrie par exemple étaient contradictoires, alors, cette contradiction s’étendrait à l’algèbre, une fois les axiomes « traduits ».

Puisque l’algèbre est sûre et peu contestable, une traduction des axiomes vers l’algèbre constitue un preuve de consistance suffisante pour la communauté mathématique.

Pourtant, la méthode commence à poser problème. Entre 1897 et 1905, trois paradoxes vont être révélés en théorie des ensembles, et ces paradoxes, qui révèlent des contradictions dans la théorie des ensembles, s’étendent alors à l’algèbre.

La théorie des nombres algébrique ne serait pas aussi sûre que ça. Il faudrait donc pouvoir prouver la consistance de l’algèbre elle-même, mais personne n’a de méthode pour ça. On ne peux pas comparer l’algèbre avec elle-même comme on le faisait pour les autres théories.

Alors c’est le début de la quête du fondement, la quête d’une preuve de consistance des axiomes de l’arithmétique. Mais avant de vraiment continuer, il faut que je vous explique quels sont les trois paradoxes qui ont provoque ce véritable tremblement de terre en mathématiques. 

La théorie des ensembles à été développée entre 1873 et 1897 par Georg Cantor, qui va , à l’aide de la théorie des ensembles, parvenir à des conclusions assez étranges, en tout cas complètement contre-intuitifs.

Alors cette théorie, du fait de ces résultats inattendus, provoquera un certain scepticisme chez certains mathématiciens, comme Kronecker ou Pointcaré. Hilbert d’un autre côté sera un vif supporter cette théorie.



——



La théorie des ensembles propose d'étudier des collections d'objets définis par une propriété commune. L'ensemble des nombres pairs, ou l'ensemble des nombres inférieurs à trois, l'ensemble des rectagles dont le périmétre est égal à 1, etc. Au sein de la théorie des ensembles, on trouve la notion de "cardinalité", ou de "taille" d'un ensemble, c'est une notion bien pratique lorsqu'on veut comparer la taille de deux ensembles, en particulier lorsqu'on a affaire à des ensembles contenants un nombre infinis d'éléments, comme l'ensemble des nombres pairs.

L'ensemble des nombres pairs est-il plus grand, ou plus petit, que l'ensemble des nombres entiers ? Si l'on considérait des ensembles finis, les nombres pairs entre 0 et 100, et les nombres entiers entre 0 et 100, la réponse serait évidente, mais comment comparer des ensembles infinis ?

C'est là où la notion de cardinalité est utile puisqu'il ne s'agit pas directement de compter le nombre d'éléments d'un ensemble, ce qui, pour des ensembles infinis serait impossible. En particulier, on peut considérer que deux ensembles possédent la même cardinalité, la même taille, si l'on peut réaliser une correspondance bi-univoque entre ux, c'est à dire, une association terme à terme pour chaque élément des deux ensembles.

Ainsi, je peux associer dans l'ensemble de tous les nombres entiers le nombre "1", au nombre "2" de l'ensemble des nombres pairs. Le nombre "2" des entiers au "4" des pairs, le "3" au "6" et ainsi de suite. D'une façon générale, un nombre x de l'ensemble des entiers est associé au nombre "x*2" des pairs. Ainsi, chaque éléments de l'ensemble des nombres entiers est associer à un et un seul élément de l'ensemble des nombres pairs. Et inversement. On peut dire que les deux ensembles ont la même "cardinalité", c'est à dire, la même taille. L'infini des entiers n'est pas plus grand que l'infini des nombres pairs.

C'est déjà surprenant, mais ce qui va être plus surprenant encore, c'est ce que Cantor va montrer ensuite. Certains infinis sont plus grands que d'autres. On trouve dans certains ensembles infinis nécéssairement plus d'éléments que dans d'autres ensembles infinis.

Ce que fait Cantor c'est qu'il choisit de prendre l'ensemble des nombres entiers, qu'il catégorise d'infini dénombrable, ou listable, et de le comparer à l'ensemble des nombres réels, les nombres à virgule. Pour commencer, Cantor présuppose que ces deux ensembles ont la même cardinalité, la même taille, donc, on il peut réaliser une sorte de liste où à côté de chaque nombre entier serait associé un nombre réel. Dans cette liste, il procéde à une "diagonalisation". Il prends le chiffre à la première position du prmier nombre, celui à la seconde position du second nombre, à la troisième position du troisième nombre, et ainsi de suite pour l'ensemble des nombres de la liste.

Avec cette suite de chiffres, il construit un nouveau nombre en appliquant une régle spéciale : si le chiffre est un "0", je le remplace par un "1", si c'est autre chose qu'un "0", alors je le remplace par un "0". De cette façon, le nombre nouvelle construit est nécéssairement différent de tous les nombres de la liste. Il est différent du premier nombre de la liste puisque le chiffre à la première position est différent, il est différent du second nombre puisque le chiffre à la seconde position est différent, etc.

Mais puisque Cantor à réussit à construire un nouveau nombre, qui est un nombre réel, et qui n'était pas déjà dans la liste, cela signifie qu'il est impossible de faire une correspondance bi-univoque entre ces deux ensembles, et que l'ensemble des nombres réels est "plus grand" que l'ensemble des nombres entiers. Tous les infinis ne se valent pas. D'un côté, les infinis dénombrables, comme les nombres entiers, d'un autre, les infinis continus, comme les nombres réels.

Une question qui va hanter ensuite Cantor est de savoir si il existe des infinis de taille intermédiaire, plus petits que le continu mais plus grand que le dénombrable. C'est ce qu'on appelle "l'hypothése du continu" de Cantor, et c'est pour répondre à cette question que Cantor va développer les nombres ordinaux, qui servent de support au premier paradoxe de la théorie des ensembles.

Les nombres ordinaux servent à décrire à la fois la quantité, et l'ordre des éléments d'un ensemble. À chaque suite d'éléments correspond un nombre ordinal, et à chaque nombre ordinal correspond une suite d'éléments. Le mathématicien Italien Burali-Forti va tenter de calculer le nombre ordinal associé à la suite de tous les nombres ordinaux.

Mais s'il calcule le nombre ordinal de la suite des ordinaux, il n'a pas vraiment calculé le nombre ordinal de la suite de tous les nombres ordinaux, mais seulement le nombre ordinal associé à la suite de tous les nombres ordinaux sauf lui-même. Et même s'il l'on calculait une nouvelle fois un nombre ordinal en incluant celui précédement calculé, on obtiendrait un nouvel nombre ordinal qui n'aurait pas été pris en compte dans la liste.

C'est le paradoxe : N'importe quelle suite devrait posséder un nombre ordinal, pourtant il y ne peut pas exister de nombre ordinal pour la suite des nombres ordinaux.

Le second paradoxe est mis à jour par Bertrand Russell en 1902. Il dit : l'ensemble des cuillères à thé n'est pas lui-même une cuillière à thé, il ne s'appartient pas à lui-même. Mais considérons ensemble l'ensemble de tous les ensembles qui ne s'appartiennent pas à eux-mêmes, est-ce que cet ensemble là s'appartient à lui-même ou pas ?

Si il s'appartenait à lui-même, il correspondrait à sa propre définition d'une ensemble qui ne s'appartient pas à lui-même, donc s'il s'appartenait à lui-même, il ne s'appartiendrait pas à lui-même. Mais s'il ne s'appartient pas à lui-même, alors il mérite de faire partie des ensembles qui ne s'appartiennent pas à eux-mêmes, et donc, il s'appartiendrait à lui-même.

Russell va aussi appliquer la même logique à l'ordre des concepts. "Être vert" est un concept, on peut dire qu'une pomme "est verte", mais "être vert" n'est pas vert lui-même, il ne s'applique pas à lui-même. Il y a un nom pour cela, c'est ce qu'on appelle l'hétérologie, un concept hétérologique est une concept qui ne s'applique pas à lui-même.

Maintenant, est-ce que l'hétérologie est hétérologique ? Si le concept était hétérologique, il s'appliquerait à lui-même, et donc, ne pourrait pas être hétérologique. Mais s'il n'est pas hétérologique, il ne s'applique pas à lui-même, alors il est hétérologique.

Hilbert n'est pas surpris par les réflexions de Russull, dans une lettre à Frege, il explique que Zermelo lui aussi est arrivé à la même conclusion que Russell, et que le paradoxe est connu à Göttingen depuis déjà trois ou quatre ans.

Puis, c'est en 1905 que le dernier paradoxe de la série va être mis à jour par Jules Antoine Richard, qui va au passage emprunter la méthode de "diagonalisation" de Cantor. Il commence par définir l'ensemble de tous les nombres définissables en moins de milles mots, puis, à l'aide de la diagonalisation, crée à partir de cette liste un nouveau nombre. Ce nouveau nombre à été définit en moins de milles mots, puisque la méthode de diagonalisation s'explique en moins de milles mots, donc il devrait être dans la liste, pourtant il ne peut pas être dans la liste, puisque c'est le principe même de la construction par diagonalisation, d'où le paradoxe.

Il faut bien comprendre que tous ces paradoxes, même s'ils ne concernent directement que la théorie des ensembles, se répercutent sur l'arithmétique, et donc sur l'ensemble des mathématiques. Il s'agit alors pour les mathématiciens de repenser l'axiomatique de l'arithmétique, afin de supprimer les paradoxes connus, et de se prévenir contre de futurs paradoxes, en garantissant la consistance, la non-contradiction, des axiomes de l'arthmétique. Le problème ? C'est que personne à ce moment là n'à la moindre de comment construire une preuve de consistance pour l'arithmétique.

Hilbert s'était déjà exprimé sur la nécéssité d'une preuve de consistance pour l'arithmétique. En 1900, au congrès internationnal des mathématiciens, le plus important rassemblement du monde mathématique qui se tient tous les quatres ans, et qui en 1900, se déroule à Paris, juste à côté de l'exposition internationale, Hilbert va donner une conférence. Il envisage d'abord de faire un exposé général sur les mathématiques, mais c'est Minkowski, son ami, qui va lui donner une autre idée. Il écrit à Hilbert en janvier 1900, le 5 janvier, et dit : "Il serait intéressant de regarder dans le futur et de faire une liste des problèmes sur lequels les mathématiciens travaillerons dans le siécle qui vient. Avec un tel sujet, on parlera encore de ton exposé dans plusieurs décénies".

En effet Minkowski ne s'est pas trompé et la liste des 23 problèmes de Hilbert au congrès de 1900 va occuper la quasi-totalité de la recherche mathématique du 20ème siècle, et encore aujourd'hui, certains problèmes ne sont toujours pas résolus.

Mais c'est, pour notre histoire, le second problème de cette liste qui va avoir une résonnance particulière : "Peut-on prouver la cohérence de l'arithmétique ? En d'autres termes, peut-on démontrer que les axiomes de l'arithmétique ne sont pas contradictoires ?".

Hilbert va tenter en 1904, dans le cadre d'une conférence intitulée "Sur les fondements de la logique et de l'arithmétique", une démonstrations de consistance pour un système minimaliste d'axiomes qui ne représentent que les nombres entiers, et la notion d'égalité entre ces nombres.

Cette démonstartion sera vivement critiqué par Henri Pointacré, trés influent dans le monde des mathématiques, et qui ne partage pas les idées d'Hilbert.

Hilbert estime que les objets mathématiques, comme les nombres, existent. Tous les nombres, même si personne ne les a jamais écrits, même si on ne sait pas les calculers, tous les nombres existent. Pour Pointcaré, c'est le contraire, les nombres n'existent pas, ils sont construits par la méthématicien.

Ça ne parait rien mais ça a de grande implication sur la façon de faire des mathématiques. Pour Pointacré, on ne peux pas parler d'infini, puisque les nombres n'existent pas, on ne saurait avoir une collection qui regroupe tous les nombres, ou d'ensemble de tous les ensemble, comme dans la paradoxe de Russell.

Pour le paradoxe de Richard, pas de Paradoxe ! On définit l'ensemble de tous les nombres définits en moins de milles mots, puis on définit un nouveau nombre, à partir de la l'ensemble, mais qui aurait dû appartenir à cet ensemble. Comment ? dit Pointcaré, comment ce nombre aurait-il pu appartenir à l'ensemble puisqu'au moment où on a crée l'ensemble, il n'existait pas ? Il n'y a pas de paradoxe pour Pointcaré, simplement une construction en deux étapes, d'abord on construit une liste, puis à partir de cette liste, on construit un nombre qui n'existait pas avant.

Pointcaré fait reposer les paradoxes sur un principe de cercle vicieux : des objets qui se références eux-mêmes dans leurs définition. Pour le paradoxe de Burali-Forti, on cherche le nombre ordinal de tous les nombres ordinaux. Le nombre ordinal que l'on cherche à besoin de lui-même pour se calculer, c'est le cercle vicieux, et c'est exactement ce que Pointcaré reproche à la démonstration de consistance de Hilbert en 1904.

Hilbert définit quelques axiomes pour représenter les nombres, puis il utilise des nombres pour prouver la consistance de ses axiomes, c'est le cercle vicieux. Il ne peux pas utiliser les nombres pour prouver les nombres.

Pointcaré va mourir en 1912, avant d'avoir pu proposer sa propre solution au problème de la consistance des axiomes de l'arithmétique, mais c'est depuis ses critiques sur le principe de cercle vicieux qu'il est apparu clairement qu'on devrait séparer deux choses : ce qu'on voulait prouver, et les notions qu'on allait utiliser pour le prouver.

Puisque c'est principalement la notion de l'infini qui fait débat, en particulier l'infini actuel, qui présuppose l'existance en soi des objets mathématiques, Hilbert va choisir de diviser l'arithmétique en deux domaines. D'un côté, la mathématique formelle, qui décrit l'ensembles des mathématiques, et que l'on veut prouver. Et d'un autre côté la mathématique contentuelle et finististe, c'est à dire l'arithmétique classique, privée de la notion d'infini.

Mais avant Hilbert, qui ne va s'impliquer qu'à partir de 1917-18 sur ce qu'on appelle le probléme de fondement, justifier les fondements des mathématiques, ce sont trois mathématiciens qui vont tenter de trouver une solution au problème de fondement, Russel et Whitehead d'un Côté, et Brouwer de l'autre.

Parlons d'abord de Russell, de Whitehead et des "Principia Mathematica", une tentative d'axiomatisation globale de toutes les branches des mathématiques. Les "Principias" sont largement inspirées d'un précédent article de Russell de 1908 : "La logique mathématique fondée sur la théorie des types", dans lequel il tente de hiérarchiser les différentes notions mathématiques. Les notions du rang 1 s'appliquent au rang 2, celles du rang 2 au rang 3 et ainsi de suite.

Cette hiérarchie permet d'éviter qu'une notion ne s'applique à elle-même, et évite donc le cercle vicieux décrit par Pointcaré, mais les "Principias" peinent à convaincres. Un défaut particulier, Russell et Whitehead ne présentent pas de preuve de consistance de leurs axiomes. Pour Russell, ces axiomes sont des notions intuitives, et donc, nécéssairement vraies, la démonstration de consistance ne serait qu'une confirmation de leur vérité. En 1927, après être revenu aux probléme du fondement, Hilbert a contester l'évidence de certains axiomes : "La théorie des fondements de Russell et Whitehead [...] fait reposer les mathématiques sur l'axiome de l'infini et sur un axiome dit de réductibilité. Or ces deux axiomes sont d'authentiques hypothèses qui ne peuvent s'appuyer [...] sur une preuve de consistance [... et] dont la validité universelle reste même ouverte au doute".

Un autre qui ira plus loin encore pour placer l'évidence de l'intuition au centre des mathématiques, c'est Brouwer. Pour lui, les paradoxes révélent un usage abusif des règles de la logique, qui font abstraction du sens du contenu, et créent ainsi des énoncés vides de sens, puis finalement, des paradoxes. Comme Pointcaré, il adopte une vision constructiviste des mathématiques, même si cela le force à abandonner certains principes fondamentaux des mathématiques contemporaines, en particulier le "tiers exclu".

Le principe du tiers exclu, qui d'ailleurs repose sur les notions d'infini actuel et d'existence en soi des objets mathématiques, deux notions que défend Hilbert mais que Brouwer comme Pointcaré rejettent. Le principe du tiers exclu donc, permet de dire d'une propriété qui s'applique à un ensemble d'éléments, que soit tous les éléments de l'ensemble vérifient cette propriété, soit il existe au moins un élément qui ne posséde pas cette propriété. En clair, une propriété est soit vraie, soit fausse, et il n'y a pas de troisième option. C'est ce qui fera dire à Brouwer que : "La question de la validité du tiers exclu équivaut à celle de la possibilité de problémes mathématiques non résolubles".

On ne peut pas être plus à l'opposé des idées de Hilbert, qui annonçait haut et fort au congrés international de 1900, Jamais le mathématicien ne sera réduit à dire Ignorabimus !". Ignorabimus : on ne sait pas, et on ne saura pas.

Et pourtant, l'intuitionisme de Brouwer ira jusqu'à convaincre Herman Weyl, l'ancien étudiant de Hilbert qui s'oppose à son ancien professeur : "Si les mathématiques doivent rester une préoccupation culturelle sérieuse, alors un certain sens doit être attaché au jeu de formules de Hilbert, et je ne vois qu'une seule possibilité de lui attribuer un sens intellectuel indépendant. En physique théorique, nous avons devant nous le grand exemple d'une connaissance d'un caractère tout à fait différent de la connaissance commune qui exprime purement ce qui est donné dans l'intuition".

Hilbert répondra, toujours en 1927, aux intuitionistes : "Oter le [tiers exclu] au mathématicien serait comme si on voulait enlever à l'astronome son télescope, au boxeur le droit de se servir de son poing. [... C'est] quasiment à renoncer à la science mathématique. Car que sont les misérables restes, qu'est-ce que la poignée de résultats incomplets et disparates que les intuitionistes ont pu élaborer [...] à l'égard de l'étendue formidable de la mathématique contemporaine ?".

Alors on a vu Brouwer avec l'intuitionisme et la méthode constructiviste, Russell et Whitehead avec les Principas Mathematica et la théorie des types, regardons maintenant comment Hilbert va répondre au problème de fondement.

Hilbert retourne au problème du fondement en 1917, avec une conférence "La Pensée Axiomatique", mais c'est véritablement à partir de 1922, et jusqu'en 1930, qu'Hilbert va tâcler le problème dans une série d'article qui introduit le programme formaliste.

L'objectif du programme formaliste, programme de fondement ou programme d'Hilbert, est d'établir une mathématique formelle, pure de forme et vide de sens. C'est la méthode axiomatique poussée à son paroxysme, une mathématique faite uniquement d'axiomes et de règles logiques, où l'intuition et l'évidence immédiate n'ont pas leur place.

D'un autre côté, Hilbert définit la mathématique finitiste, une arithmétique privée de la notion d'infini, et de tout ce qui fait débat parmis les mathématiciens, le tiers exclu, le principe d'induction complète, etc. Puisque la mathématique finitiste ne contient que des notions immédiatement évidentes, son rôle sera de fournir un preuve de consistance pour la mathématique formelle. Pour Hilbert : il s'agit de "s'assurer par le fini le droit d'opérer sur l'infini".

La force du programme formaliste, c'est qu'il utilise les mathématiques pour justifier les mathématiques, ainsi, Hilbert n'a "besoin ni du Bon Dieu, comme Kronecker, ni de l'hypothèse d'une faculté de conscience accordée au principe d'induction complète, comme Pointcarré, ni de l'intuition originelle de Brouwer, ni non plus des axiomes de l'infini [comme Russell et Whitehead]". Il ira même plus loin : formaliser "c'est dépeindre l'activité de notre intellignece", c'est "dresser un inventaire des règles d'après lesquelles fonctionne réellement notre pensée".

Mais malgrès la force de leurs arguments épistémologique, les mathématiciens engagés dans le programme, Hilbert, Bernays, Von Neumann ou Ackermann, pour n'en citer que quelques-uns, n'ont toujours pas de résultats. Toutes les différentes tentatives d'axiomatisation et de preuve de consistence ont échoués.

C'est alors que Hilbert prendra la parole, au congrès internationnal de Bologne, en 1928. Là, il lance à ses pairs trois problèmes ouverts : L'axiomatique formelle est-elle compléte ? consistante ? et décidable ?

L'axiomatique formelle est-elle complète ? C'est à dire que n'importe quelle proposition ou formule crée à partir des axiomes est nécéssairement soit démontrable, soit réfutable. Ça serait la validation du principe du tiers exclu et de l'idée de la résolubilité de tout problème mathématique. "Jamais le mathématicien ne sera réduit à dire Ignorabimus" !

L'axiomatique formelle est-elle consistante ? C'est la preuve de non-contradiction que cherchent les mathématiciens depuis l'apparition des paradoxes en théorie des ensembles. Qui permettrait de justifier la totalité de l'édifice mathématique et de donner à la science des fondations solides, irréfutables.

L'axiomatique formelle est-elle décidable ? Est-ce qu'il existe une méthode effective, qui permette de décider si une formule donnée est démontrable ou réfutable ? Si elle est vraie ou fausse ?

Bien entendu, Hilbert espére que les trois réponses à ces trois problèmes seront positives. C'est même à cette condition seulement que pourrait se poursuivre le programme formaliste. D'ailleurs, tout semble bien parti, toujours au cours de la conférence, Hilbert annonce qu'Ackermann et Von Neumann sont parvenus à prouver la consistance de l'axiomatique formelle.

Il annonce aussi que lui-même et Ackermann pensent pouvoir bientôt amener la preuve de la complétude des "prédicats du premier ordre". Certes, le calcul des prédicats ne représentent pas toute l'arithmétique, mais c'est la partie la plus importante : ils décrivent les règles de la logique. Sans calcul des prédicats, impossible de construire une démonstration ou un théorème en mathématique.

Mais si tout s'annonce bien, c'était sans compter sur la présence au congrés de Bologne d'un mathématicien d'origine Autrichienne : Kurt Gödel.

La nationalité de Gödel fait débat : il est né à Brno, en Autriche-Hongrie, mais sera naturalisé Tchécoslovaque en 1918, à la dissolution de l'Autriche-Hongrie. Attaché à ses racines, il retrouvera la nationnalité Autrichienne en 1929, seulement pour devenir Allemand aprés l'annexion de son pays en 1938. Il finirat par s'exiler aux États-Unis, où il n'obtient la nationnalité que grâce au support de son ami, Albert Einstein.

Mais laiisons là cette histoire et retournons aux fondements. Je vous avais dit qu'en 1928 congrés de Bologne, Hilbert avait annoncé pouvoir apporter la preuve de la complétude des prédicats du premier ordre avec Ackermann. C'est en fait Gödel qui arrivera le premier à démontrer la complétude de cette partie de l'arithmétique, en 1929.

Mais c'est ensuite, en 1931, que Gödel va marquer l'histoire de la recherche des fondements en mathématiques. Le 26 Août 1930, Gödel assiste à une conférence à Köningsberg, Heyting y parle de l'intuitionnisme, Von Neumann parle du formalisme, et Hilbert annonce sa retraite dans un discourt : "Contrairement à l'Ignorabimus stupide, notre credo est: Nous devons savoir. Nous le saurons!", "Wir müssen wissen. Wir werden wissen!", des mots qui seront inscrits sur son épitaphe.

Au cours d'une discussion fortuite, Gödel va présenter à quelques-une de ses pairs le premier théorème d'incomplétude : "Si l'arithmétique élémantaire est ω-consistante, elle comporte des formules fermées qui ne sont ni démontrables, ni réfutables à partir des axiomes". Von Neumann commentera instantanément : "Tout est fini" !

Et il a raison, puisque le théoréme d'incomplétude signe la fin du programme formaliste dans sa forme actuelle. En clair, le théorème dit que n'importe quelle axiomatique, à partir du moment où elle suffisament expressive pour représenter les nombres entiers et les opérations d'addition et de multiplication, est nécéssairement soit inconsistante, soit incompléte. Pour Hilbert qui voulait contruire une axiomatique, qui soit à la fois consistante, compléte et décidable, c'est la catastrophe.

Gödel parvient à ce résultat en montrant que pour n'importe quelle axiomatique, dans laquelle on puisse représenter l'arithématique élémentaire, il peut construire une proposition qui dit "Je ne suis pas démontrable".

De là, deux possibilités, soit la formuler est démontrable, et c'est terrible puisqu'on vient de démontrer quelquechose d'évidement faux, donc le système est inconsistant. Soit, la formule n'est pas démontrable, auquel cas, elle dit vrai. On se retrouve alors avec une formule vraie, mais qui n'est pas démontrable, donc le système est incomplet (dans un système complet, toute les formules vraies sont démontrables).

Von Neumann écrira à Gödel le 20 Novembre 1930 pour lui dire qu'il à trouvé un second théorème à partir du premier : "la consistance d'un systéme ne peut pas être établie au moyen de raisonnements qui se laisseraient formaliser dans le systéme".

Gödel est en fait déjà arrivé à la même conclusion quelques jours plus tôt. Pour le programme formaliste, c'est un nouveau coup dur, Hilbert voulait démontrer l'axiomatique formelle à l'aide de la mathématique finitiste, ce que le second théorème d'incomplétude interdit.

Les deux thèorèmes seront publiés en Janvier 1931 dans une revue mathématique Viennoise. En apprenant les théorèmes de Gödel, Hilbert rentra dans une colère noire. Peut-être parcequ'il n'a pas trouvé lui même ce que Gödel considére comme une "conséquence presque triviale" des travaux de Skolem, mais qu'il n'avait pas remarqué de faute de n'avoir pas quité un point de vue strictement finitiste. Ou alors, plus simplement, parceque ces deux théorèmes d'incomplétude semblent signer la fin du programme formaliste et de la recherche du fondement.

Ce n'est pourtant pas le cas, Gödel commentera d'ailleurs : "il reste un espoir pour que dans le futur on puisse trouver des méthodes satisfaisantes [...] dépassant les limites du système [finitiste de Hilbert] et permettant de fonder l'arithmétique classique et l'analyse. Cette question ouvre un champ de recherches fécond". Et ajoute dans un second commentaire : "la conviction dans la décidabilité de tout problème mathématique n'est pas ébranlée par ce résultat".

Je crois que Gödel est au moins aussi triste que Hilbert d'avoir trouvé les théorèmes d'incomplétudes. Il partage plusieurs croyances sur le monde mathématique avec Hilbert, il dit : "les mathématiques décrivent une réalité non sensible, qui existe indépendament des actes et des facultés de l'esprit humain et n'est que perçue, et probablement perçue de façon très incomplète". C'est l'expression de l'existance en soi des objets mathématiques.

Gôdel reviendra d'ailleurs sur la quête des fondements en 1947, et il explique maintenant l'indécidabilité de certains problèmes, cette indécidabilité qu'il a mise à jour, par le manque d'axiomes, ou l'imprécision de ceux-ci : "les concepts et les théorémes de la théorie des ensembles décrivent une réalité bien déterminée, dans laquelle la conjecture de Cantor est vraie ou fausse. Ainsi son indécidabilité à partir des axiomes acceptés aujourd'hui peut seulement signifier que ces axiomes ne contiennent pas une description complète de cette réalité".

Mais Gôdel ne sera pas le seul à commenter sur ses théorèmes, c'est Von Neumann cette fois qu'on écoute : "Ce résultat imposant de l'analyse de Gödel ne doit pas être mal compris: il n'exclut pas une preuve  méta-mathématique de la consistance de l'arithmétique. [...] Gödel a montré qu'aucune preuve n'est possible qui peut être représentée au sein de l'arithmétique. Son argument ne supprime pas la possibilité de preuves strictement finitiste qui ne sont pas représentés au sein de l'arithmétique. Mais personne aujourd'hui ne semble avoir une idée claire de ce qu'une preuve finitiste serait qui ne serait pas formulable dans l'arithmétique".

Mais de toute les manières, même si on voulait abandonner le programme formaliste, il reste une question à résoudre, la décidabilité. L'axiomatique formelle est-elle décidable ? Bon, depuis les résultats de Gödel, on se doute que la réponse sera négative : il n'existe pas de procédure effective qui puisse décider si une formule donnée est démontrable ou non. Encore faudra t-il le prouver.

Et ça va devenir d'autant plus important qu'au sein de la question de la décidabilité se trouve la notion de procédure effective, mais, le terme qu'utilise Hilbert de "procédure effective" ne dispose pas de définition formelle. En fait, la notion de "procédure effective" renvoie à la notion de "calculabilité".

Depuis le 18éme siècle, les mathématiciens ont associé l'idée de calcul avec l'idée de fonction. Mais les fonctions évoluent au 19ème siécle pour ne plus décrire qu'une correspondance entre un point de départ et un point d'arrivé, sans qu'un calcul effectif n'ait besoin d'être réalisée. On commence alors à dissocier les fonctions en deux groupes, celles qui possédent une procédure de calcul effective, les fonction calculables, et les autres, les non-calculables.

Il s'agit alors de trouver une définition au terme de "procédure effective", de "calculabilité", qui engloble toute les fonctions calculables, et mette les autres de côté.

Si je vous ai dit que la question de la décidabilité était devenue d'autant plus importante après les théorèmes d'incomplétude de Gödel, c'est que les théorèmes sont généralisables, mais cette généralisation ne peut se faire qu'une fois qu'on aura une définition satisfaisante de la calculabilité.

Alors ce sont trois mathématiciens qui vont tenter de résoudre ce problème. Gödel d'abord, mais on ne parlera pas de ses recherches, elles sont compliquées et n'aboutissent pas. En revanche, on va parler un peu des travaux d'Alonzo Chruch, et surtout, on verra en détail l'article fondateur d'un jeune mathématicien anglais : Alan Turing.

Church d'abord, établit à Princeton aux États-Unis, il publie en 1936 une preuve de l'indécidabilité de l'arithématique, à l'aide d'un système de calcul qu'il développe en 1932 et 1933, le λ-calcul.

Le λ-calcul est un système formel qui permet de décrire l'ensemble des fonctions calculables. Une fonction est décrire par une expression, qui peut elle-même contenir d'autres fonctions. Afin de créer des fonctions de plus en plus complexes, on peut "appliquer" une fonction à une autre, en clair, on doit d'abord calculer le résultat d'une première fonction, pour ensuite réutiliser ce résultat lors du calcul de la second fonction.

C'est à partir de cette base seulement que l'on peut construire n'importe quelle fonction calculable. Pour vous donner quelques exemples simples, on peut construire la fonction d'identité, qui ne modifie pas la valeur qu'on lui donne : λx.x. On peut aussi construire une fonction constante qui à n'importe quelle valeur fait correspondre la valeur 2 : λx.2.

À partir de ces deux fonctions, on peut les assembler pour créer une fonction qui fabrique des fonctions constantes : λx(λy.x). SI j'envoie la valeur 2, je récupére la fonction constante à 2 : λy.2.

Le λ-calcul permet à Church d'identifier la limite des fonctions calculables, et va lui servir de base pour fournir la démonstration que l'arithmétique n'est pas décidable. Mais si le principe est simple, le λ-calcul est difficile à lire et à relire, et la vérification des résultats de Church est un vrai casse-tête pour le reste des mathématiciens. Tous ne sont pas convaincu.

Stephen Kleene par exemple, un étudiant d'Hilbert qui se souvient de la méthode de diagonalisation de Cantor. Kleene pense que la diagonalisation empêche toute définition formelle de la calculabilité. L'idée est simple : si on a une définition, on peut alors faire une liste de toutes les fonctions calculables, puis, par diagonalisation, on va créer une nouvelle fonction calculable qui n'était pas dans la liste, donc qui n'était pas incluse par la définition de calculabilité, donc la définition est mauvaise.

C'est ce qu'il va immédiatement tenter de faire : "Lorsque Church me proposa sa thèse [pour une définition de la calculabilité], je me mis aussitôt à la tâche de la réfuter par une diagonalisation de la classe des fonctions [calculables]. Mais, réalisant vite que la diagonalisation ne pouvait être faite de façon effective, je devins du jour au lendemain partisan de la thèse de Church".

La définition de Church, de la calculabilité, est bonne, mais quelques mois plus tard, et sans connaitre les travaux de Church, Alan Turing propose une autre définition, identique du point de vue mathématique, mais bien plus simple à comprendre et à réaliser, c'est cette définition qui restera dans l'histoire, c'est la machine de Turing.

En 1935, Turing, qui est encore étudiant au King's College à Cambridge, en Angleterre, assiste au cours de son professeur Max Newman : "Fondement des mathématiques". Newman enseigne les théories de Hilbert, les théorèmes d'incomplétudes de Gödel et commente sur le problème de la décision : "Supposons, par exemple, que nous puission trouver un système fini de règles qui nous permettrait de dire si une formule quelconque est ou non démontrable. Ce système contiendrait un théorème de métamathématique. Évidemment, ce théorème n'existe pas et c'est heureux, parceque s'il existait, nous aurions un ensemble mécanique de règles nous permettant de trouver la solution de tous les problèmes mathématiques et notre activité en tant que mathématiciens cesserait d'exister".

C'est cette vision mécaniste du calcul, qui vient d'abord de Von Neumann, "il y aurait une instruction absolument mécanique à l'aide de laquelle quiconque pourrait décider, à partir de n'importe quelle formule donnée, si elle est ou non démontrable", qui va pousser Turing à essayer de trouver une machine pour définir la calculabilité.

Alors j'ai deux citations là dessus, une de Max Newman : "et cela bien sûr conduit [Turing] au prochain défi, quel type de machine ? Et cela l'a inspiré pour essayer de définir ce que l'on voudrait dire par une machine à calculer parfaitement générale".

L'autre citation vient de William Newman, qui est le fils de Max Newman, et qui à connu Alan Turing : "À un moment, il a posé sa classe une question: la prouvabilité des énoncés mathématiques pourrait-elle être découvert par un procédé mécanique ? Cette question est restée dans l'esprit d'Alan, et peu à peu, il a développé le papier qui allait faire sa réputation dans le monde mathématique"

Turing termine à la fin de l'été 1936, deux mois seulement après la publication de Church, un article "On Computable Numbers, with an Application to the Entscheidungsproblem", "Sur les nombres calculables, avec une application au problème de la décision".

Alors, rappelons-le c'est important, Turing, quand il termine son article et qu'il le montre en première lecture à Newman, son professeur, il ne connait pas encore les travaux de Church. Par contre, il les connait en janvier 1937, date où l'article de Turing est publié pour la première fois.

On le sait pour deux raisons, d'abord, parceque Turing mentionne les travaux de Church en introduction de l'article : "Selon ma définition, un nombre est calculable si [il] peut être écrit par une machine. [...] Dans un article récent Alonzo Church a introduit l'idée de "calculabilité effective", ce qui équivaut à ma "calculabilité", mais est définie de manière très différente. Church atteint également des conclusions similaires au sujet du problème de la décision. La preuve de l'équivalence entre "calculabilité" et "calculabilité effective" est décrite dans une annexe au présent document".

Et aussi, parceque Turing va s'installer pendant deux ans à l'université de Princeton, travailler sur des problèmes de logiques sous la direction de Church. C'est son professeur de Cambridge, Max Newman, qui à arrangé cette collaboration, il écrit dans une lettre à Church : "Je dois mentionner que le travail de Turing est entièrement indépendant: il a travaillé sans supervision ou critique de quiconque. Cela rend d'autant plus important qu'il devrait entrer en contact le plus tôt possible avec les principaux travailleurs de ce domaine, de sorte qu'il ne devrait pas se transformer en un solitaire confirmé."

Alors maintenant que nous avons décrit le contexte d'écriture de cet article fondateur de Turing, fondateur à plusieurs niveau on en parlera ensuite, on peut regarder et lire la définition dans le premier chapitre de l'article de cette fameuse machine de Turing.

"On peut comparer un homme en train de calculer un nombre à une machine qui est seulement capable d'un nombre fini de conditions, qui seront appelés "m-configurations". La machine est livrée avec une "bande" (l'analogue du papier) qui la traverse, et est divisée en sections (appelé "carrés") capables chacun de porter un "symbole". A tout moment, il y a juste un carré [...] qui est "dans la machine". Nous pouvons appeler cette place le "carré lu". Le symbole sur la carré lu peut être appelé le "symbole lu". Le "symbole lu" est le seul dont la machine est, pour ainsi dire, "directement au courant". Cependant, en modifiant sa m-configuration la machine peut se rappeler efficacement certains des symboles qu'elle a "vu" précédemment. Le comportement de la machine possible à tout moment est déterminé par la m-configuration [...] et [...] le symbole lu. Cette paire [...] sera appelé "configuration" : ainsi la configuration détermine le comportement possible de la machine. Dans certaines configurations dans lesquelles le carré lu est vierge (i.e. il ne porte pas de symbole), la machine écrit un nouveau symbole sur la place balayée: dans d'autres configurations, il efface le symbole lu. La machine peut également changer le carré en cours de lecture, mais seulement en le déplaçant d'une case à droite ou à gauche. En plus de l'une de ces opérations, la m-configuration peut être modifiée. Certains des symboles écrits formeront la séquence de chiffres [...] du nombre [...] qui est calculé. Les autres ne sont que des brouillons pour "aider la mémoire". [...] Je soutiens que ces opérations comprennent toutes celles qui sont utilisés dans le calcul d'un nombre."

Alors on a une description qui est très courte, et minimaliste, mais c'est tout à fait vonlontaire de la part de Turing puisqu'il veut forcer le lecteur qui veut comprendre à s'identifier à la manichine en train de réaliser un calcul. Et cette identification va renforcer les arguments épistémologiques, philosophiques de Turing par rapport à la justesse de sa machine.

On va passer sur quelques exemples donc, et on va d'ailleurs réutiliser les mêmes exemples que Alan Turing donne dans son article : "Une machine peut être construite pour calculer la séquence 0101001 ... [...] La machine posséde quatre m-configurations "b", "c", "f", "e" et est capable d'écrire "0" et "1". Le comportement de la machine est décrite dans le tableau suivant dans lequel "R" [ndl: Right en anglais, Droite] signifie "la machine se déplace de sorte à lire le carré immédiatement à la droite de celui qui était auparavant lu". De même, pour "L" [ndl: Left, Gauche]. "E" [ndl: Erase] signifie "le symbole lu est effacé" et "P" [ndl: Print] signifie "écrire". La machine démarre dans la m-configuration "b" et une bande vide. [b None P0, R c; c None R e; e None P1, R f; f None R b]"

Il faut que j'insiste sur un point avant de continuer. La table d'instruction qui décrit le comportement de la machine est unique pour chaque machine. La machine que nous venons de décrire n'est capable que de produire la suite 010101 ... De la même manière, il existe une machine capable de faire une soustraction, une pour la multiplication et une autre qui calcule π. Pour chaque calcul, chaque séquence calculable, il existe une machine de Turing.

On peut du coup considérer qu'un calcul en particulier est définissable par rapport à la machine de Turing qui effectue ce calcul. La séquence 010101 ... peut donc être définie par rapport à la machine qu'on a utilisé tout à l'heure. Et cette machine est caractérisé par rapport à sa table d'instruction.

Et si on code chaque ligne de la table d'instruction, on peut obtenir un nombre, que Turing apelle le "nombre standard", qui nous permet de représenter une machine de Turing, et donc, un calcul, sous forme numérique.

Pour faire ça, Turing propose une méthode : On commence la lister les m-configurations de la machines, de façon à pouvoir les identifier comme la "première" m-configuration, ou la "cinquième" m-configuration. On peut alors coder une m-configuration spécifique en utilisant la lettre "D", suivie par la lettre "A" autant de fois que nécéssaire pour décrire sa position dans la liste. Ainsi, la première m-configuration sera codée par "DA", la seconde par "DAA", la cinquième par "DAAAAA".

Et on peut procéder de la même manière pour les symboles qu'écrit la machine. On fait une liste de tout les symboles et on les code avec la lettre "D" suivi de la lettre "C". Le premier symbole sera "DC" et le troisième sera "DCCC".

En plus des m-configurations et des symboles, on va associer une lettre spécifique pour chaque opération de la machine, ainsi, on peut représenter la table d'instriction d'une machine par un code uniquement composé des caractères "A", "C", "D", "L", "R", "N" et ";". Le ";" est utilisé comme séparateur, pour différentier une ligne de l'autre.

La dernière étape est d'associer à chaque caractère un chiffre. Le "A" est remplacé par un "1", le "C" par "2", "D" par "3", "L" par "4", "R" par "5", "N" par "6" et finalement, ";" par "7".

Si je reprends la table d'instruction de notre machine d'exemple, on commence par renommer les m-configurations et les symboles : [table, q est m-configuration, S est symbole] [q1 S0 PS1,R q2; q2 S0 PS0,R q3; q3 S0 PS2,R q4; q4 S0 PS0,R q1]

Puis, on code chaque ligne de la table pour déterminier la "définition standard" : "DADDCRDAA;DAADDRDAAA;DAAADDCCRDAAAA;DAAAADDRDA". Et à partir de là, le nombre de la définition : 31332531173113353111731113322531111731111335317.

L'interêt de cette notation de Turing, c'est qu'on dispose maintenant d'un nombre qui décrit une machine de Turing. Et qu'on va pouvoir se servir de ce nombre pour étudier les propriètés de la machine qu'il décrit. Et en particulier, Turing cherche à savoir si il est possible de prédire, à partir du nombre standard d'une machine de Turing prise au hasard, si cette machine va aboutir à un résultat ou non.

On l'a déjà dit, Turing utilise ses machines pour définir la calculabilité, donc l'ensemble des machines de Turing représentent l'ensemble de tout ce qui est calculable. Mais il faut bien remarquer que les calculs n'aboutissent pas tous à un résultat. On peut très bien imaginer une machine de Turing qui inscrirait successivement, sur le même carrée de la bande, le symbole "0", puis "1", puis "2", puis "0", puis "1", puis "2", puis "0", et ainsi de suite, pour toujours. C'est ce que Turing appelle les machines "circulaires", elles tournent en boucle et n'arrivent jamais nulle part.

Alors c'est ça que Turing veut parvenir à deviner, décider à l'avance si une machine s'arrêtera ou non. C'est le problème de l'arrêt, et l'interêt de ce problème, c'est qu'il est presque identique au problème de la décision. Si on résouds le problème de l'arrêt, on aura également résolu le problème de la décision d'Hilbert.

Alors comme pour le problème de la décision, on peut supposer que c'est impossible de décider à l'avance si une machine de Turing que l'on choisit aléatoirement, appelons-la la machine M, si cette machine M est circulaire, donc qu'elle ne s'arrête jamais, ou bien si elle est sans cercle, c'est à dire qu'elle s'arrête.

Mais imaginons pour une seconde qu'il existe une procédure effective, donc une machine de Turing qui puisse décider à l'avance si la machine M est circulaire ou non. On appelera cette machine la machine D.

Comment fonctionne cette machine D ? On commence par lui donner, sur le ruban, le nombre de la description standard de la machine M, si la machine M s'arrête, la machine D va inscrire sur le ruban le symbole "s". En revanche, si la machine M est circulaire, si elle ne s'arrête jamais, la machine D va inscrire sur son ruban le symbole "u".

Maintenant, Turing nous propose de construire une autre machine, la machine U. Son fonctionnement est simple, si elle lit sur le ruban le symbole "u", la machine s'arrête immédiatement. Par contre, si elle lit le symbole "s", la machine U rentre dans une configuration où elle ne s'arrêtera pas.

On sait que cette machine U existe puisqu'il est finalement assez simple de trouver sa table d'instruction.

À partir des machines D et U, en les associants, on va créer la machine H. Donc la machine H, on lui fournit d'abord la description standard d'une machine de Turing, n'importe laquelle, la machine M.

La machine H calcule d'abord un résultat intermédiaire, soit le symbole "u", soit le symbole "s", en fonction si la machine M est circulaire ou non. Et puis, la machine H va soit s'arrêter immédiatement, soit ne jamais s'arrêter, en fonction de ce résultat intermédiaire.

Alors, que se passe t'il si on donne à la machine H sa propre définition stadard ? D'abord, elle doit calculer le résultat intermédiaire, deux solutions, soit la machine D prédit que la machine H s'arrête, soit que la machine H ne s'arrête pas, qu'elle est circulaire.

Si la machine H s'arrete, alors elle inscrit le symbole "s" sur la bande, et rentre dans une configuration où elle ne s'arrête pas. En court, si elle s'arrête, elle ne s'arrête pas. Et si elle ne s'arrête pas ? Dans ce cas, le résultat intermédiaire est un "u", donc la machine H s'arrête.

On a là une double contradiction, une situation impossible, ce qui signifie que les suppositions que l'on avait faites au départ, nos hypothéses, sont fausses. Et la seule hypothése que l'on avait faite, c'était qu'il existe une machine D qui puisse prédire si une autre machine de Turing est circulaire ou non. Cette machine D ne peut donc pas exister. On ne peux pas prédire à l'avance si une machine de Turing s'arrêtera.

Et exactement avec la même démonstration, on peut prouver qu'il n'existe pas de machine de Turing, de procédure effective, qui puisse déterminer si une autre machine inscrira le symbole "0" à un moment donnée dans son exécution.

C'est important pour le problème de la décision, puisque Turing va prouver, dans un language mathématique avancé que je ne développerais pas ici, que si il existe une méthode générale capable de décider si une formule est prouvable, alors, il existe une méthode générale pour déterminer si la machine de Turing correspondante à cette formule écrit "0".

Et comme on a déjà montré qu'une telle machine ne peux pas exister, alors, il n'y a également pas de processus pour déterminer si une formule est prouvable. D'où le problème de la décision ne peut pas être résolu.

Dans la suite de l'article, Turing va exposer plusieurs argument épistémologiques, philosophiques afin de justifier la validité de sa définition, des machines de Turing. Il va les comparer au cahier d'algébre, quadrillé, qu'utilisent les écoliers lorsqu'ils apprenant à calculer. Pour lui, le fonctionnement de ses machines est une bonne description de la façon que nous avons nous, humains, de penser.

C'est d'ailleurs cette validation philosophique qui fera la force de la définition de Turing, du modéle des machines de Turing pour décrire la calculabilité. C'est ce qui manquait au λ-calcul de Church.

Mais je vous avait dit que l'article de Turing était fondateur, alors il n'est pas fondateur pour les mathématiques. Il n'y a finalement aucun résultat nouveau dans ce que présente Turing.

Il propose une définition correcte de la calculabilité, mais on en avait déjà une avec celle de Church. Et d'ailleurs, au moment où l'article est publié, en janvier 1937, Turing à rajouté un appendice dans lequel il prouve que tout ce qu'on peut faire avec les machines de Turing, on peut le faire avec le λ-calcul. Et tout ce qu'on peut faire avec le λcalcul, on peut le faire avec les machines de Turing.

Alors les deux définitions sont bien équivalentes. Même si celle de Turing, qui est largement plus simple, fera l'objet d'une plus largeme approbation, et de l'avis de Church en premier lieu : l'identification avec l'effectivité dans l'ordinaire [...] semble immédiatement évident", ce sont le mots de Church.

On a aussi Gödel qui ajoutera en note à ses théorèmes d'incomplétudes : Grâce à certains travaux qui ont suivi cet article, en particulier ceux de A. M. Turing, nous disposons désormais d'une définition sûre, précise et adéquate du concept de système formel [...] dont la proprièté est qu'en son sein, et en principe, le raisonnement peut être entièrement remplacé par des règles mécaniques".

On a aussi dans l'article la solution, négative, au problème de la décision d'Hilbert. Mais là aussi, Church avait devancé Turing.

Alors si cet article est devenu tellement important par la suite, c'est à cause d'un chapitre dont je ne vous ai pas encore parlé, et qui décrit ce que Turing apelle la machine universelle.

C'est donc la première phrase du sixième chapitre de l'article, intitulé "La machine à calculer universelle" que je vous lis : "Il est possible d'inventer une machine unique qui peut être utilisée pour calculer toute séquence calculable. [...] Si cette machine U est fournie avec une bande sur laquelle est écrite la définition standard d'une machine M, U calculera la même séquence que M".

Il faut comprendre que c'est absolument extraordinaire ce que nous raconte Turing à ce moment là. Remettons-nous dans le contexte, en 1936, au moment où Turing rédige son article, on construit déjà, et depuis un certain temps maintenant, des machines. Mais chacune de ces machines est construite pour réaliser une tâche spécifique.

Et c'est bien la même chose pour les machines à calculer de l'époque. Des machines mécaniques qui vont nous sembler assez rudimentaires puisqu'elle ne permettent que de manipuler les quatres opérations de bases, l'addition, la soustraction, la multiplication et la division.

Mais il faut voir que chacune de ces opérations est réalisée grâce à un assemblage de roues, d'engrenages etc. Alors si on voulait ajouter une opération supplémentaire, il faudrait déssiner, ajouter un assemblage supplémentaire.

Et c'est en ça que la machine universelle de Turing est révolutionaire, c'est que Turing montre qu'on peut construire une machine unique, un assemblage unique, qui permettra de réaliser n'importe quel calcul, de calculer tout ce qui est calculable, à condition de lui fournir la description de ce calcul.

Et c'est là la seconde grande idée, le concept de programme. Alors il existe aussi des machines programmables, à commencer par le métier à tissier Jacquard, qui date de 1801. Mais le programme est toujours considéré comme une entité extérieure, immuable face à la machine.

Alors que dans la machine universelle, le programme est à l'intérieur de la machine, il est inscrit sur le ruban, ce qu'on peut considérer comme la "mémoire" de la machine. Et c'est aussi un endroit que la machine de Turing peut modifier, elle pourrait, pourquoi pas, se reprogrammer elle-même. Et c'est bien la première fois en 1936 qu'on peut envisager une telle posibilité.

Et c'est en ça que l'article de 1936 est fondateur, c'est parcequ'il pose les deux piliers théoriques, une machine unique capable de calculer tout ce qui est calculable, et le programme stocké en mémoire, qui seront fondamataux pour la science informatique à venir.
