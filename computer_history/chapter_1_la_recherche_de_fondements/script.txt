Bonjour. Aujourd'hui vous et moi, nous allons nous lancer dans une longue histoire, un exposé sur l'histoire de la naissance des premiers ordinateurs. Mais avant de se commencer directement, j'aimerais paraphraser ce que m'a dit Jean Lassègue dans un entretient au moment où j'effectuais mes recherches. Il me disait, l'histoire de l'ordinateur est soit vue d'un point de vue théorique. Les premiers ordinateurs seraient le fruit d'une réfléxion très théorique menée principalement par Turing et Von Neumann.. Soit, l'autre version de la même histoire, c'est de considérer qu'il s'agit essentiellement d'une affaire d'ingénierie, et de la mise ou point, ou de la perfection, de machines calculantes.

Alors, on va essayer ensemble d'explorer les deux versans de cette histoire. Et pour commencer, on va remonter un peu avant le début du 20ème siècle, et suivre à travers le travail de David Hilbert l'apparition de la théorie de la calculabilité, dans le cadre de ce qui à été l'un des plus terribles problème mathématique : la recherche de fondement.

Mais commençons par le commencement, Hilbert est Allemand, et il va démarrer ses études en mathémtiques, contre l'avis de son père on peut le noter, à l'université de Köningsberg, qui, il faut le dire, est une des plus réputés d'Allemagne.
Et c'est à Köningsberg qu'Hilbert va faire deux rencontres qui vont semer les graines de son futur parcours. D'abord, il va croiser le chemin d'Adolf Huritz qui est professeur à l'unversité, mais surtout, Hilbert va nouer une grande amitié avec une autre étudiant qui pourtant bénéficier déjà d'une renommé mathématique internationale, c'est Hermann Minkowsky.

On a d'ailleur un témoignage, une citation directement de Hilbert, qui nous raconte, il se souvient, puisque la citation date de 1920 et que le temps de Hilbert à Köningsberg commence en 1880. Donc Hilbert se souvient, et nous raconte : "Ainsi, alors que j'étais encore étudiant, j'ai été poussé par Hurwitz au coeur des débats scientifiques et j'ai eu la chance, en étant avec lui, d'apprendre à connaître, d'une façon plaisante, les deux écoles opposées mais parfaitement complémentaires, l'école géométrique de Klein et l'école algébrique-analytique de Berlin. Lorsqu'il revenait dans sa famille à Köningsberg, le génial Minkowski, avec qui je m'étais déjà lié, se joignait à nous. Au cours de ces innombrables promenades, jour après jour, pendant huit années, nous avons fouillé tous les coins du savoir mathématique."

Peu après ses études, et après avoir pris le temps de voyager et de rencontrer certaines des grands noms des mathématiques de son époque, Klein, Kronecker, Pointcaré; Hilbert va devenir "enseignant", ou plutôt, "privatzen", qu'on peut traduire par "assistant". C'est classique dans le système éducatif de l'époque, le "privatzen" peut enseigner mais ne touche pas de rémunération fixe, il est payé directement par les élèves qui choississent d'assister à ses cours, puisqu'il n'y a pas dans les universités de classes imposés.

Mais ce statut lui offre également le temps, la flexibilité nécéssaire pour commencer un travail de recherche, et en particulier, Hilbert va s'intèresser à la théorie des invariants qui, depuis 20 ans maintenant, attends des réponses. Le problème que l'on cherche à résoudre en théorie des invariants, c'est d'identifier certaines propriètés invariantes pour des formes représentées dans des espaces à plusieurs dimensions. Et pour l'instant, on ne sait identifier ces propriètés invariante que pour les espaces en deux dimensions, grâce aux travaux de Gordan, qui déjà, ont nécéssités une quantité astronomique de calculs. Le problème est clair, avec la méthode actuelle, personne ne peut réaliser la quantité de calculs nécéssaires pour des espaces à plus de deux dimensions.

Alors Hilbert décide simplement de changer de méthode. En utilisant ce que l'on apelle la méthode abstraite, Hilbert va réussir à démontrer qu'il existe une famille génératrice de formes pour une espace de n'importe quel nombre de dimensions, et que donc, le propriètés invariantes des formes sont les propriètes de la famille génératrice. Et il arrive à ce résultat sans aucun calcul ! Mais il manque une méthode pour calculer la famille génératrice, il faut donc croire Hilbert, et accepter que cette famille génératrice existe, même si on ne la connait pas et qu'on ne sait pas la calculer.

Il va publier ses résultats en 1890 dans un article "De la théorie des formes algébriques", auquel Gordant répondra : "Das ist nicht Mathematik. Das ist Theologie! [Ce n'est pas des mathématiques, c'est de la théologie]". Pourtant, trois ans plus tard, Hilbert publie à nouveau sur la théorie des invariants et cette fois, il fournit une méthode afin de calculer la famille génératrice de forme. Gordant sera obligé de l'admettre : "La théologie à parfois ses mérites".

De son côté, Hilbert écrit à Minkowski : "Je quitte maintenant le domaine des invariants définitivement et je ne m'occuperais plus que de théorie des nombres". L'association des mathématiciens Allemands lui demande d'écrire, avec Minkowski, un rapport sur la théorie des nombres algébriques, puisque Kummer et Kronecker, qui sont les deux grandes figures du domaine, ont peu publiés. Minkowski est peu intéressé par ce travail et en 1897, Hilbert publiera finalement seul son rapport, "la théories des nombres algébriques", qui deviendra dans les années vingt un véritable ouvrage de référence.

Au même moment, Hilbert arrive à Göttingen. À l'invitation de Klein, il est nommé professeur ordinaire à l'université en 1895, puis à son tour, il fera nommer Minkowski en 1902. De l'influence de Klein, de Hilbert et de Minkowski, Göttingen va devenir un centre incontournable des mathématiques, et la reconnaissance du travail d'Hilbert viendra autant de ses propres travaux, que la place particulière de l'université. Vous voyez, Göttingen attire de nombreux étudiants, certains comme Hermann Weyl qui écrira en 1944 : "J'entends toujours la flûte douce de Hilbert nous séduisant pour nous conduire dans la rivière profonde des mathématiques [...] Les portes d'un monde nouveau s'ouvraient devant moi et je n'étais pas là depuis longtemps que déjà la résolution s'était formé dans mon jeune coeur de lire tout ce que cet homme avait écrit."

Et Hilbert va publier. Après avoir publié son rapport sur la théorie des nombres, il change une fois encore de domaine et s'intéresse à la géométrie. Je vous avais dit quand il s'occupait de théorie des invariants qu'il avait résolu le problème en adoptant un différent point de vue, et en appliquant la méthode abstraite au probléme. C'est ce qu'il va faire avec la géométrie en poussant encore un peu loin la méthode abstraite, jusqu'à l'axiomatique.

En 300 avant notre ère, Euclide est le premier mathématicien à définir formelement une ensemble de régles pour définir ce que nous pouvons et ne pouvons pas faire en géométrie. C'est la première axiomatisation. Définir un ensemble de régles, un ensemble d'axiomes, qui sont intuitivement vrais, sans qu'on ait besoin de prouver leurs vérités. Tout le reste, toutes les propositions, tous les théorèmes, doivent être prouvés à partir des axiomes et des axiomes seulement.

Depuis Euclide, la méthode axiomatique s'est étendue à tous les champs des mathématiques, et chaque branche des mathématiques poséde son axiomatique, son ensemble de règles qui définissent les objets mathématiques, et ce qu'on peut faire avec.

Mais l'axiomatisation de la géométrie d'Euclide est critiquée, et ça n'est pas nouveau, puisque déjà à son époque, Archiméde avait ajouté un axiome supplémentaire. Le défaut de l'axiomatisation d'Euclide, c'est qu'il n'y a pas suffisament d'axiomes pour répondre à certains problèmes de façon uniquement logique, et on doit parfois recourir à l'intuition, au sens évident d'une chose, pour pallier au manque d'axiomes.

Pour vous donner un exemple, si je définis deux axiomes "Socrates est un homme" et "tous les hommes sont mortels". En suivant les règles de la logique je peux affirmer que "Socrate est mortel". Mais en imaginant que je n'ai pas définit le second axiome, celui qui dit que "tous les hommes sont mortels", il m'aurait fallu recourir à l'intuition pour déclarer que "Socrates est mortel". À mon expérience du monde qui m'indique qu'en effet, les hommes sont mortels, mais c'est une preuve mathématique assez faible, puisqu'il suffit de ne pas être d'accord sur le fait que tous les hommes soient mortels, pour ne pas accepter ma conclusion. D'ailleurs qui sait, peut-être qu'il existe ou qu'il existera un homme qui ne soit pas mortel, si je n'ai pas établit en tant que règle que "tous les hommes sont mortels", n'importe qui est parfaitement en droit de ne pas être d'accord.

C'est ce problème que Hilbert veut résoudre en proposant une nouvelle axiomatisation, plus complète, de la géométrie. Et comme il l'avait fait avec les invariants, il va encore une fois changer de perspective par rapport au reste de ses pairs.

D'habitude, les axiomes servent à décrire directement les objets mathématiques. En géométrie ça sera les points, les droites, etc. Plutôt que ça, Hilbert va se servir des axiomes non pas pour décrire les objets mais pour décrire les interactions entre ces objets. Et c'est particulièrement bien illustré dans l'introduction de son cours de géométrie : "Nous pensons trois systèmes différents de choses. Nous nommons les choses du premier système des points [...]. Nous nommons droites les choses du deuxièmes système [...]. Nous appelons plans les choses du troisième système. [...]. Entre les points, les droites et les plans, nous imaginons certaines relations que nous exprimons par des expressions telles que "être sur", "entre", "congruent". La description exacte et appropriée au but des mathématiques de ces relations est donnée par les axiomes de la géométrie".

L'intetrêt de ne décrire que les relations des différents objets, c'est que de cette façon, on peut abstraire le sens des noms, et mettre totalement de côté le sens intuitif.

Si je reprends l'exemple de tout à l'heure, "Socrates est mortel", je peux remplacer toutes les notions contenues dans les axiomes, qui ont un sens intuitif, être un homme, être mortel, par des mots qui ne portent aucun sens. "X est un A", "Tout les A sont des P", donc je peux en déduire que "X est un P". La réflexion est la même, la logique est la même, mais on a supprimé le sens intuitif du contenu, et c'est ce qu'on va appeller la mathématique formelle, à l'inverse de la mathématique contentuelle.

D'ailleurs, il y a une anectode que j'aimerais vous raconter sur Hilbert qui est à la terrasse d'un café avec ses étudiants - c'est exactement la même histoire que ce qu'on vient de faire - et qui dit à ses éléves : "L'on devrait pouvoir parler en géométrie de tables, de chaises et de chopes de bière, au lieu de points, de droites et de plan".

Il s'attaquera ensuite, entre 1901 et 1908 à l'axiomatisation de l'analyse, la branche mathématique qui nous sert à étudier la notion notion de "limite". C'est à cette période qu'il va développer sa "théorie spectrale", ou comme elle est connue aujourd'hui : la "théorie des espace de Hilbert". Ces travaux, liés à la résolution des équations intégrales, seront fondamentaux à la formulation générale de la mécanique quantique, et aux travaux de Weyl, Von Neumann, Schrödinger, de Bohr et d'Heisenberg, qui dira par exemple : "Indirectement, Hibert exerça la plus grande influence sur le développement de la physique [...] Les méthodes mathématiques de la mécanique quantique sont une application directe de la théorie hilbertienne des équations intégrales".

Pour qu'une axiomatisation puisse convaincre, il faut également pouvoir donner une preuve de consistance, c'est à dire, démontrer, prouver qu'on ne peut pas construire à partir des axiomes des propositions contradictoires.

Pour ça, Hilbert, comme les autres mathématiciens avant lui, va procéder par analogie. Il va exprimer les axiomes de la géométrie sous forme algébrique, si les axiomes de la géométrie étaient contradictoires, leur représentation algébrique serait également contradictoire, donc les axiomes de la théorie des nombres algébriques le seraient aussi. Or, la théorie des nombres algébrique est sûre, et peu constestable, donc si Hilbert peut exprimer les axiomes de la géométrie sous forme algébrique, sela constituera une preuve suffisante pour le reste de la communauté.

Mais cette méthode commence à poser problème, puisque la théorie des nombres algébriques elle-même, pourtant au coeur des mathématiques, commence à poser problème. Entre 1897 et 1905, trois paradoxes vont être révélés en théorie des ensembles, dont la consistance repose sur la consistance de l'arithmétique. Et puisque les preuves de consistances reposaient jusqu'à à faire une analogie avec l'algébre, l'algébre elle-même ne posséde pas de preuve de consistance pour ses propres axiomes. C'est le point de départ de ce qui deviendra la "quête de fondement", la recherche d'un fondement solide pour l'ensemble des mathématiques.

Les trois paradoxes sont liés à la théorie des ensembles alors il faut que je vous en parle un peu. La théorie des ensembles à été développée entre 1873 et 1897 par Cantor, et va produire des résultats mathématiques contre-intuitifs. et terriblement innatendus. Ce qui suscitera un profond scepticisme à l'égard de la théorie. Kronecker et Pointcaré par exemple vont vivement critiquer les ensembles, alors que d'un autre cöté, Hilbert en sera l'un des plus farouche soutient.

La théorie des ensembles propose d'étudier des collections d'objets définis par une propriété commune. L'ensemble des nombres pairs, ou l'ensemble des nombres inférieurs à trois, l'ensemble des rectagles dont le périmétre est égal à 1, etc. Au sein de la théorie des ensembles, on trouve la notion de "cardinalité", ou de "taille" d'un ensemble, c'est une notion bien pratique lorsqu'on veut comparer la taille de deux ensembles, en particulier lorsqu'on a affaire à des ensembles contenants un nombre infinis d'éléments, comme l'ensemble des nombres pairs.

L'ensemble des nombres pairs est-il plus grand, ou plus petit, que l'ensemble des nombres entiers ? Si l'on considérait des ensembles finis, les nombres pairs entre 0 et 100, et les nombres entiers entre 0 et 100, la réponse serait évidente, mais comment comparer des ensembles infinis ?

C'est là où la notion de cardinalité est utile puisqu'il ne s'agit pas directement de compter le nombre d'éléments d'un ensemble, ce qui, pour des ensembles infinis serait impossible. En particulier, on peut considérer que deux ensembles possédent la même cardinalité, la même taille, si l'on peut réaliser une correspondance bi-univoque entre ux, c'est à dire, une association terme à terme pour chaque élément des deux ensembles.

Ainsi, je peux associer dans l'ensemble de tous les nombres entiers le nombre "1", au nombre "2" de l'ensemble des nombres pairs. Le nombre "2" des entiers au "4" des pairs, le "3" au "6" et ainsi de suite. D'une façon générale, un nombre x de l'ensemble des entiers est associé au nombre "x*2" des pairs. Ainsi, chaque éléments de l'ensemble des nombres entiers est associer à un et un seul élément de l'ensemble des nombres pairs. Et inversement. On peut dire que les deux ensembles ont la même "cardinalité", c'est à dire, la même taille. L'infini des entiers n'est pas plus grand que l'infini des nombres pairs.

C'est déjà surprenant, mais ce qui va être plus surprenant encore, c'est ce que Cantor va montrer ensuite. Certains infinis sont plus grands que d'autres. On trouve dans certains ensembles infinis nécéssairement plus d'éléments que dans d'autres ensembles infinis.

Ce que fait Cantor c'est qu'il choisit de prendre l'ensemble des nombres entiers, qu'il catégorise d'infini dénombrable, ou listable, et de le comparer à l'ensemble des nombres réels, les nombres à virgule. Pour commencer, Cantor présuppose que ces deux ensembles ont la même cardinalité, la même taille, donc, on il peut réaliser une sorte de liste où à côté de chaque nombre entier serait associé un nombre réel. Dans cette liste, il procéde à une "diagonalisation". Il prends le chiffre à la première position du prmier nombre, celui à la seconde position du second nombre, à la troisième position du troisième nombre, et ainsi de suite pour l'ensemble des nombres de la liste.

Avec cette suite de chiffres, il construit un nouveau nombre en appliquant une régle spéciale : si le chiffre est un "0", je le remplace par un "1", si c'est autre chose qu'un "0", alors je le remplace par un "0". De cette façon, le nombre nouvelle construit est nécéssairement différent de tous les nombres de la liste. Il est différent du premier nombre de la liste puisque le chiffre à la première position est différent, il est différent du second nombre puisque le chiffre à la seconde position est différent, etc.

Mais puisque Cantor à réussit à construire un nouveau nombre, qui est un nombre réel, et qui n'était pas déjà dans la liste, cela signifie qu'il est impossible de faire une correspondance bi-univoque entre ces deux ensembles, et que l'ensemble des nombres réels est "plus grand" que l'ensemble des nombres entiers. Tous les infinis ne se valent pas. D'un côté, les infinis dénombrables, comme les nombres entiers, d'un autre, les infinis continus, comme les nombres réels.

Une question qui va hanter ensuite Cantor est de savoir si il existe des infinis de taille intermédiaire, plus petits que le continu mais plus grand que le dénombrable. C'est ce qu'on appelle "l'hypothése du continu" de Cantor, et c'est pour répondre à cette question que Cantor va développer les nombres ordinaux, qui servent de support au premier paradoxe de la théorie des ensembles.

Les nombres ordinaux servent à décrire à la fois la quantité, et l'ordre des éléments d'un ensemble. À chaque suite d'éléments correspond un nombre ordinal, et à chaque nombre ordinal correspond une suite d'éléments. Le mathématicien Italien Burali-Forti va tenter de calculer le nombre ordinal associé à la suite de tous les nombres ordinaux.

Mais s'il calcule le nombre ordinal de la suite des ordinaux, il n'a pas vraiment calculé le nombre ordinal de la suite de tous les nombres ordinaux, mais seulement le nombre ordinal associé à la suite de tous les nombres ordinaux sauf lui-même. Et même s'il l'on calculait une nouvelle fois un nombre ordinal en incluant celui précédement calculé, on obtiendrait un nouvel nombre ordinal qui n'aurait pas été pris en compte dans la liste.

C'est le paradoxe : N'importe quelle suite devrait posséder un nombre ordinal, pourtant il y ne peut pas exister de nombre ordinal pour la suite des nombres ordinaux.

Le second paradoxe est mis à jour par Bertrand Russell en 1902. Il dit : l'ensemble des cuillères à thé n'est pas lui-même une cuillière à thé, il ne s'appartient pas à lui-même. Mais considérons ensemble l'ensemble de tous les ensembles qui ne s'appartiennent pas à eux-mêmes, est-ce que cet ensemble là s'appartient à lui-même ou pas ?

Si il s'appartenait à lui-même, il correspondrait à sa propre définition d'une ensemble qui ne s'appartient pas à lui-même, donc s'il s'appartenait à lui-même, il ne s'appartiendrait pas à lui-même. Mais s'il ne s'appartient pas à lui-même, alors il mérite de faire partie des ensembles qui ne s'appartiennent pas à eux-mêmes, et donc, il s'appartiendrait à lui-même.

Russell va aussi appliquer la même logique à l'ordre des concepts. "Être vert" est un concept, on peut dire qu'une pomme "est verte", mais "être vert" n'est pas vert lui-même, il ne s'applique pas à lui-même. Il y a un nom pour cela, c'est ce qu'on appelle l'hétérologie, un concept hétérologique est une concept qui ne s'applique pas à lui-même.

Maintenant, est-ce que l'hétérologie est hétérologique ? Si le concept était hétérologique, il s'appliquerait à lui-même, et donc, ne pourrait pas être hétérologique. Mais s'il n'est pas hétérologique, il ne s'applique pas à lui-même, alors il est hétérologique.

Hilbert n'est pas surpris par les réflexions de Russull, dans une lettre à Frege, il explique que Zermelo lui aussi est arrivé à la même conclusion que Russell, et que le paradoxe est connu à Göttingen depuis déjà trois ou quatre ans.

Puis, c'est en 1905 que le dernier paradoxe de la série va être mis à jour par Jules Antoine Richard, qui va au passage emprunter la méthode de "diagonalisation" de Cantor. Il commence par définir l'ensemble de tous les nombres définissables en moins de milles mots, puis, à l'aide de la diagonalisation, crée à partir de cette liste un nouveau nombre. Ce nouveau nombre à été définit en moins de milles mots, puisque la méthode de diagonalisation s'explique en moins de milles mots, donc il devrait être dans la liste, pourtant il ne peut pas être dans la liste, puisque c'est le principe même de la construction par diagonalisation, d'où le paradoxe.

Il faut bien comprendre que tous ces paradoxes, même s'ils ne concernent directement que la théorie des ensembles, se répercutent sur l'arithmétique, et donc sur l'ensemble des mathématiques. Il s'agit alors pour les mathématiciens de repenser l'axiomatique de l'arithmétique, afin de supprimer les paradoxes connus, et de se prévenir contre de futurs paradoxes, en garantissant la consistance, la non-contradiction, des axiomes de l'arthmétique. Le problème ? C'est que personne à ce moment là n'à la moindre de comment construire une preuve de consistance pour l'arithmétique.

Hilbert s'était déjà exprimé sur la nécéssité d'une preuve de consistance pour l'arithmétique. En 1900, au congrès internationnal des mathématiciens, le plus important rassemblement du monde mathématique qui se tient tous les quatres ans, et qui en 1900, se déroule à Paris, juste à côté de l'exposition internationale, Hilbert va donner une conférence. Il envisage d'abord de faire un exposé général sur les mathématiques, mais c'est Minkowski, son ami, qui va lui donner une autre idée. Il écrit à Hilbert en janvier 1900, le 5 janvier, et dit : "Il serait intéressant de regarder dans le futur et de faire une liste des problèmes sur lequels les mathématiciens travaillerons dans le siécle qui vient. Avec un tel sujet, on parlera encore de ton exposé dans plusieurs décénies".

En effet Minkowski ne s'est pas trompé et la liste des 23 problèmes de Hilbert au congrès de 1900 va occuper la quasi-totalité de la recherche mathématique du 20ème siècle, et encore aujourd'hui, certains problèmes ne sont toujours pas résolus.

Mais c'est, pour notre histoire, le second problème de cette liste qui va avoir une résonnance particulière : "Peut-on prouver la cohérence de l'arithmétique ? En d'autres termes, peut-on démontrer que les axiomes de l'arithmétique ne sont pas contradictoires ?".

Hilbert va tenter en 1904, dans le cadre d'une conférence intitulée "Sur les fondements de la logique et de l'arithmétique", une démonstrations de consistance pour un système minimaliste d'axiomes qui ne représentent que les nombres entiers, et la notion d'égalité entre ces nombres.

Cette démonstartion sera vivement critiqué par Henri Pointacré, trés influent dans le monde des mathématiques, et qui ne partage pas les idées d'Hilbert.

Hilbert estime que les objets mathématiques, comme les nombres, existent. Tous les nombres, même si personne ne les a jamais écrits, même si on ne sait pas les calculers, tous les nombres existent. Pour Pointcaré, c'est le contraire, les nombres n'existent pas, ils sont construits par la méthématicien.

Ça ne parait rien mais ça a de grande implication sur la façon de faire des mathématiques. Pour Pointacré, on ne peux pas parler d'infini, puisque les nombres n'existent pas, on ne saurait avoir une collection qui regroupe tous les nombres, ou d'ensemble de tous les ensemble, comme dans la paradoxe de Russell.

Pour le paradoxe de Richard, pas de Paradoxe ! On définit l'ensemble de tous les nombres définits en moins de milles mots, puis on définit un nouveau nombre, à partir de la l'ensemble, mais qui aurait dû appartenir à cet ensemble. Comment ? dit Pointcaré, comment ce nombre aurait-il pu appartenir à l'ensemble puisqu'au moment où on a crée l'ensemble, il n'existait pas ? Il n'y a pas de paradoxe pour Pointcaré, simplement une construction en deux étapes, d'abord on construit une liste, puis à partir de cette liste, on construit un nombre qui n'existait pas avant.

Pointcaré fait reposer les paradoxes sur un principe de cercle vicieux : des objets qui se références eux-mêmes dans leurs définition. Pour le paradoxe de Burali-Forti, on cherche le nombre ordinal de tous les nombres ordinaux. Le nombre ordinal que l'on cherche à besoin de lui-même pour se calculer, c'est le cercle vicieux, et c'est exactement ce que Pointcaré reproche à la démonstration de consistance de Hilbert en 1904.

Hilbert définit quelques axiomes pour représenter les nombres, puis il utilise des nombres pour prouver la consistance de ses axiomes, c'est le cercle vicieux. Il ne peux pas utiliser les nombres pour prouver les nombres.

Pointcaré va mourir en 1912, avant d'avoir pu proposer sa propre solution au problème de la consistance des axiomes de l'arithmétique, mais c'est depuis ses critiques sur le principe de cercle vicieux qu'il est apparu clairement qu'on devrait séparer deux choses : ce qu'on voulait prouver, et les notions qu'on allait utiliser pour le prouver.

Puisque c'est principalement la notion de l'infini qui fait débat, en particulier l'infini actuel, qui présuppose l'existance en soi des objets mathématiques, Hilbert va choisir de diviser l'arithmétique en deux domaines. D'un côté, la mathématique formelle, qui décrit l'ensembles des mathématiques, et que l'on veut prouver. Et d'un autre côté la mathématique contentuelle et finististe, c'est à dire l'arithmétique classique, privée de la notion d'infini.

Mais avant Hilbert, qui ne va s'impliquer qu'à partir de 1917-18 sur ce qu'on appelle le probléme de fondement, justifier les fondements des mathématiques, ce sont trois mathématiciens qui vont tenter de trouver une solution au problème de fondement, Russel et Whitehead d'un Côté, et Brouwer de l'autre.

Parlons d'abord de Russell, de Whitehead et des "Principia Mathematica", une tentative d'axiomatisation globale de toutes les branches des mathématiques. Les "Principias" sont largement inspirées d'un précédent article de Russell de 1908 : "La logique mathématique fondée sur la théorie des types", dans lequel il tente de hiérarchiser les différentes notions mathématiques. Les notions du rang 1 s'appliquent au rang 2, celles du rang 2 au rang 3 et ainsi de suite.

Cette hiérarchie permet d'éviter qu'une notion ne s'applique à elle-même, et évite donc le cercle vicieux décrit par Pointcaré, mais les "Principias" peinent à convaincres. Un défaut particulier, Russell et Whitehead ne présentent pas de preuve de consistance de leurs axiomes. Pour Russell, ces axiomes sont des notions intuitives, et donc, nécéssairement vraies, la démonstration de consistance ne serait qu'une confirmation de leur vérité. En 1927, après être revenu aux probléme du fondement, Hilbert a contester l'évidence de certains axiomes : "La théorie des fondements de Russell et Whitehead [...] fait reposer les mathématiques sur l'axiome de l'infini et sur un axiome dit de réductibilité. Or ces deux axiomes sont d'authentiques hypothèses qui ne peuvent s'appuyer [...] sur une preuve de consistance [... et] dont la validité universelle reste même ouverte au doute".

Un autre qui ira plus loin encore pour placer l'évidence de l'intuition au centre des mathématiques, c'est Brouwer. Pour lui, les paradoxes révélent un usage abusif des règles de la logique, qui font abstraction du sens du contenu, et créent ainsi des énoncés vides de sens, puis finalement, des paradoxes. Comme Pointcaré, il adopte une vision constructiviste des mathématiques, même si cela le force à abandonner certains principes fondamentaux des mathématiques contemporaines, en particulier le "tiers exclu".

Le principe du tiers exclu, qui d'ailleurs repose sur les notions d'infini actuel et d'existence en soi des objets mathématiques, deux notions que défend Hilbert mais que Brouwer comme Pointcaré rejettent. Le principe du tiers exclu donc, permet de dire d'une propriété qui s'applique à un ensemble d'éléments, que soit tous les éléments de l'ensemble vérifient cette propriété, soit il existe au moins un élément qui ne posséde pas cette propriété. En clair, une propriété est soit vraie, soit fausse, et il n'y a pas de troisième option. C'est ce qui fera dire à Brouwer que : "La question de la validité du tiers exclu équivaut à celle de la possibilité de problémes mathématiques non résolubles".

On ne peut pas être plus à l'opposé des idées de Hilbert, qui annonçait haut et fort au congrés international de 1900, Jamais le mathématicien ne sera réduit à dire Ignorabimus !". Ignorabimus : on ne sait pas, et on ne saura pas.

Et pourtant, l'intuitionisme de Brouwer ira jusqu'à convaincre Herman Weyl, l'ancien étudiant de Hilbert qui s'oppose à son ancien professeur : "Si les mathématiques doivent rester une préoccupation culturelle sérieuse, alors un certain sens doit être attaché au jeu de formules de Hilbert, et je ne vois qu'une seule possibilité de lui attribuer un sens intellectuel indépendant. En physique théorique, nous avons devant nous le grand exemple d'une connaissance d'un caractère tout à fait différent de la connaissance commune qui exprime purement ce qui est donné dans l'intuition".

Hilbert répondra, toujours en 1927, aux intuitionistes : "Oter le [tiers exclu] au mathématicien serait comme si on voulait enlever à l'astronome son télescope, au boxeur le droit de se servir de son poing. [... C'est] quasiment à renoncer à la science mathématique. Car que sont les misérables restes, qu'est-ce que la poignée de résultats incomplets et disparates que les intuitionistes ont pu élaborer [...] à l'égard de l'étendue formidable de la mathématique contemporaine ?".

Alors on a vu Brouwer avec l'intuitionisme et la méthode constructiviste, Russell et Whitehead avec les Principas Mathematica et la théorie des types, regardons maintenant comment Hilbert va répondre au problème de fondement.

Hilbert retourne au problème du fondement en 1917, avec une conférence "La Pensée Axiomatique", mais c'est véritablement à partir de 1922, et jusqu'en 1930, qu'Hilbert va tâcler le problème dans une série d'article qui introduit le programme formaliste.

L'objectif du programme formaliste, programme de fondement ou programme d'Hilbert, est d'établir une mathématique formelle, pure de forme et vide de sens. C'est la méthode axiomatique poussée à son paroxysme, une mathématique faite uniquement d'axiomes et de règles logiques, où l'intuition et l'évidence immédiate n'ont pas leur place.

D'un autre côté, Hilbert définit la mathématique finitiste, une arithmétique privée de la notion d'infini, et de tout ce qui fait débat parmis les mathématiciens, le tiers exclu, le principe d'induction complète, etc. Puisque la mathématique finitiste ne contient que des notions immédiatement évidentes, son rôle sera de fournir un preuve de consistance pour la mathématique formelle. Pour Hilbert : il s'agit de "s'assurer par le fini le droit d'opérer sur l'infini".

La force du programme formaliste, c'est qu'il utilise les mathématiques pour justifier les mathématiques, ainsi, Hilbert n'a "besoin ni du Bon Dieu, comme Kronecker, ni de l'hypothèse d'une faculté de conscience accordée au principe d'induction complète, comme Pointcarré, ni de l'intuition originelle de Brouwer, ni non plus des axiomes de l'infini [comme Russell et Whitehead]". Il ira même plus loin : formaliser "c'est dépeindre l'activité de notre intellignece", c'est "dresser un inventaire des règles d'après lesquelles fonctionne réellement notre pensée".

Mais malgrès la force de leurs arguments épistémologique, les mathématiciens engagés dans le programme, Hilbert, Bernays, Von Neumann ou Ackermann, pour n'en citer que quelques-uns, n'ont toujours pas de résultats. Toutes les différentes tentatives d'axiomatisation et de preuve de consistence ont échoués.

C'est alors que Hilbert prendra la parole, au congrès internationnal de Bologne, en 1928. Là, il lance à ses pairs trois problèmes ouverts : L'axiomatique formelle est-elle compléte ? consistante ? et décidable ?

L'axiomatique formelle est-elle complète ? C'est à dire que n'importe quelle proposition ou formule crée à partir des axiomes est nécéssairement soit démontrable, soit réfutable. Ça serait la validation du principe du tiers exclu et de l'idée de la résolubilité de tout problème mathématique. "Jamais le mathématicien ne sera réduit à dire Ignorabimus" !

L'axiomatique formelle est-elle consistante ? C'est la preuve de non-contradiction que cherchent les mathématiciens depuis l'apparition des paradoxes en théorie des ensembles. Qui permettrait de justifier la totalité de l'édifice mathématique et de donner à la science des fondations solides, irréfutables.

L'axiomatique formelle est-elle décidable ? Est-ce qu'il existe une méthode effective, qui permette de décider si une formule donnée est démontrable ou réfutable ? Si elle est vraie ou fausse ?

Bien entendu, Hilbert espére que les trois réponses à ces trois problèmes seront positives. C'est même à cette condition seulement que pourrait se poursuivre le programme formaliste. D'ailleurs, tout semble bien parti, toujours au cours de la conférence, Hilbert annonce qu'Ackermann et Von Neumann sont parvenus à prouver la consistance de l'axiomatique formelle.

Il annonce aussi que lui-même et Ackermann pensent pouvoir bientôt amener la preuve de la complétude des "prédicats du premier ordre". Certes, le calcul des prédicats ne représentent pas toute l'arithmétique, mais c'est la partie la plus importante : ils décrivent les règles de la logique. Sans calcul des prédicats, impossible de construire une démonstration ou un théorème en mathématique.

Mais si tout s'annonce bien, c'était sans compter sur la présence au congrés de Bologne d'un mathématicien d'origine Autrichienne : Kurt Gödel.

La nationalité de Gödel fait débat : il est né à Brno, en Autriche-Hongrie, mais sera naturalisé Tchécoslovaque en 1918, à la dissolution de l'Autriche-Hongrie. Attaché à ses racines, il retrouvera la nationnalité Autrichienne en 1929, seulement pour devenir Allemand aprés l'annexion de son pays en 1938. Il finirat par s'exiler aux États-Unis, où il n'obtient la nationnalité que grâce au support de son ami, Albert Einstein.

Mais laiisons là cette histoire et retournons aux fondements. Je vous avais dit qu'en 1928 congrés de Bologne, Hilbert avait annoncé pouvoir apporter la preuve de la complétude des prédicats du premier ordre avec Ackermann. C'est en fait Gödel qui arrivera le premier à démontrer la complétude de cette partie de l'arithmétique, en 1929.

Mais c'est ensuite, en 1931, que Gödel va marquer l'histoire de la recherche des fondements en mathématiques. Le 26 Août 1930, Gödel assiste à une conférence à Köningsberg, Heyting y parle de l'intuitionnisme, Von Neumann parle du formalisme, et Hilbert annonce sa retraite dans un discourt : "Contrairement à l'Ignorabimus stupide, notre credo est: Nous devons savoir. Nous le saurons!", "Wir müssen wissen. Wir werden wissen!", des mots qui seront inscrits sur son épitaphe.

Au cours d'une discussion fortuite, Gödel va présenter à quelques-une de ses pairs le premier théorème d'incomplétude : "Si l'arithmétique élémantaire est ω-consistante, elle comporte des formules fermées qui ne sont ni démontrables, ni réfutables à partir des axiomes". Von Neumann commentera instantanément : "Tout est fini" !

Et il a raison, puisque le théoréme d'incomplétude signe la fin du programme formaliste dans sa forme actuelle. En clair, le théorème dit que n'importe quelle axiomatique, à partir du moment où elle suffisament expressive pour représenter les nombres entiers et les opérations d'addition et de multiplication, est nécéssairement soit inconsistante, soit incompléte. Pour Hilbert qui voulait contruire une axiomatique, qui soit à la fois consistante, compléte et décidable, c'est la catastrophe.

Gödel parvient à ce résultat en montrant que pour n'importe quelle axiomatique, dans laquelle on puisse représenter l'arithématique élémentaire, il peut construire une proposition qui dit "Je ne suis pas démontrable".

De là, deux possibilités, soit la formuler est démontrable, et c'est terrible puisqu'on vient de démontrer quelquechose d'évidement faux, donc le système est inconsistant. Soit, la formule n'est pas démontrable, auquel cas, elle dit vrai. On se retrouve alors avec une formule vraie, mais qui n'est pas démontrable, donc le système est incomplet (dans un système complet, toute les formules vraies sont démontrables).

Von Neumann écrira à Gödel le 20 Novembre 1930 pour lui dire qu'il à trouvé un second théorème à partir du premier : "la consistance d'un systéme ne peut pas être établie au moyen de raisonnements qui se laisseraient formaliser dans le systéme".

Gödel est en fait déjà arrivé à la même conclusion quelques jours plus tôt. Pour le programme formaliste, c'est un nouveau coup dur, Hilbert voulait démontrer l'axiomatique formelle à l'aide de la mathématique finitiste, ce que le second théorème d'incomplétude interdit.

Les deux thèorèmes seront publiés en Janvier 1931 dans une revue mathématique Viennoise. En apprenant les théorèmes de Gödel, Hilbert rentra dans une colère noire. Peut-être parcequ'il n'a pas trouvé lui même ce que Gödel considére comme une "conséquence presque triviale" des travaux de Skolem, mais qu'il n'avait pas remarqué de faute de n'avoir pas quité un point de vue strictement finitiste. Ou alors, plus simplement, parceque ces deux théorèmes d'incomplétude semblent signer la fin du programme formaliste et de la recherche de fondement.

Ce n'est pourtant pas le cas, Gödel commentera d'ailleurs : "il reste un espoir pour que dans le futur on puisse trouver des méthodes satisfaisantes [...] dépassant les limites du système [finitiste de Hilbert] et permettant de fonder l'arithmétique classique et l'analyse. Cette question ouvre un champ de recherches fécond". Et ajoute dans un second commentaire : "la conviction dans la décidabilité de tout problème mathématique n'est pas ébranlée par ce résultat".

Une autre citation, de Von Neumann cette fois : "Ce résultat imposant de l'analyse de Godel ne doit pas être mal compris: il n'exclut pas une preuve  méta-mathématique de la consistance de l'arithmétique. [...] Gödel a montré qu'aucune preuve n'est possible qui peut être représentée au sein de l'arithmétique. Son argument ne supprime pas la possibilité de preuves strictement finitiste qui ne sont pas représentés au sein de l'arithmétique. Mais personne aujourd'hui ne semble avoir une idée claire de ce qu'une preuve finitiste serait qui ne serait pas formulable dans l'arithmétique".

De toute façon, avant de clôre le programme formaliste, il reste à régler la question de la décidabilité. L'axiomatique formelle est-elle décidable ? Et même si depuis les résultats de Gödel, on pense que la réponse sera négative : non il n'existe pas de procédure effective qui puisse décider si une formuler est démontrable ou non, cela reste à prouver.

Et ça va devenir d'autant plus important qu'au sein de la question de la décidabilité se trouve la notion de procédure effective, et si Hilbert disait qu'il existe une réponse pour n'importe quelle question correctement formulée, celle-là ne l'est pas.

Le terme qu'utilise Hilbert de "procédure effective" ne dispose pas de définition formelle. En fait, la notion de "procédure effective" renvoie à la notion de "calculabilité".

Depuis le 18éme siècle, les mathématiciens ont associé l'idée de calcul avec l'idée de fonction. Mais les fonctions évoluent au 19èeme siécle pour ne plus décrire qu'une correspondance entre un point de départ et un point d'arrivé, sans qu'une procédure effective de calcul n'ait besoin d'être réalisée. On commence alors à dissocier les fonctions endeux groupes, celles qui ont une procédure de calcul effective, les fonction calculables, et les autres, les non-calculables.

Il s'agit alors de trouver une définition au terme de "procédure effective", de "calculabilité", qui engloble toute les fonctions calculables, et mette les autres de côté.

Si je vous ai dit que la question de la décidabilité était devenue d'autant plus importante après les théorèmes d'incomplétude de Gödel, c'est que les théorèmes sont généralisables, mais cette généralisation ne peut se faire qu'une fois qu'on aura une définition satisfaisante de la calculabilité.

Alors ce sont trois mathématiciens qui vont tenter de résoudre ce problème. Gödel d'abord, mais on ne parlera pas de ses recherches, elles sont compliquées et n'aboutissent pas. En revanche, on va parler un peu des travaux d'Alonzo Chruch, et surtout, on verra en détail l'article fondateur d'un jeune mathématicien anglais : Alan Turing.

Church d'abord, établit à Princeton aux États-Unis, il publie en 1936 une preuve de l'indécidabilité de l'arithématique, à l'aide d'un système de calcul qu'il développe en 1932 et 1933, le λ-calcul.

Le λ-calcul est un système formel qui permet de décrire l'ensemble des fonctions calculables. Une fonction est décrire par une expression, qui peut elle-même contenir d'autres fonctions. Afin de créer des fonctions de plus en plus complexes, on peut "appliquer" une fonction à une autre, en clair, on doit d'abord calculer le résultat d'une première fonction, pour ensuite réutiliser ce résultat lors du calcul de la second fonction.

C'est à partir de cette base seulement que l'on peut construire n'importe quelle fonction calculable. Pour vous donner quelques exemples simples, on peut construire la fonction d'identité, qui ne modifie pas la valeur qu'on lui donne : λx.x. On peut aussi construire une fonction constante qui à n'importe quelle valeur fait correspondre la valeur 2 : λx.2.

À partir de ces deux fonctions, on peut les assembler pour créer une fonction qui fabrique des fonctions constantes : λx(λy.x). SI j'envoie la valeur 2, je récupére la fonction constante à 2 : λy.2.

Le λ-calcul permet à Church d'identifier la limite des fonctions calculables, et va lui servir de base pour fournir la démonstration que l'arithmétique n'est pas décidable. Mais si le principe est simple, le λ-calcul est difficile à lire et à relire, et la vérification des résultats de Church est un vrai casse-tête pour le reste des mathématiciens. Tous ne sont pas convaincu.

Stephen Kleene par exemple, un étudiant d'Hilbert qui se souvient de la méthode de diagonalisation de Cantor. Kleene pense que la diagonalisation empêche toute définition formelle de la calculabilité. L'idée est simple : si on a une définition, on peut alors faire une liste de toutes les fonctions calculables, puis, par diagonalisation, on va créer une nouvelle fonction calculable qui n'était pas dans la liste, donc qui n'était pas incluse par la définition de calculabilité, donc la définition est mauvaise.

C'est ce qu'il va immédiatement tenter de faire : "Lorsque Church me proposa sa thèse [pour une définition de la calculabilité], je me mis aussitôt à la tâche de la réfuter par une diagonalisation de la classe des fonctions [calculables]. Mais, réalisant vite que la diagonalisation ne pouvait être faite de façon effective, je devins du jour au lendemain partisan de la thèse de Church".

La définition de Church, de la calculabilité, est bonne, mais quelques mois plus tard, et sans connaitre les travaux de Church, Alan Turing propose une autre définition, identique du point de vue mathématique, mais bien plus simple à comprendre et à réaliser, c'est cette définition qui restera dans l'histoire, c'est la machine de Turing.

En 1935, Turing, qui est encore étudiant au King's College à Cambridge, en Angleterre, assiste au cours de son professeur Max Newman : "Fondement des mathématiques". Newman enseigne les théories de Hilbert, les théorèmes d'incomplétudes de Hilbert et commente sur le problème de la décision : "Supposons, par exemple, que nous puission trouver un système fini de règles qui nous permettrait de dire si une formule quelconque est ou non démontrable. Ce système contiendrait un théorème de métamathématique. Évidemment, ce théorème n'existe pas et c'est heureux, parceque s'il existait, nous aurions un ensemble mécanique de règles nous permettant de trouver la solution de tous les problèmes mathématiques et notre activité en tant que mathématiciens cesserait d'exister".

C'est cette vision mécaniste du calcul, qui vient d'abord de Von Neumann, "il y aurait une instruction absolument mécanique à l'aide de laquelle quiconque pourrait décider, à partir de n'importe quelle formule donnée, si elle est ou non démontrable", qui va pousser Turing à essayer de trouver une machine pour définir la calculabilité. Et on a là dessus le témoignage du fils de Max Newman : "À un moment, il a posé sa classe une question: la prouvabilité des énoncés mathématiques pourrait-elle être découvert par un procédé mécanique ? Cette question est restée dans l'esprit d'Alan, et peu à peu, il a développé le papier qui allait faire sa réputation dans le monde mathématique".

Turing termine à la fin de l'été 1936, deux mois seulement après la publication de Church, un article "On Computable Numbers, with an Application to the Entscheidungsproblem", "Sur les nombres calculables, avec une application au problème de la décision".

Alors, rappelons-le c'est important, Turing, quand il termine son article et qu'il le montre en première lecture à Newman, son professeur, il ne connait pas encore les travaux de Church. Par contre, il les connait en janvier 1937, date où l'article de Turing est publié pour la première fois.

On le sait pour deux raisons, d'abord, parceque Turing mentionne les travaux de Church en introduction de l'article : "Selon ma définition, un nombre est calculable si [il] peut être écrit par une machine. [...] Dans un article récent Alonzo Church a introduit l'idée de «calculabilité effective», ce qui équivaut à ma «calculabilité», mais est définie de manière très différente. Church atteint également des conclusions similaires au sujet du problème de la décision. La preuve de l'équivalence entre «calculabilité» et «calculabilité effective» est décrite dans une annexe au présent document".

Et aussi, parceque Turing va s'installer pendant deux ans à l'université de Princeton, travailler sur des problèmes de logiques sous la direction de Church. C'est son professeur de Cambridge, Max Newman, qui à arrangé cette collaboration, il écrit dans une lettre à Church : "Je dois mentionner que le travail de Turing est entièrement indépendant: il a travaillé sans supervision ou critique de quiconque. Cela rend d'autant plus important qu'il devrait entrer en contact le plus tôt possible avec les principaux travailleurs de ce domaine, de sorte qu'il ne devrait pas se transformer en un solitaire confirmé."

Alors maintenant que nous avons décrit le contexte d'écriture de cet article fondateur de Turing, fondateur à plusieurs niveau on en parlera ensuite, on peut regarder et lire la définition dans le premier chapitre de l'article de cette fameuse machine de Turing.

"On peut comparer un homme en train de calculer un nombre à une machine qui est seulement capable d'un nombre fini de conditions, qui seront appelés "m-configurations". La machine est livrée avec une "bande" (l'analogue du papier) qui la traverse, et est divisée en sections (appelé "carrés") capables chacun de porter un "symbole". A tout moment, il y a juste un carré [...] qui est "dans la machine". Nous pouvons appeler cette place le "carré lu". Le symbole sur la carré lu peut être appelé le "symbole lu". Le "symbole lu" est le seul dont la machine est, pour ainsi dire, "directement au courant". Cependant, en modifiant sa m-configuration la machine peut se rappeler efficacement certains des symboles qu'elle a "vu" précédemment. Le comportement de la machine possible à tout moment est déterminé par la m-configuration [...] et [...] le symbole lu. Cette paire [...] sera appelé "configuration" : ainsi la configuration détermine le comportement possible de la machine. Dans certaines configurations dans lesquelles le carré lu est vierge (i.e. il ne porte pas de symbole), la machine écrit un nouveau symbole sur la place balayée: dans d'autres configurations, il efface le symbole lu. La machine peut également changer le carré en cours de lecture, mais seulement en le déplaçant d'une case à droite ou à gauche. En plus de l'une de ces opérations, la m-configuration peut être modifiée. Certains des symboles écrits formeront la séquence de chiffres [...] du nombre [...] qui est calculé. Les autres ne sont que des brouillons pour "aider la mémoire". [...] Je soutiens que ces opérations comprennent toutes celles qui sont utilisés dans le calcul d'un nombre."

Alors on a une description qui est très courte, et minimaliste, mais c'est tout à fait vonlontaire de la part de Turing puisqu'il veut forcer le lecteur qui veut comprendre à s'identifier à la manichine en train de réaliser un calcul. Et cette identification va renforcer les arguments épistémologiques, philosophiques de Turing par rapport à la justesse de sa machine.

On va passer sur quelques exemples donc, et on va d'ailleurs réutiliser les mêmes exemples que Alan Turing donne dans son article : "Une machine peut être construite pour calculer la séquence 0101001 ... [...] La machine posséde quatre m-configurations "b", "c", "f", "e" et est capable d'écrire "0" et "1". Le comportement de la machine est décrite dans le tableau suivant dans lequel "R" [ndl: Right en anglais, Droite] signifie "la machine se déplace de sorte à lire le carré immédiatement à la droite de celui qui était auparavant lu". De même, pour "L" [ndl: Left, Gauche]. "E" [ndl: Erase] signifie "le symbole lu est effacé" et "P" [ndl: Print] signifie "écrire". La machine démarre dans la m-configuration "b" et une bande vide. [b None P0, R c; c None R e; e None P1, R f; f None R b]"

Il faut que j'insiste sur un point avant de continuer. La table d'instruction qui décrit le comportement de la machine est unique pour chaque machine. La machine que nous venons de décrire n'est capable que de produire la suite 010101 ... De la même manière, il existe une machine capable de faire une soustraction, une pour la multiplication et une autre qui calcule π. Pour chaque calcul, chaque séquence calculable, il existe une machine de Turing.

On peut du coup considérer qu'un calcul en particulier est définissable par rapport à la machine de Turing qui effectue ce calcul. La séquence 010101 ... peut donc être définie par rapport à la machine qu'on a utilisé tout à l'heure. Et cette machine est caractérisé par rapport à sa table d'instruction.

Et si on code chaque ligne de la table d'instruction, on peut obtenir un nombre, que Turing apelle le "nombre standard", qui nous permet de représenter une machine de Turing, et donc, un calcul, sous forme numérique.

Pour faire ça, Turing propose une méthode : On commence la lister les m-configurations de la machines, de façon à pouvoir les identifier comme la "première" m-configuration, ou la "cinquième" m-configuration. On peut alors coder une m-configuration spécifique en utilisant la lettre "D", suivie par la lettre "A" autant de fois que nécéssaire pour décrire sa position dans la liste. Ainsi, la première m-configuration sera codée par "DA", la seconde par "DAA", la cinquième par "DAAAAA".

Et on peut procéder de la même manière pour les symboles qu'écrit la machine. On fait une liste de tout les symboles et on les code avec la lettre "D" suivi de la lettre "C". Le premier symbole sera "DC" et le troisième sera "DCCC".

En plus des m-configurations et des symboles, on va associer une lettre spécifique pour chaque opération de la machine, ainsi, on peut représenter la table d'instriction d'une machine par un code uniquement composé des caractères "A", "C", "D", "L", "R", "N" et ";". Le ";" est utilisé comme séparateur, pour différentier une ligne de l'autre.

La dernière étape est d'associer à chaque caractère un chiffre. Le "A" est remplacé par un "1", le "C" par "2", "D" par "3", "L" par "4", "R" par "5", "N" par "6" et finalement, ";" par "7".

Si je reprends la table d'instruction de notre machine d'exemple, on commence par renommer les m-configurations et les symboles : [table, q est m-configuration, S est symbole] [q1 S0 PS1,R q2; q2 S0 PS0,R q3; q3 S0 PS2,R q4; q4 S0 PS0,R q1]

Puis, on code chaque ligne de la table pour déterminier la "définition standard" : "DADDCRDAA;DAADDRDAAA;DAAADDCCRDAAAA;DAAAADDRDA". Et à partir de là, le nombre de la définition : 31332531173113353111731113322531111731111335317.

L'interêt de cette notation de Turing, c'est qu'on dispose maintenant d'un nombre qui décrit une machine de Turing. Et qu'on va pouvoir se servir de ce nombre pour étudier les propriètés de la machine qu'il décrit. Et en particulier, Turing cherche à savoir si il est possible de prédire, à partir du nombre standard d'une machine de Turing prise au hasard, si cette machine va aboutir à un résultat ou non.

On l'a déjà dit, Turing utilise ses machines pour définir la calculabilité, donc l'ensemble des machines de Turing représentent l'ensemble de tout ce qui est calculable. Mais il faut bien remarquer que les calculs n'aboutissent pas tous à un résultat. On peut très bien imaginer une machine de Turing qui inscrirait successivement, sur le même carrée de la bande, le symbole "0", puis "1", puis "2", puis "0", puis "1", puis "2", puis "0", et ainsi de suite, pour toujours. C'est ce que Turing appelle les machines "circulaires", elles tournent en boucle et n'arrivent jamais nulle part.

Alors c'est ça que Turing veut parvenir à deviner, décider à l'avance si une machine s'arrêtera ou non. C'est le problème de l'arrêt, et l'interêt de ce problème, c'est qu'il est presque identique au problème de la décision. Si on résouds le problème de l'arrêt, on aura également résolu le problème de la décision d'Hilbert.

Alors comme pour le problème de la décision, on peut supposer que c'est impossible de décider à l'avance si une machine de Turing que l'on choisit aléatoirement, appelons-la la machine M, si cette machine M est circulaire, donc qu'elle ne s'arrête jamais, ou bien si elle est sans cercle, c'est à dire qu'elle s'arrête.

Mais imaginons pour une seconde qu'il existe une procédure effective, donc une machine de Turing qui puisse décider à l'avance si la machine M est circulaire ou non. On appelera cette machine la machine D.

Comment fonctionne cette machine D ? On commence par lui donner, sur le ruban, le nombre de la description standard de la machine M, si la machine M s'arrête, la machine D va inscrire sur le ruban le symbole "s". En revanche, si la machine M est circulaire, si elle ne s'arrête jamais, la machine D va inscrire sur son ruban le symbole "u".

Maintenant, Turing nous propose de construire une autre machine, la machine U. Son fonctionnement est simple, si elle lit sur le ruban le symbole "u", la machine s'arrête immédiatement. Par contre, si elle lit le symbole "s", la machine U rentre dans une configuration où elle ne s'arrêtera pas.

On sait que cette machine U existe puisqu'il est finalement assez simple de trouver sa table d'instruction.

À partir des machines D et U, en les associants, on va créer la machine H. Donc la machine H, on lui fournit d'abord la description standard d'une machine de Turing, n'importe laquelle, la machine M.

La machine H calcule d'abord un résultat intermédiaire, soit le symbole "u", soit le symbole "s", en fonction si la machine M est circulaire ou non. Et puis, la machine H va soit s'arrêter immédiatement, soit ne jamais s'arrêter, en fonction de ce résultat intermédiaire.

Alors, que se passe t'il si on donne à la machine H sa propre définition stadard ? D'abord, elle doit calculer le résultat intermédiaire, deux solutions, soit la machine D prédit que la machine H s'arrête, soit que la machine H ne s'arrête pas, qu'elle est circulaire.

Si la machine H s'arrete, alors elle inscrit le symbole "s" sur la bande, et rentre dans une configuration où elle ne s'arrête pas. En court, si elle s'arrête, elle ne s'arrête pas. Et si elle ne s'arrête pas ? Dans ce cas, le résultat intermédiaire est un "u", donc la machine H s'arrête.

On a là une double contradiction, une situation impossible, ce qui signifie que les suppositions que l'on avait faites au départ, nos hypothéses, sont fausses. Et la seule hypothése que l'on avait faite, c'était qu'il existe une machine D qui puisse prédire si une autre machine de Turing est circulaire ou non. Cette machine D ne peut donc pas exister. On ne peux pas prédire à l'avance si une machine de Turing s'arrêtera.

Et exactement avec la même démonstration, on peut prouver qu'il n'existe pas de machine de Turing, de procédure effective, qui puisse déterminer si une autre machine inscrira le symbole "0" à un moment donnée dans son exécution.

C'est important pour le problème de la décision, puisque Turing va prouver, dans un language mathématique avancé que je ne développerais pas ici, que si il existe une méthode générale capable de décider si une formule est prouvable, alors, il existe une méthode générale pour déterminer si la machine de Turing correspondante à cette formule écrit "0".

Et comme on a déjà montré qu'une telle machine ne peux pas exister, alors, il n'y a également pas de processus pour déterminer si une formule est prouvable. D'où le problème de la décision ne peut pas être résolu.

Dans la suite de l'article, Turing va exposer plusieurs argument épistémologiques, philosophiques afin de justifier la validité de sa définition, des machines de Turing. Il va les comparer au cahier d'algébre, quadrillé, qu'utilisent les écoliers lorsqu'ils apprenant à calculer. Pour lui, le fonctionnement de ses machines est une bonne description de la façon que nous avons nous, humains, de penser.

C'est d'ailleurs cette validation philosophique qui fera la force de la définition de Turing, du modéle des machines de Turing pour décrire la calculabilité. C'est ce qui manquait au λ-calcul de Church.

Mais je vous avait dit que l'article de Turing était fondateur, alors il n'est pas fondateur pour les mathématiques. Il n'y a finalement aucun résultat nouveau dans ce que présente Turing.

Il propose une définition correcte de la calculabilité, mais on en avait déjà une avec celle de Church. Et d'ailleurs, au moment où l'article est publié, en janvier 1937, Turing à rajouté un appendice dans lequel il prouve que tout ce qu'on peut faire avec les machines de Turing, on peut le faire avec le λ-calcul. Et tout ce qu'on peut faire avec le λcalcul, on peut le faire avec les machines de Turing.

Alors les deux définitions sont bien équivalentes. Même si celle de Turing, qui est largement plus simple, fera l'objet d'une plus largeme approbation, et de l'avis de Church en premier lieu : l'identification avec l'effectivité dans l'ordinaire [...] semble immédiatement évident", ce sont le mots de Church.

On a aussi Gödel qui ajoutera en note à ses théorèmes d'incomplétudes : Grâce à certains travaux qui ont suivi cet article, en particulier ceux de A. M. Turing, nous disposons désormais d'une définition sûre, précise et adéquate du concept de système formel [...] dont la proprièté est qu'en son sein, et en principe, le raisonnement peut être entièrement remplacé par des règles mécaniques".

On a aussi dans l'article la solution, négative, au problème de la décision d'Hilbert. Mais là aussi, Church avait devancé Turing.

Alors si cet article est devenu tellement important par la suite, c'est à cause d'un chapitre dont je ne vous ai pas encore parlé, et qui décrit ce que Turing apelle la machine universelle.

--41 to 44
